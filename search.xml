<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>spark on yarn</title>
      <link href="/2019/05/28/spark-on-yarn/"/>
      <url>/2019/05/28/spark-on-yarn/</url>
      
        <content type="html"><![CDATA[<p>​    Spark在yarn集群上的部署方式分为两种，yarn client（driver运行在客户端）和yarn cluster（driver运行在master上）</p><h4 id="1、driver-on-master。"><a href="#1、driver-on-master。" class="headerlink" title="1、driver on master。"></a>1、driver on master。</h4><p>​    <strong>(1)</strong> Spark Yarn Client向YARN中提交应用程序，包括Application Master程序、启动Application Master的命令、需要在Executor中运行的程序等；</p><p>​    <strong>(2)</strong> Resource manager收到请求后，在其中一个node manager中为应用程序分配一个container，要求它在container中启动应用程序的Application Master，Application master初始化sparkContext以及创建DAG Scheduler和Task Scheduler。</p><p>​    <strong>(3)</strong> Application master根据sparkContext中的配置，向resource manager申请container，同时，Application master向Resource manager注册，这样用户可通过Resource manager查看应用程序的运行状态</p><p>​    <strong>(4)</strong> Resource manager 在集群中寻找符合条件的node manager，在node manager启动container，要求container启动executor，</p><p>​    <strong>(5)</strong> Executor启动后向Application master注册，并接收Application master分配的task</p><p>​    <strong>(6)</strong> 应用程序运行完成后，Application Master向Resource Manager申请注销并关闭自己。</p><h4 id="2、Driver-on-client"><a href="#2、Driver-on-client" class="headerlink" title="2、Driver on client"></a>2、Driver on client</h4><p>​    <strong>(1)</strong> Spark Yarn Client向YARN的Resource Manager申请启动Application Master。同时在SparkContent初始化中将创建DAG Scheduler和TASK Scheduler等</p><p>​    <strong>(2)</strong> ResourceManager收到请求后，在集群中选择一个NodeManager，为该应用程序分配第一个Container，要求它在这个Container中启动应用程序的ApplicationMaster，与YARN-Cluster区别的是在该ApplicationMaster不运行SparkContext，只与SparkContext进行联系进行资源的分派</p><p>​    <strong>(3)</strong> Client中的SparkContext初始化完毕后，与Application Master建立通讯，向Resource Manager注册，根据任务信息向Resource Manager申请资源(Container)</p><p>​    <strong>(4)</strong> 当application master申请到资源后，便与node manager通信，要求它启动container</p><p>​    <strong>(5)</strong> Container启动后向driver中的sparkContext注册，并申请task</p><p>​    <strong>(6)</strong> 应用程序运行完成后，Client的SparkContext向ResourceManager申请注销并关闭自己。</p><h4 id="3、两种方式的区别"><a href="#3、两种方式的区别" class="headerlink" title="3、两种方式的区别"></a>3、两种方式的区别</h4><p>​    Yarn-client和Yarn cluster模式对比可以看出，在Yarn-client（Driver on client）中，Application Master仅仅从Yarn中申请资源给Executor，之后client会跟container通信进行作业的调度。如果client离集群距离较远，建议不要采用此方式，不过此方式有利于交互式的作业。</p>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> yarn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark的Shuffle过程介绍</title>
      <link href="/2019/05/28/spark%E7%9A%84Shuffle%E8%BF%87%E7%A8%8B%E4%BB%8B%E7%BB%8D/"/>
      <url>/2019/05/28/spark%E7%9A%84Shuffle%E8%BF%87%E7%A8%8B%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h4 id="HashShuffle过程介绍"><a href="#HashShuffle过程介绍" class="headerlink" title="HashShuffle过程介绍"></a>HashShuffle过程介绍</h4><p>​    Spark丰富了任务类型，有些任务之间数据流转不需要通过Shuffle，但是有些任务之间还是需要通过Shuffle来传递数据，比如wide dependency的group by key。</p><p>​    Spark中需要Shuffle输出的Map任务会为每个Reduce创建对应的bucket，Map产生的结果会根据设置的partitioner得到对应的bucketId，然后填充到相应的bucket中去。每个Map的输出结果可能包含所有的Reduce所需要的数据，所以每个Map会创建R个bucket（R是reduce的个数），M个Map总共会创建M*R个bucket。</p><p>​    Map创建的bucket其实对应磁盘上的一个文件，Map的结果写到每个bucket中其实就是写到那个磁盘文件中，这个文件也被称为blockFile，是Disk Block Manager管理器通过文件名的Hash值对应到本地目录的子目录中创建的。每个Map要在节点上创建R个磁盘文件用于结果输出，Map的结果是直接输出到磁盘文件上的，100KB的内存缓冲是用来创建Fast Buffered OutputStream输出流。这种方式一个问题就是Shuffle文件过多。</p><pre><code>每一个Mapper创建出和Reducer数目相同的bucket，bucket实际上是一个buffer，其大小为shuffle.file.buffer.kb（默认32KB）。</code></pre><p>Mapper产生的结果会根据设置的partition算法填充到每个bucket中去，然后再写入到磁盘文件。<br>Reducer从远端或是本地的block manager中找到相应的文件读取数据。</p><p>​    针对上述Shuffle过程产生的文件过多问题，Spark有另外一种改进的Shuffle过程：consolidation Shuffle，以期显著减少Shuffle文件的数量。在consolidation Shuffle中每个bucket并非对应一个文件，而是对应文件中的一个segment部分。Job的map在某个节点上第一次执行，为每个reduce创建bucket对应的输出文件，把这些文件组织成ShuffleFileGroup，当这次map执行完之后，这个ShuffleFileGroup可以释放为下次循环利用；当又有map在这个节点上执行时，不需要创建新的bucket文件，而是在上次的ShuffleFileGroup中取得已经创建的文件继续追加写一个segment；当前次map还没执行完，ShuffleFileGroup还没有释放，这时如果有新的map在这个节点上执行，无法循环利用这个ShuffleFileGroup，而是只能创建新的bucket文件组成新的ShuffleFileGroup来写输出。</p><p><strong>优点</strong></p><pre><code>1、快-不需要排序，也不需要维持hash表2、不需要额外空间用作排序3、不需要额外IO-数据写入磁盘只需一次，读取也只需一次</code></pre><p><strong>缺点</strong></p><pre><code>1、当partitions大时，输出大量的文件（cores * R）,性能开始降低2、大量的文件写入，使文件系统开始变为随机写，性能比顺序写要降低100倍3、缓存空间占用比较大</code></pre><h4 id="SortShuffle过程介绍"><a href="#SortShuffle过程介绍" class="headerlink" title="SortShuffle过程介绍"></a>SortShuffle过程介绍</h4><p>​    从1.2.0开始默认为sort shuffle(spark.shuffle.manager= sort)，实现逻辑类似于Hadoop MapReduce，Hash Shuffle每一个reducers产生一个文件，但是Sort Shuffle只是产生一个按照reducer id排序可索引的文件，这样，只需获取有关文件中的相关数据块的位置信息，并fseek就可以读取指定reducer的数据。但对于rueducer数比较少的情况，Hash Shuffle明显要比Sort Shuffle快，因此Sort Shuffle有个“fallback”计划，对于reducers数少于 “spark.shuffle.sort.bypassMergeThreshold” (200 by default)，我们使用fallback计划，hashing相关数据到分开的文件，然后合并这些文件为一个，具体实现为BypassMergeSortShuffleWriter。</p><p>​    在map进行排序，在reduce端应用Timsort[1]进行合并。map端是否容许spill，通过spark.shuffle.spill来设置，默认是true。设置为false，如果没有足够的内存来存储map的输出，那么就会导致OOM错误，因此要慎用。</p><p>​    spark使用AppendOnlyMap存储map输出的数据，利用开源hash函数MurmurHash3和平方探测法把key和value保存在相同的array中。这种保存方法可以是spark进行combine。如果spill为true，会在spill前sort。</p><p>​    与hash shuffle相比，sort shuffle中每个Mapper只产生一个数据文件和一个索引文件，数据文件中的数据按照Reducer排序，但属于同一个Reducer的数据不排序。Mapper产生的数据先放到AppendOnlyMap这个数据结构中，如果内存不够，数据则会spill到磁盘，最后合并成一个文件。<br>与Hash shuffle相比，shuffle文件数量减少，内存使用更加可控。但排序会影响速度。</p><p><strong>优点</strong></p><pre><code>1 map创建文件量较少2 少量的IO随机操作，大部分是顺序读写</code></pre><p><strong>缺点</strong></p><pre><code>1 要比Hash Shuffle要慢，需要自己通过shuffle.sort.bypassMergeThreshold来设置合适的值。2 如果使用SSD盘存储shuffle数据，那么Hash Shuffle可能更合适。</code></pre>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> shuffle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark通信架构</title>
      <link href="/2019/05/28/Spark%E9%80%9A%E4%BF%A1%E6%9E%B6%E6%9E%84/"/>
      <url>/2019/05/28/Spark%E9%80%9A%E4%BF%A1%E6%9E%B6%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<ul><li>Spark一开始使用 Akka 作为内部通信部件。<ul><li>在Spark 1.3年代，为了解决大块数据（如Shuffle）的传输问题，Spark引入了Netty通信框架。到了 Spark 1.6, Spark可以配置使用 Akka 或者 Netty 了，这意味着 Netty 可以完全替代 Akka了。再到 Spark 2, Spark 已经完全抛弃 Akka了，全部使用Netty了。</li></ul></li><li>为什么呢？官方的解释是：<ul><li>很多Spark用户也使用Akka，但是由于Akka不同版本之间无法互相通信，这就要求用户必须使用跟Spark完全一样的Akka版本，导致用户无法升级Akka。</li><li>Spark的Akka配置是针对Spark自身来调优的，可能跟用户自己代码中的Akka配置冲突。</li><li>Spark用的Akka特性很少，这部分特性很容易自己实现。同时，这部分代码量相比Akka来说少很多，debug比较容易。如果遇到什么bug，也可以自己马上fix，不需要等Akka上游发布新版本。而且，Spark升级Akka本身又因为第一点会强制要求用户升级他们使用的Akka，对于某些用户来说是不现实的。</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> 通信 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA -Xms -Xmx -XX:PermSize -XX:MaxPermSize 区别</title>
      <link href="/2019/05/28/JAVA-Xms-Xmx-XX-PermSize-XX-MaxPermSize-%E5%8C%BA%E5%88%AB/"/>
      <url>/2019/05/28/JAVA-Xms-Xmx-XX-PermSize-XX-MaxPermSize-%E5%8C%BA%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h4 id="1、参数设置背景"><a href="#1、参数设置背景" class="headerlink" title="1、参数设置背景"></a>1、参数设置背景</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在做java开发时尤其是大型软件开发时经常会遇到内存溢出的问题，比如说OutOfMemoryError等。这是个让开发人员很痛苦、也很纠结的问题，因为我们有时不知道什么样的操作导致了这种问题的发生。所以我们不得不通过不断的审查、优化自己的代码结构。但是有时我们会发现有些时候不单单是通过重构自身的代码就能够解决这样的问题，因为也可能是由于我们对java虚拟机运行时的内存分配的不得当导致了内存溢出现象的不断发生。</span><br><span class="line"></span><br><span class="line">为了解决这一问题，java开发团队提供了一个用户自定义的方式按需配置java虚拟机运行时的所需的内存——通过参数配置的形式实现参数分配自定义化。</span><br></pre></td></tr></table></figure><h4 id="2、JVM按照其存储数据的内容将所需内存分配为堆区与非堆区两个部分："><a href="#2、JVM按照其存储数据的内容将所需内存分配为堆区与非堆区两个部分：" class="headerlink" title="2、JVM按照其存储数据的内容将所需内存分配为堆区与非堆区两个部分："></a>2、JVM按照其存储数据的内容将所需内存分配为堆区与非堆区两个部分：</h4><pre><code>堆区即为通过new的方式创建的对象（类实例）所占用的内存空间，非堆区即为代码、常量、外部访问（如文件访问流所占资源）等</code></pre><p>​    虽然java的垃圾回收机制虽然能够很好的解决内存浪费的问题，但是这种机制也仅仅的是回收堆区的资源，而对于非堆区的资源就束手无策了，针对这样的资源回收只能凭借开发人员自身的约束来解决。就算是这样（堆区有java回收机制、非堆区开发人员能够很好的解决），当运行时所需内存瞬间激增的时候JVM无奈的也要中止程序的运行。所以本文讲述的是如何解决后者的问题。<br>常见参数种类（配置内存）</p><pre><code>配置堆区：-Xms 、-Xmx、-XX:newSize、-XX:MaxnewSize、-Xmn配置非堆区：-XX:PermSize、-XX:MaxPermSize</code></pre><h5 id="2-1、堆区参数配置"><a href="#2-1、堆区参数配置" class="headerlink" title="2.1、堆区参数配置"></a>2.1、堆区参数配置</h5><ul><li>2.11、-Xms ：表示java虚拟机堆区内存初始内存分配的大小，通常为操作系统可用内存的1/64大小即可，但仍需按照实际情况进行分配。有可能真的按照这样的一个规则分配时，设计出的软件还没有能够运行得起来就挂了。</li><li><p>2.12、-Xmx： 表示java虚拟机堆区内存可被分配的最大上限，通常为操作系统可用内存的1/4大小。但是开发过程中，通常会将 -Xms 与 -Xmx两个参数的配置相同的值，其目的是为了能够在java垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小而浪费资源。</p><p>  一般来讲对于堆区的内存分配只需要对上述两个参数进行合理配置即可。</p></li></ul><h5 id="2-2、非堆区参数配置"><a href="#2-2、非堆区参数配置" class="headerlink" title="2.2、非堆区参数配置"></a>2.2、非堆区参数配置</h5><ul><li>1、-XX:PermSize：表示非堆区初始内存分配大小，其缩写为permanent size（持久化内存）</li><li>2、-XX:MaxPermSize：表示对非堆区分配的内存的最大上限<ul><li>注：在配置之前一定要慎重的考虑一下自身软件所需要的非堆区内存大小，因为此处内存是不会被java垃圾回收机制进行处理的地方。并且更加要注意的是 最大堆内存与最大非堆内存的和绝对不能够超出操作系统的可用内存。</li></ul></li></ul><h4 id="3、jvm-参数配置"><a href="#3、jvm-参数配置" class="headerlink" title="3、jvm 参数配置"></a>3、jvm 参数配置</h4><ul><li><p>1、-Xms：表示java虚拟机堆区内存初始内存分配的大小，通常为操作系统可用内存的1/64大小即可，但仍需按照实际情况进行分配。</p></li><li><p>2、-Xmx：表示java虚拟机堆区内存可被分配的最大上限，通常为操作系统可用内存的1/4大小。</p><ul><li>开发过程中，通常会将-Xms 与-Xmx两个参数的配置相同的值，其目的是为了能够在java垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小而浪费资源。</li></ul><p>1、-XX:newSize：表示新生代初始内存的大小，应该小于-Xms的值；<br>2、-XX:MaxnewSize：表示新生代可被分配的内存的最大上限；当然这个值应该小于-Xmx的值；<br>3、-Xmn：至于这个参数则是对 -XX:newSize、-XX:MaxnewSize两个参数的同时配置，也就是说如果通过-Xmn来配置新生代的内存大小，那么-XX:newSize = -XX:MaxnewSize　=　-Xmn，虽然会很方便，但需要注意的是这个参数是在JDK1.4版本以后才使用的。</p></li></ul><h5 id="3-1、java虚拟机对非堆区内存配置的两个参数："><a href="#3-1、java虚拟机对非堆区内存配置的两个参数：" class="headerlink" title="3.1、java虚拟机对非堆区内存配置的两个参数："></a>3.1、java虚拟机对非堆区内存配置的两个参数：</h5><p>​    1、-XX:PermSize：表示非堆区初始内存分配大小（方法区）<br>​    2、-XX:MaxPermSize：表示对非堆区分配的内存的最大上限（方法区）。</p><p>​    在配置之前一定要慎重的考虑一下自身软件所需要的非堆区内存大小，因为此处内存是不会被java垃圾回收机制进行处理的地方。并且更加要注意的是最大堆内存与最大非堆内存的和绝对不能够超出操作系统的可用内存。</p>]]></content>
      
      
      <categories>
          
          <category> jvm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> JVM </tag>
            
            <tag> GC </tag>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scala 集合转换 java集合</title>
      <link href="/2019/05/28/scala-%E9%9B%86%E5%90%88%E8%BD%AC%E6%8D%A2-java%E9%9B%86%E5%90%88/"/>
      <url>/2019/05/28/scala-%E9%9B%86%E5%90%88%E8%BD%AC%E6%8D%A2-java%E9%9B%86%E5%90%88/</url>
      
        <content type="html"><![CDATA[<p>使用 scala.collection.JavaConverters 与Java集合交互。它有一系列的隐式转换，添加了asJava和asScala的转换方法。使用它们这些方法确保转换是显式的，有助于阅读：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import scala.collection.JavaConverters._</span><br><span class="line"></span><br><span class="line">val list: java.util.List[Int] = Seq(1,2,3,4).asJava</span><br><span class="line">val buffer: scala.collection.mutable.Buffer[Int] = list.asScala</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> scala </tag>
            
            <tag> 集合 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>sparksql处理小文件</title>
      <link href="/2019/05/28/sparksql%E5%A4%84%E7%90%86%E5%B0%8F%E6%96%87%E4%BB%B6/"/>
      <url>/2019/05/28/sparksql%E5%A4%84%E7%90%86%E5%B0%8F%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h4 id="spark处理方式一："><a href="#spark处理方式一：" class="headerlink" title="spark处理方式一："></a>spark处理方式一：</h4><p>val value: RDD[(Text, Text)] = sc.newAPIHadoopFile[Text,Text,CombineTextInputFormat](“hdfs://localhost:9000/test/hadoopkv1”)</p><h4 id="spark处理方式二："><a href="#spark处理方式二：" class="headerlink" title="spark处理方式二："></a>spark处理方式二：</h4><p>var hadoopConf = new Configuration()<br>hadoopConf.set(“mapreduce.input.fileinputformat.split.maxsize”, “512000000”)<br>hadoopConf.set(“mapreduce.input.fileinputformat.split.minsize”, “268435456”)<br>hadoopConf.set(“mapreduce.input.fileinputformat.split.minsize.per.node”, “134217728”)   //下面这两参数可以不设置，详情看文章末尾<br>hadoopConf.set(“mapreduce.input.fileinputformat.split.minsize.per.rack”, “268435456”)</p><p>val data = sc.newAPIHadoopFile(args(1),<br>  classOf[CombineTextInputFormat],<br>  classOf[LongWritable],<br>  classOf[Text], hadoopConf)</p><h4 id="hive处理小文件："><a href="#hive处理小文件：" class="headerlink" title="hive处理小文件："></a>hive处理小文件：</h4><p>sparksession.sqlContext.setConf(“hive.merge.mapfiles”,”true”)<br>sparksession.sqlContext.setConf(“mapred.max.split.size”,”256000000”)<br>sparksession.sqlContext.setConf(“mapred.min.split.size.per.node”,”192000000”)<br>sparksession.sqlContext.setConf(“mapred.min.split.size.per.rack”,”192000000”)<br>sparksession.sqlContext.setConf(“hive.input.format”,”org.apache.hadoop.hive.ql.io.CombineHiveInputFormat”)</p>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> sparksql </tag>
            
            <tag> 小文件 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自己搭建梯子</title>
      <link href="/2019/05/28/%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA%E6%A2%AF%E5%AD%90/"/>
      <url>/2019/05/28/%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA%E6%A2%AF%E5%AD%90/</url>
      
        <content type="html"><![CDATA[<h4 id="1、挑选服务器："><a href="#1、挑选服务器：" class="headerlink" title="1、挑选服务器："></a><strong>1、挑选服务器：</strong></h4><p>​     一般供应商都会提供IP<a href="http://lib.csdn.net/base/softwaretest" target="_blank" rel="noopener">测试</a>延迟，或者看各VPS网站评测介绍，一般来讲亚洲服务器延迟更低，比如香港.新加坡就有很多电信或者网通直连机房，而美国VPS价格更便宜，而且带宽大些。</p><p>​    服务器类型，Xen KVM 性能要好过openvz，不过也要更贵一些，综上所述，建议选直连自己运营商的KVM虚拟技术的亚洲VPS。</p><p>下面我们用日本conoha VPS为例开始操作。</p><p>1.日本conoha支持支付宝支付，每月900日元、中文界面 （50rmb如果几个人合用的话成本还算可以。选择HOSTUS的香港25美元/年电信机房也不错）设置并记root密码点击追加建立服务器，这里我们选择centos 6.6 64位版本</p><p><img src="http://i3.tietuku.com/73939c8862f69acd.png" alt="img">2.回到服务器界面，点开网络配置，记下IP4地址</p><h4 id="2-用XshellPortable连接服务器"><a href="#2-用XshellPortable连接服务器" class="headerlink" title="2.用XshellPortable连接服务器"></a>2.用XshellPortable连接服务器</h4><p>填上IP地址点击确定</p><p>用户名为 root</p><p>密码为开通vps设置的9位密码</p><p>连接成功会显示，root@XXXXXX #<br>然后在设置里把右键改成复制剪贴板中的代码 如图，右键粘贴比较方便</p><h4 id="3-这里我们用秋水兄的SS一键安装脚本"><a href="#3-这里我们用秋水兄的SS一键安装脚本" class="headerlink" title="3.这里我们用秋水兄的SS一键安装脚本"></a>3.这里我们用秋水兄的SS一键安装脚本</h4><p>​    全程仅需3行代码，即使0基础毫无问题，依次输入代码回车即可</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.sh</span><br><span class="line"></span><br><span class="line">chmod +x shadowsocks.sh</span><br><span class="line"></span><br><span class="line">./shadowsocks.sh 2&gt;&amp;1 | tee shadowsocks.log</span><br></pre></td></tr></table></figure><p><img src="http://i3.tietuku.com/ae721437801a8c77.png" alt="img"></p><p>询问密码：输入t66y为端口密码</p><p><img src="http://i3.tietuku.com/0ffcb227120d76cd.png" alt="img"></p><p>默认端口8989.可以指定任意端口 ，回车后耐心等待安装</p><p><img src="http://i3.tietuku.com/5d03e29f5ba8a52b.png" alt="img"></p><p>安装完成后，脚本提示如下：</p><p><img src="http://i3.tietuku.com/ace55c8d0f0405c8.png" alt="img"></p><p>现在我们已经成功搭建了一个单用户版SS代理服务器，用其他帖子的教程连接该服务器即可<br>端口为8989 密码t66y</p><h4 id="4-多用户配置"><a href="#4-多用户配置" class="headerlink" title="4.多用户配置"></a>4.多用户配置</h4><p>删除原配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -f /etc/shadowsocks.json</span><br></pre></td></tr></table></figure><p>编辑配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/shadowsocks.json</span><br></pre></td></tr></table></figure><p><img src="http://i3.tietuku.com/0abd0889dc17cb2e.png" alt="img"></p><p>按下I键，进入编辑状态<br>左下角有标示—INSERT—<br>如图复制下面代码至配置文件<br>配置端口 8989到9004，密码t66y0到t66y4等5个账号<br>可照例加入更多用户</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&quot;local_address&quot;:&quot;127.0.0.1&quot;,</span><br><span class="line">&quot;local_port&quot;:1080,</span><br><span class="line">&quot;port_password&quot;:&#123;</span><br><span class="line">&quot;8989&quot;:&quot;t66y0&quot;,</span><br><span class="line">&quot;9001&quot;:&quot;t66y1&quot;,</span><br><span class="line">&quot;9002&quot;:&quot;t66y2&quot;,</span><br><span class="line">&quot;9003&quot;:&quot;t66y3&quot;,</span><br><span class="line">&quot;9004&quot;:&quot;t66y4&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;timeout&quot;:300,</span><br><span class="line">&quot;method&quot;:&quot;aes-256-cfb&quot;,</span><br><span class="line">&quot;fast_open&quot;: false</span><br></pre></td></tr></table></figure><p>按下ESC键退出编辑状态，同时按下SHIFT+Q键进入退出模式<br>如图输入wq回车保存退出</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wd</span><br></pre></td></tr></table></figure><h4 id="5、重启-SS服务"><a href="#5、重启-SS服务" class="headerlink" title="5、重启 SS服务"></a>5、重启 SS服务</h4><p><code>/etc/init.d/shadowsocks restart</code></p><p>至此一个多用户版本的SS服务器已经搭建完成<br>其他命令：<br>启动：/etc/init.d/shadowsocks start<br>停止：/etc/init.d/shadowsocks stop<br>重启：/etc/init.d/shadowsocks restart<br>状态：/etc/init.d/shadowsocks status<br>卸载：./shadowsocks.sh uninstall</p><h4 id="6、Shadowsocks-WIN客户端设置"><a href="#6、Shadowsocks-WIN客户端设置" class="headerlink" title="6、Shadowsocks WIN客户端设置"></a>6、Shadowsocks WIN客户端设置</h4><p>Win客户端下载地址：<a href="http://sourceforge.NET/projects/shadowsocksgui/files/dist/" target="_blank" rel="noopener">http://sourceforge.NET/projects/shadowsocksgui/files/dist/</a></p><p>设置界面如下：</p><p>其中：Server IP为服务器IP，Server Port为远程端口（在服务器端shadowsocks.json中设置），Password为密码，Encryption为加密方式，选择<code>AES-256-CFB</code>，Proxy Port为本地端口（在服务器端shadowsocks.json中设置），Remarks为别名。</p><p>配置好客户端后，我们需要选择合适的浏览器和插件来应用本地代理，下面分别介绍了Chrome和Firefox的设置方法。</p><p><strong>a、Chrome</strong></p><p>Chrome使用本地代理需要用到插件<a href="http://switchysharp.com/install.html" target="_blank" rel="noopener">SwitchySharp</a>，安装好插件后，打开插件的设置界面，填入如下设置</p><p>设置完成后选择插件的代理模式为<code>Shadowsocks</code>(或者你自己命名的情景模式)后即可。</p><p>上面的设置为全局代理，如需实现智能代理需要手动添加规则，还可以订阅GFWlist，地址为：<a href="http://autoproxy-gfwlist.googlecode.com/svn/trunk/gfwlist.txt" target="_blank" rel="noopener">http://autoproxy-gfwlist.googlecode.com/svn/trunk/gfwlist.txt</a> 由于这个地址不通过代理无法访问，所以你可以通过其它途径下载到本地，这方面资料网上比较丰富，再者使用起来不是很方便，在此我就不赘述了。下面介绍另一种规则，<a href="https://github.com/clowwindy/" target="_blank" rel="noopener">gfwlist2pac</a>，这是网友在Gfwlist的基础上，更新了部分网址转化成的PAC规则文件，目前我就采用的是这种方式，体验不错，当然，由于规则文件都具有时效性，也许你看到这篇文章时这个规则或许不是最好用的了，这里只是讲一种思路，你可以自行选择其他规则，甚至是自定义的规则，使用PAC规则设置如下:</p><p>PAC规则地址：<a href="https://raw.githubusercontent.com/clowwindy/gfwlist2pac/master/test/proxy_abp.pac" target="_blank" rel="noopener">https://raw.githubusercontent.com/clowwindy/gfwlist2pac/master/test/proxy_abp.pac</a></p><p>设置完成后选择插件的代理模式为<code>gfwlist2pac</code>(或者你自己命名的情景模式)后即可。</p><p><strong>b、Firefox</strong></p><p>Firefox使用本地代理需要用到插件<a href="http://fxthunder.com/blog/archives/2866/" target="_blank" rel="noopener">Autoproxy</a>，这个插件原作者已经没有更新了，本文使用的是其他作者的继续更新版，修复了无法订阅gfwlist的bug，订阅方法和上述类似，同样由于原地址无法直接访问，所以可以通过其他途径下载到本地然后导入。</p><h4 id="7、Shadowsocks-Android客户端设置"><a href="#7、Shadowsocks-Android客户端设置" class="headerlink" title="7、Shadowsocks  Android客户端设置"></a>7、Shadowsocks  Android客户端设置</h4><p>首先需要下载android客户端，Shadowsocks的中文名称为影梭，可以从googleplay下载，如果你无法使用googleplay,可从下面的地址下载:<a href="https://github.com/shadowsocks/shadowsocks-android/releases" target="_blank" rel="noopener">https://github.com/shadowsocks/shadowsocks-android/releases</a> ，android版的设置和PC端类似</p>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> 梯子 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络模型和tcp/ip协议</title>
      <link href="/2019/05/28/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%92%8Ctcp-ip%E5%8D%8F%E8%AE%AE/"/>
      <url>/2019/05/28/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%92%8Ctcp-ip%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<h4 id="0、网络模型自上而下共分为七层："><a href="#0、网络模型自上而下共分为七层：" class="headerlink" title="0、网络模型自上而下共分为七层："></a>0、网络模型自上而下共分为七层：</h4><p>7 应用层<br>6 表示层<br>5 会话层<br>4 传输层<br>3 网络层<br>2 数据链路层<br>1 物理层</p><p><strong>其中3、2、1层主要面向通过网络的端到端的数据流，7、6、5、4层定义了应用程序的功能。</strong></p><p><strong>（1）应用层</strong>：与其他计算机进行通讯的一个应用，它是对应应用程序的通信服务的。例如，一个没有通信功能的字处理程序就不能执行通信的代码，从事字处理工作的程序员也不关心OSI的第7层。但是，如果添加了一个传输文件的选项，那么字处理器的程序员就需要实现OSI的第7层。示例：telnet，HTTP,FTP,WWW,NFS,SMTP等。</p><p><strong>（2）表示层</strong>：这一层的主要功能是定义数据格式及加密。例如，FTP允许你选择以二进制或ASII格式传输。如果选择二进制，那么发送方和接收方不改变文件的内容。如果选择ASII格式，发送方将把文本从发送方的字符集转换成标准的ASII后发送数据。在接收方将标准的ASII转换成接收方计算机的字符集。示例：加密，ASII等。</p><p><strong>（3）会话层</strong>：他定义了如何开始、控制和结束一个会话，包括对多个双向小时的控制和管理，以便在只完成连续消息的一部分时可以通知应用，从而使表示层看到的数据是连续的，在某些情况下，如果表示层收到了所有的数据，则用数据代表表示层。示例：RPC，SQL等。</p><p><strong>（4）传输层</strong>：这层的功能包括是否选择差错恢复协议还是无差错恢复协议，及在同一主机上对不同应用的数据流的输入进行复用，还包括对收到的顺序不对的数据包的重新排序功能。示例：TCP，UDP，SPX。</p><p><strong>（5）网络层</strong>：这层对端到端的包传输进行定义，他定义了能够标识所有结点的逻辑地址，还定义了路由实现的方式和学习的方式。为了适应最大传输单元长度小于包长度的传输介质，网络层还定义了如何将一个包分解成更小的包的分段方法。示例：IP,IPX等。</p><p><strong>（6）数据链路层</strong>：他定义了在单个链路上如何传输数据。这些协议与被讨论的歌种介质有关。示例：ATM，FDDI等。</p><p><strong>（7）物理层</strong>：OSI的物理层规范是有关传输介质的特性标准，这些规范通常也参考了其他组织制定的标准。连接头、针、针的使用、电流、电流、编码及光调制等都属于各种物理层规范中的内容。物理层常用多个规范完成对所有细节的定义。示例：Rj45，802.3等。</p><p><strong>OSI分层的优点：</strong><br>（1）人们可以很容易的讨论和学习协议的规范细节。<br>（2）层间的标准接口方便了工程模块化。<br>（3）创建了一个更好的互连环境。<br>（4）降低了复杂度，使程序更容易修改，产品开发的速度更快。<br>（5）每层利用紧邻的下层服务，更容易记住个层的功能。</p><p><strong>tcp/ip</strong></p><p>TCP/IP是“transmission Control Protocol/Internet Protocol”的简写，中文译名为传输控制协议/互联网络协议）协议。</p><p>TCP/IP（传输控制协议/网间协议）是一种网络通信协议，它规范了网络上的所有通信设备，尤其是一个主机与另一个主机之间的数据往来格式以及传送方式。TCP/IP是INTERNET的基础协议，也是一种电脑数据打包和寻址的标准方法。在数据传送中，可以形象地理解为有两个信封，TCP和IP就像是信封，要传递的信息被划分成若干段，每一段塞入一个TCP信封，并在该信封面上记录有分段号的信息，再将TCP信封塞入IP大信封，发送上网。在接受端，一个TCP软件包收集信封，抽出数据，按发送前的顺序还原，并加以校验，若发现差错，TCP将会要求重发。因此，TCP/IP在INTERNET中几乎可以无差错地传送数据。对普通用户来说，并不需要了解网络协议的整个结构，仅需了解IP的地址格式，即可与世界各地进行网络通信。<br>​        </p>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络模型 </tag>
            
            <tag> tcp </tag>
            
            <tag> ip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux安装LAMP</title>
      <link href="/2019/05/27/Linux%E5%AE%89%E8%A3%85LAMP/"/>
      <url>/2019/05/27/Linux%E5%AE%89%E8%A3%85LAMP/</url>
      
        <content type="html"><![CDATA[<h2 id="Linux安装LAMP"><a href="#Linux安装LAMP" class="headerlink" title="Linux安装LAMP"></a>Linux安装LAMP</h2><h4 id="0、使用以下命令安装Apache："><a href="#0、使用以下命令安装Apache：" class="headerlink" title="0、使用以下命令安装Apache："></a><strong>0、使用以下命令安装Apache：</strong></h4><p>yum install httpd</p><p>安装完之后，重新启动Apache：/etc/init.d/httpd restart<br>接着将Apache设置为开机启动：chkconfig httpd on.(这一步使得服务器不需要在每次重启的时候都要手动启动httpd服务)</p><p>要查看httpd服务的启动状态，可以使用命令：chkconfig –list httpd(会显示httpd在各个级别(level)下的启动状态)</p><h4 id="1、使用以下命令安装MySQL："><a href="#1、使用以下命令安装MySQL：" class="headerlink" title="1、使用以下命令安装MySQL："></a>1、使用以下命令安装MySQL：</h4><p>yum install mysql mysql-server<br>同样，如果出现提示已安装的话，就说明系统安装了MySQL了，可以跳过这一步，否则，系统接下来会自动安装MySQL。<br>安装完成了之后，启动MySQL：/etc/init.d/mysql start</p><p>将MySQL设置为开机启动：chkconfig mysqld on<br>最后，拷贝配置文件：cp /usr/share/mysql/my-medium.cnf /etc/my.cnf (在/etc下有个my.cnf文件，直接覆盖就行了)</p><p>1.2、用以下命令给root账户设置密码</p><p>mysql_secure_installation<br>根据提示输入2次密码，就设置成功了。注意，在设置过程中，会提示删除是否anonymous用户，是否拒绝root的远程访问，是否删除测试用的数据库等，这些都需要根据自己的实际情况进行选择。最后出现：Thanks for using MySQL!，设置密码成功了。</p><p>重新启动MySQL：/etc/init.d/mysqld restart</p><ol><li>3、mysql开启远程访问权限</li></ol><p>GRANT ALL PRIVILEGES ON <em>.</em> TO ‘myuser‘@’%’IDENTIFIED BY ‘mypassword’ WITH GRANT OPTION;</p><h4 id="2：安装PHP"><a href="#2：安装PHP" class="headerlink" title="2：安装PHP"></a><strong>2：安装PHP</strong></h4><p>2.1、使用以下命令安装PHP：</p><p>yum install php<br>根据提示往下安装就行了。安装完之后重新启动Apache：/etc/init.d/httpd restart<br>2.2、安装PHP组件，是PHP支持MySQL</p><p>可以使用命令：yum search php来查看PHP的组件，选择需要的模块进行安装：</p><p>yum install php-mysql php-gd libjpeg* php-imap php-ldap php-odbc php-pear php-xml php-xmlrpc php-mbstring php-mcrypt php-bcmath php-mhash libmcrypt</p><p>安装完之后，重启Apache：/etc/init.d/httpd restart</p><p>重启MySQL：/etc/init.d/mysqld restart</p>]]></content>
      
      
      <categories>
          
          <category> 博客搭建 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> apache </tag>
            
            <tag> mysql </tag>
            
            <tag> php </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
