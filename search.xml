<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>RAM和ROM</title>
      <link href="/2019/06/05/RAM%E5%92%8CROM/"/>
      <url>/2019/06/05/RAM%E5%92%8CROM/</url>
      
        <content type="html"><![CDATA[<p><strong>前言</strong></p><p>​    无论是电脑还是手机，容量小的那个一定是内存RAM，容量大的一定是存储（闪存）ROM，比如手机的3GB+64GB、4GB+64GB、6GB+128GB，前者都是内存后者都是存储（闪存）；电脑也是如此，8GB+120GB、16GB+240GB（+3TB），前者都是内存后者都是闪存（或硬盘）。</p><p>​    就像电脑的内存条，可能会有4G，可硬盘有1 TB，装个大的程序有几十G呢哦。为什么相差这么大呢，这是因为，亲们下载的程序在运行的时候只有调用的那部分进去内存，用完就出栈，所以并不需要这么大的RAM，另外业界公认的最大的原因是RAM的制造成本比ROM高太多了，亲们可以参考数字电路里面RAM和ROM的构造等等。</p><p><strong>RAM</strong></p><p>​    RAM又被称作“随机存储器”，是与CPU直接交换数据的内部存储器，也叫主存（内存）。它可以随时读写，而且速度很快，通常作为操作系统或其他正在运行中的程序的临时数据存储媒介。当电源关闭时RAM不能保留数据（掉电数据消失哦）如果需要保存数据，就必须把它们写入一个长期的存储设备中（例如硬盘）。</p><p><strong>ROM</strong></p><p>​    ROM又被称为“只读存储器”，ROM所存数据，一般是装入整机前事先写好的，整机工作过程中只能读出，而不像随机存储器那样能快速地、方便地加以改写。ROM所存数据稳定，断电后所存数据也不会改变。</p><p>RAM和ROM相比，两者的最大区别是RAM在断电以后保存在上面的数据会自动消失，而ROM不会自动消失，可以长时间断电保存。</p><p>​    通常亲们比较难以理解RAM和ROM相比平时亲们口口相传的内存和硬盘容量有什么关系，其实在绝大多数情况下他们的意义是相同的，但对于计算机和手机的角度来说又有一点不同的意义。</p><p>​    假如说在电脑方面RAM即是亲们平时所说的运行内存，它的确是随时可读写的。那么对于电脑ROM来说，并不是指的就是硬盘，因为ROM是只可以读而不可以写的，但是这里的电脑硬盘却是可以写入并修改的。</p><p><strong>总结</strong></p><p>1、RAM与ROM其实都是内存</p><p>2、硬盘是外存</p><p>3、ROM不等于硬盘</p><p>有些亲们可能会想，电脑ROM是用来做什么的呢？</p><p>答曰：存储一些系统相关信息和开机引导BIOS等等。</p><p><strong>对于手机方面</strong></p><p>​    其实亲们太多的困惑大多都来自于手机厂商宣传信息的误导。</p><p>​    因为一般手机厂商都会说有多少G的RAM，多少G的ROM。</p><p>​    对于手机来说，RAM的意义与电脑相同。但ROM就不一样了，倘若一样的话只是存储一些系统信息和开机引导程序等等，又如何会需要几个G的容量，这样庞大的浪费对于厂商来说岂不是割肉一样了吗？</p><p>​    相对来说手机ROM与电脑硬盘意义相同，可读可写，只是除了手机ROM大部分容量作为硬盘，其中有一部分是用来存储系统信息和装机软件的。</p>]]></content>
      
      
      <categories>
          
          <category> 小知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ram </tag>
            
            <tag> rom </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark调优系列之内存和GC调优</title>
      <link href="/2019/06/04/spark%E8%B0%83%E4%BC%98%E7%B3%BB%E5%88%97%E4%B9%8B%E5%86%85%E5%AD%98%E5%92%8CGC%E8%B0%83%E4%BC%98/"/>
      <url>/2019/06/04/spark%E8%B0%83%E4%BC%98%E7%B3%BB%E5%88%97%E4%B9%8B%E5%86%85%E5%AD%98%E5%92%8CGC%E8%B0%83%E4%BC%98/</url>
      
        <content type="html"><![CDATA[<p><strong>本文基于spark1.6讲解。</strong></p><h4 id="一，基本概述"><a href="#一，基本概述" class="headerlink" title="一，基本概述"></a><strong>一，基本概述</strong></h4><p>​    调优内存的使用主要有三个方面的考虑：对象的内存占用量(你可能希望整个数据集都适合内存)，访问这些数据的开销，垃圾回收的负载。</p><p>​    默认情况下，java的对象是可以快速访问的，但是相比于内部的原始数据消耗估计2-5倍的空间。主要归于下面三个原因：</p><p><strong>1)</strong>,每个不同的Java对象都有一个“对象头”，它大约是16个字节，包含一个指向它的类的指针。对于一个数据很少的对象（比如一个Int字段），这可以比数据大。</p><p><strong>2)</strong>,Java字符串在原始字符串数据上具有大约40字节的开销（因为它们将它们存储在一个Chars数组中，并保留额外的数据，例如长度），并且由于String的内部使用UTF-16编码而将每个字符存储为两个字节。因此，一个10个字符的字符串可以容易地消耗60个字节。</p><p><strong>3)</strong>,常用集合类（如HashMap和LinkedList）使用链接的数据结构，其中每个条目都有一个“包装器”对象（例如Map.Entry）。该对象不仅具有头部，还包括指针（通常为8个字节）到列表中的下一个对象。</p><p><strong>4)</strong>,原始类型的集合通常将它们存储为“boxed”对象，如java.lang.Integer。</p><p>本节将从Spark的内存管理概述开始，然后讨论用户可以采取的具体策略，以便在他/她的应用程序中更有效地使用内存。具体来说，我们将描述如何确定对象的内存使用情况，以及如何改进数据结构，或通过以序列化的格式存储数据。然后我们将介绍调优Spark的缓存大小和Java垃圾回收器。</p><h4 id="二，spark的内存管理概述"><a href="#二，spark的内存管理概述" class="headerlink" title="二，spark的内存管理概述"></a><strong>二，spark的内存管理概述</strong></h4><p>​    Spark中的内存使用大部分属于两类：执行和存储。运行内存指的是用于计算的，shuffle，joins，sorts 和aggregations，然后存储内存主要用于缓存和在集群中传播的内部数据。在spark内部，存储器和执行器共享一个统一的区域(M)。当没有使用执行器内存的时候，存储器可以获取所有可用的执行器内存，反之亦然。如果有需要执行器可以驱逐存储占用，但是仅仅当内存小于一个阈值(R)的时候才会发生。换句话说，R描述了M内部的一个子区域，R中的缓存永远不会被清除。由于实施的复杂性，存储内存不得驱逐执行内存。该设计保证了几个理想的性能。</p><p>首先，不使用缓存的应用程序可以将整个空间用于执行，从而避免不必要的磁盘溢写。</p><p>其次，使用缓存的应用程序可以保留最小的存储空间（R），其中数据块不受驱逐。</p><p>最后，这种方法为各种工作负载提供了合理的开箱即用性能，而不需要用户掌握内部如何分配内存的专业知识。</p><p>虽然有两个相关配置，但典型用户不需要调整它们，因为默认值适用于大多数工作负载：</p><p><strong>1)</strong>,spark.memory.fraction将M的大小表示为（JVM堆空间 - 300MB）的一部分（默认为0.75，新版本如spark2.2改为0.6）。剩余的空间（25％，对应的新版本是0.4）用于用户数据结构，Spark中的内部元数据，并且在稀疏和异常大的记录的情况下保护OOM错误。</p><p><strong>2)</strong>,spark.memory.storageFraction表示R的大小作为M的一部分（默认为0.5）。R是M内的存储空间，其中缓存的块免于被执行器驱逐。</p><h4 id="三，确定内存的消耗"><a href="#三，确定内存的消耗" class="headerlink" title="三，确定内存的消耗"></a><strong>三，确定内存的消耗</strong></h4><p>最好的方式去计算一个数据的的内存消耗，就是创建一个RDD，然后加入cache，这样就可以在web ui中Storage页面看到了。页面会告诉你，这个RDD消耗了多少内存。</p><p>要估计特定对象的内存消耗，请使用SizeEstimator的估计方法。这对于尝试使用不同的数据布局来修剪内存使用情况以及确定广播变量在每个执行程序堆中占用的空间量非常有用。</p><h4 id="四，调优数据结构"><a href="#四，调优数据结构" class="headerlink" title="四，调优数据结构"></a><strong>四，调优数据结构</strong></h4><p>减少内存消耗的第一种方法是避免使用增加负担的java特性，例如基于指针的数据结构和包装对象。下面几种方法可以来避免这个。</p><p><strong>1</strong>,将数据结构设计为偏好对象数组和原始类型，而不是标准的Java或Scala集合类（例如HashMap）。fastutil库(<a href="http://fastutil.di.unimi.it/)为与Java标准库兼容的原始类型提供方便的集合类。" target="_blank" rel="noopener">http://fastutil.di.unimi.it/)为与Java标准库兼容的原始类型提供方便的集合类。</a></p><p><strong>2</strong>,尽可能避免使用有很多小对象和指针的嵌套结构。</p><p><strong>3</strong>,针对关键词，考虑使用数字ID或者枚举对象而不是字符串。</p><p><strong>4</strong>,如果您的RAM少于32 GB，请设置JVM标志-XX：+ UseCompressedOops使指针为四个字节而不是八个字节。您可以在spark-env.sh中添加这些选项。</p><h4 id="五，序列化RDD"><a href="#五，序列化RDD" class="headerlink" title="五，序列化RDD"></a><strong>五，序列化RDD</strong></h4><p>​    尽管进行了调优，当您的对象仍然太大而无法有效存储时，一个简单的方法来减少内存使用是使用RDD持久性API中的序列化StorageLevel（如MEMORY_ONLY_SER）以序列化形式存储它们。Spark将会将每个RDD分区存储为一个大字节数组。以序列化形式存储数据的唯一缺点是数据访问变慢，因为必须对每个对象进行反序列化。如果您想以序列化形式缓存数据，我们强烈建议使用Kryo，因为它会使数据比java序列化后的大小更小（而且肯定比原Java对象更小）。</p><h4 id="六，垃圾回收调优"><a href="#六，垃圾回收调优" class="headerlink" title="六，垃圾回收调优"></a><strong>六，垃圾回收调优</strong></h4><h5 id="1，基本介绍"><a href="#1，基本介绍" class="headerlink" title="1，基本介绍"></a><strong>1，基本介绍</strong></h5><p>​    当你程序的RDD频繁的变动的时候，垃圾回收将会是一个问题。RDD的一次读入，然后有很多种基于它的计算，这种情况下垃圾回收没啥问题。当JAVA需要驱逐旧的对象，为新对象腾出空间的时候，需要跟踪所有Java对象并找到无用的对象。要记住的要点是，垃圾收集的成本与Java对象的数量成正比，因此使用较少对象的数据结构（例如，Ints数组，代替LinkedList）将大大降低了成本。一个更好的方法是以序列化形式持久化对象，如上所述：每个RDD分区将只有一个对象（一个字节数组）。在尝试其他技术之前，如果GC是一个问题，首先要尝试的是使用序列化缓存。</p><p>由于任务的运行内存和RDD的缓存内存的干扰，GC也会是一个问题。</p><h5 id="2，测量GC的影响"><a href="#2，测量GC的影响" class="headerlink" title="2，测量GC的影响"></a><strong>2，测量GC的影响</strong></h5><p>​    GC调优的第一步是收集关于垃圾收集发生频率和GC花费的时间的统计信息。通过将-verbose：gc -XX：+ PrintGCDetails -XX：+ PrintGCTimeStamps添加到Java选项来完成。下次运行Spark作业时，每当垃圾收集发生时，都会看到在工作日志中打印的消息。请注意，这些日志将在您的群集的Executor节点上（在其工作目录中的stdout文件中），而不是您的driver功能中。</p><h5 id="3，高级GC调优"><a href="#3，高级GC调优" class="headerlink" title="3，高级GC调优"></a><strong>3，高级GC调优</strong></h5><p>​    为了进一步调整垃圾收集，我们首先需要了解一些关于JVM内存管理的基本信息：</p><p><strong>1)</strong>,java的堆内存分为两个区域新生代和老年代。新生代保存的是生命周期比较短的对象，老年代保存生命周期比较长的对象。</p><p><strong>2)</strong>,新生代又分为了三个区域(Eden, Survivor1, Survivor2)。</p><p><strong>3)</strong>,垃圾收集过程的简化说明：当Eden已满时，Eden上运行了一个minor GC，并将Eden和Survivor1中存在的对象复制到Survivor2。Survivor 将进行交换。如果一个对象足够老，或者Survivor2已满，则会移动到老年代。最后当老年代接近满的时候，会触发full GC。</p><p>​    Spark应用程序GC调优的目标是，确保生命周期比较长的RDD保存在老年代，新生代有足够的空间保存生命周期比较短的对象。这有助于避免触发Full GC去收集task运行期间产生的临时变量。下面列举几个有用的步骤：</p><p><strong>1)</strong>,通过收集垃圾回收信息，判断是否有太多的垃圾回收过程。假如full gc在一个task完成之前触发了好几次，那说明运行task的内存空间不足，需要加内存。</p><p><strong>2)</strong>,在gc的统计信息中，如果老年代接近满了，减少用于缓存的内存(通过减小spark.memory.storageFraction)。缓存较少的对象比降低运行速度对我们来说更有好处。另外，可以考虑减少年轻代。可以通过减小-Xmn参数设置的值，假如使用的话。假如没有设置可以修改JVM的NewRation参数。大多数JVMs默认值是2，意思是老年代占用了三分之二的总内存。这个值要足够大，相当于扩展了spark.memory.fraction.</p><p><strong>3)</strong>,如果有太多的minor gc，较少的major gc，增加Eden区内存会有帮助。将Eden区内存设置的比task运行估计内存稍微大一些。如果Eden区大小确定为E，那就将新生代的内存设置为-Xmn=4/3E，按比例增加内存是考虑到survivor区所占用的内存。</p><p><strong>4)</strong>,尝试通过设置-XX:+UseG1GC垃圾回收器为G1。在垃圾回收器是瓶颈的一些情况下，它可以提高性能。请注意，对于大的Executor堆，通过使用-XX:G!HeapRegionSize去增大G1的堆大小，显得尤为重要。</p><p><strong>5)</strong>,例如，如果您的任务是从HDFS读取数据，则可以使用从HDFS读取的数据块的大小来估计任务使用的内存量。请注意，解压缩块的大小通常是块大小的2或3倍。所以如果我们希望有3或4个任务的工作空间，HDFS块的大小是64 MB，我们可以估计Eden的大小是4 <em> 3 </em> 64MB。</p><p><strong>6)</strong>,监控垃圾收集的频率和时间如何随着新设置的变化而变化。</p><p>经验表明，GC调整的效果取决于您的应用程序和可用的内存量。下面的链接里有更多的在线描述的调优的选项，但在高层次上，管理GC的全面发生频率有助于减少开销。</p><p><a href="http://www.oracle.com/technetwork/java/javase/gc-tuning-6-140523.html" target="_blank" rel="noopener">http://www.oracle.com/technetwork/java/javase/gc-tuning-6-140523.html</a></p>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> gc </tag>
            
            <tag> 调优 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>log4j 输出日志到flume</title>
      <link href="/2019/06/04/log4j-%E8%BE%93%E5%87%BA%E6%97%A5%E5%BF%97%E5%88%B0flume/"/>
      <url>/2019/06/04/log4j-%E8%BE%93%E5%87%BA%E6%97%A5%E5%BF%97%E5%88%B0flume/</url>
      
        <content type="html"><![CDATA[<p>将log4j产生的日志直接输出到flume控制台</p><h4 id="1-编写客户端"><a href="#1-编写客户端" class="headerlink" title="1.编写客户端"></a>1.编写客户端</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">package com.study.test;</span><br><span class="line"></span><br><span class="line">import org.apache.commons.logging.Log;</span><br><span class="line">import org.apache.commons.logging.LogFactory;</span><br><span class="line"></span><br><span class="line">import java.util.Date;</span><br><span class="line"></span><br><span class="line">public class WriteLog &#123;</span><br><span class="line"></span><br><span class="line">    protected static final Log logger = LogFactory.getLog(WriteLog.class);</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        while (true) &#123;</span><br><span class="line">            // 每隔两秒log输出一下当前系统时间戳</span><br><span class="line">            logger.info(new Date().getTime());</span><br><span class="line">            //System.out.println(new Date().getTime());</span><br><span class="line">            Thread.sleep(2000);</span><br><span class="line">            try &#123;</span><br><span class="line">                throw new Exception(&quot;exception msg&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">            catch (Exception e) &#123;</span><br><span class="line">                logger.error(&quot;error:&quot; + e.getMessage());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-pom-xml"><a href="#2-pom-xml" class="headerlink" title="2.pom.xml"></a>2.pom.xml</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"> &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;</span><br><span class="line">         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span><br><span class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;</span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</span><br><span class="line"></span><br><span class="line">    &lt;groupId&gt;com.study.test&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;log4j2flume&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.flume.flume-ng-clients&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;flume-ng-log4jappender&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.7.0&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.6.1&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line">&lt;/project&gt;</span><br></pre></td></tr></table></figure><h4 id="3-log4j-properties"><a href="#3-log4j-properties" class="headerlink" title="3. log4j.properties"></a>3. log4j.properties</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">log4j.rootLogger=INFO,flume</span><br><span class="line">log4j.appender.console=org.apache.log4j.ConsoleAppender</span><br><span class="line">log4j.appender.console.target=System.out</span><br><span class="line">log4j.appender.console.layout=org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.console.layout.ConversionPattern=&quot;%d&#123;yyyy-MM-dd HH:mm:ss&#125; %p [%c:%L] - %m%n</span><br><span class="line"></span><br><span class="line">log4j.appender.flume = org.apache.flume.clients.log4jappender.Log4jAppender</span><br><span class="line">log4j.appender.flume.Hostname = 10.45.17.66</span><br><span class="line">log4j.appender.flume.Port = 4444</span><br><span class="line">log4j.appender.flume.UnsafeMode = true</span><br><span class="line">log4j.appender.flume.layout=org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.flume.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss&#125; %p [%c:%L] - %m%n</span><br></pre></td></tr></table></figure><h4 id="4-配置flume-建立testlog2flume-conf"><a href="#4-配置flume-建立testlog2flume-conf" class="headerlink" title="4.配置flume 建立testlog2flume.conf"></a>4.配置flume 建立testlog2flume.conf</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"># Describe/configure the source</span><br><span class="line">a1.sources.r1.type = avro</span><br><span class="line">a1.sources.r1.bind =0.0.0.0</span><br><span class="line">a1.sources.r1.port = 4444</span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type=logger</span><br><span class="line">#a1.sinks.k1.type = file_roll</span><br><span class="line">#a1.sinks.k1.sink.directory = /data/soft/flume/tmp</span><br><span class="line">#a1.sinks.k1.sink.rollInterval=86400</span><br><span class="line">#a1.sinks.k1.sink.batchSize=100</span><br><span class="line">#a1.sinks.k1.sink.serializer=text</span><br><span class="line">#a1.sinks.k1.sink.serializer.appendNewline = false</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 1000</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure><p>该配置文件中 配置了一个代理a1<br>在代理agent中配置了一个source（源）一个sink（接收器）和一个channel（通道），分别为：r1，k1，c1<br>r1的类型定义为avro(序列化)，对应该类型参数为bind和port 分别为0.0.0.0和4141<br>k1的类型定义为logger，直接输出到日志文件中<br>cl的类型定义为内存方式，设置其参数capactiy和transactionCapacity分别为1000和1000<br>指定r1和k1的channel为c1</p><p>将上述配置中a1.sinks.k1.type=logger注释，把a1.sinks其他的给打开，就是将日志输入到文件</p><h4 id="5-到flume目录下启动flume"><a href="#5-到flume目录下启动flume" class="headerlink" title="5.到flume目录下启动flume"></a>5.到flume目录下启动flume</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent -c conf -f conf/testlog2flume.conf --name a1 -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure><p>flume-ng ：flume 命令<br>agent：运行一个Flume Agent<br>-c：在指定目录下使用配置 use configs in directory<br>-f：指定配置文件，这个配置文件必须在全局选项的–conf（-c）参数定义的目录下<br>–name:Agent的名称（必填）<br>-Dflume.root.logger=INFO,console 该参数将会把flume的日志输出到console</p>]]></content>
      
      
      <categories>
          
          <category> flume </category>
          
      </categories>
      
      
        <tags>
            
            <tag> log4j </tag>
            
            <tag> flume </tag>
            
            <tag> log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scala尾递归</title>
      <link href="/2019/06/03/scala%E5%B0%BE%E9%80%92%E5%BD%92/"/>
      <url>/2019/06/03/scala%E5%B0%BE%E9%80%92%E5%BD%92/</url>
      
        <content type="html"><![CDATA[<h2 id="以递归方式思考"><a href="#以递归方式思考" class="headerlink" title="以递归方式思考"></a>以递归方式思考</h2><p>递归通过灵巧的函数定义，告诉计算机做什么。在函数式编程中，随处可见递归思想的运用。<br>下面给出几个递归函数的例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">object RecursiveExample extends App&#123;</span><br><span class="line">  // 数列求和例子</span><br><span class="line">  def sum(xs: List[Int]): Int =</span><br><span class="line">    if (xs.isEmpty)</span><br><span class="line">      1</span><br><span class="line">    else</span><br><span class="line">      xs.head + sum(xs.tail)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  // 求最大值例子</span><br><span class="line">  def max(xs: List[Int]): Int =</span><br><span class="line">    if (xs.isEmpty)</span><br><span class="line">      throw new NoSuchElementException</span><br><span class="line">    else if (xs.size == 1)// 递归的边界条件</span><br><span class="line">      xs.head</span><br><span class="line">    else</span><br><span class="line">      if (xs.head &gt; max(xs.tail)) xs.head else max(xs.tail)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  // 翻转字符串</span><br><span class="line">  def str_reverse(xs: String): String =</span><br><span class="line">    if (xs.length == 1)</span><br><span class="line">      xs</span><br><span class="line">    else</span><br><span class="line">      str_reverse(xs.tail) + xs.head</span><br><span class="line"></span><br><span class="line">  // 快速排序例子</span><br><span class="line">  def quicksort(ls: List[Int]): List[Int] = &#123;</span><br><span class="line">    if (ls.isEmpty)</span><br><span class="line">      ls</span><br><span class="line">    else</span><br><span class="line">      quicksort(ls.filter(_ &lt; ls.head)) ::: ls.head :: quicksort(ls.filter(_ &gt; ls.head))</span><br><span class="line">      //quicksort(ls.filter(x =&gt;  x &lt; ls.head)) ::: ls.head :: quicksort(ls.filter(x =&gt; x &gt; ls.head))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们以上面代码最后一个快速排序函数为例，使用递归的方式，其代码实现非常的简洁和通俗易懂。递归函数的核心是设计好递归表达式，并且确定算法的边界条件。上面的快速排序中，认为空列表就是排好序的列表，这就是递归的边界条件，这个条件是递归终止的标志。</p><h2 id="尾递归"><a href="#尾递归" class="headerlink" title="尾递归"></a>尾递归</h2><p>递归算法需要保持调用堆栈，效率较低，如果调用次数较多，会耗尽内存或栈溢出。然而，尾递归可以克服这一缺点。<br>尾递归是指递归调用是函数的最后一个语句，而且其结果被直接返回，这是一类特殊的递归调用。由于递归结果总是直接返回，<strong>尾递归比较方便转换为循环</strong>，因此编译器容易对它进行优化。</p><h3 id="递归求阶乘的经典例子"><a href="#递归求阶乘的经典例子" class="headerlink" title="递归求阶乘的经典例子"></a>递归求阶乘的经典例子</h3><p>普通递归求解的代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def factorial(n: BigInt): BigInt = &#123;</span><br><span class="line">  if (n &lt;= 1)</span><br><span class="line">    1</span><br><span class="line">  else</span><br><span class="line">    n * factorial(n-1)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码，由于每次递归调用n-1的阶乘时，都有一次额外的乘法计算，这使得堆栈中的数据都需要保留。在新的递归中要分配新的函数栈。<br>运行过程就像这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">factorial(4)</span><br><span class="line">--------------</span><br><span class="line">4 * factorial(3)</span><br><span class="line">4 * (3 * factorial(2))</span><br><span class="line">4 * (3 * (2 * factorial(1)))</span><br><span class="line">4 * (3 * (2 * 1))</span><br></pre></td></tr></table></figure><p>而下面是一个尾递归版本，在效率上，和循环是等价的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import scala.annotation.tailrec</span><br><span class="line"></span><br><span class="line">def factorialTailRecursive(n: BigInt): BigInt = &#123;</span><br><span class="line">  @tailrec</span><br><span class="line">  def _loop(acc: BigInt, n: BigInt): BigInt =</span><br><span class="line">    if(n &lt;= 1) acc else _loop(acc*n, n-1)</span><br><span class="line"></span><br><span class="line">  _loop(1, n)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的运行过程如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">factorialTailRecursive(4)</span><br><span class="line">--------------------------</span><br><span class="line">_loop(1, 4)</span><br><span class="line">_loop(4, 3)</span><br><span class="line">_loop(12, 2)</span><br><span class="line">_loop(24, 1)</span><br></pre></td></tr></table></figure><p>该函数中的<code>_loop</code>在最后一步，要么返回递归边界条件的值，要么调用递归函数本身。<br><strong>改写成尾递归版本的关键：</strong><br>尾递归版本最重要的就是找到合适的累加器，该累加器可以保留最后一次递归调用留在堆栈中的数据，积累之前调用的结果，这样堆栈数据就可以被丢弃，当前的函数栈可以被重复利用。<br>在这个例子中，变量acc就是累加器，每次递归调用都会更新该变量，直到递归边界条件满足时返回该值。<br><em>对于尾递归，Scala语言特别增加了一个注释@tailrec，该注释可以确保程序员写出的程序是正确的尾递归程序，如果由于疏忽大意，写出的不是一个尾递归程序，则编译器会报告一个编译错误，提醒程序员修改自己的代码。</em></p><h3 id="菲波那切数列的例子"><a href="#菲波那切数列的例子" class="headerlink" title="菲波那切数列的例子"></a>菲波那切数列的例子</h3><p>原始的代码很简单：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def fibonacci(n: Int): Int =</span><br><span class="line">  if (n &lt;= 2)</span><br><span class="line">    1</span><br><span class="line">  else</span><br><span class="line">    fibonacci(n-1) + fibonacci(n-2)</span><br></pre></td></tr></table></figure><p>尾递归版本用了两个累加器，一个保存较小的项acc1，另一个保存较大项acc2：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def fibonacciTailRecursive(n: Int): Int = &#123;</span><br><span class="line">  @tailrec</span><br><span class="line">  def _loop(n: Int, acc1: Int, acc2: Int): Int =</span><br><span class="line">    if(n &lt;= 2)</span><br><span class="line">      acc2</span><br><span class="line">    else</span><br><span class="line">      _loop(n-1, acc2, acc1+acc2)</span><br><span class="line"></span><br><span class="line">  _loop(n, 1, 1)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="几个列表操作中使用尾递归的例子"><a href="#几个列表操作中使用尾递归的例子" class="headerlink" title="几个列表操作中使用尾递归的例子"></a>几个列表操作中使用尾递归的例子</h2><h3 id="求列表的长度"><a href="#求列表的长度" class="headerlink" title="求列表的长度"></a>求列表的长度</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def lengthTailRecursive[A](ls: List[A]): Int = &#123;</span><br><span class="line">  @tailrec</span><br><span class="line">  def lengthR(result: Int, curList: List[A]): Int = curList match &#123;</span><br><span class="line">    case Nil =&gt; result</span><br><span class="line">    case _ :: tail =&gt; lengthR(result+1, tail)</span><br><span class="line">  &#125;</span><br><span class="line">  lengthR(0, ls)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="翻转列表"><a href="#翻转列表" class="headerlink" title="翻转列表"></a>翻转列表</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def reverseTailRecursive[A](ls: List[A]): List[A] = &#123;</span><br><span class="line">  @tailrec</span><br><span class="line">  def reverseR(result: List[A], curList: List[A]): List[A] = curList match &#123;</span><br><span class="line">    case Nil        =&gt; result</span><br><span class="line">    case h :: tail  =&gt; reverseR(h :: result, tail)</span><br><span class="line">  &#125;</span><br><span class="line">  reverseR(Nil, ls)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="去除列表中多个重复的元素"><a href="#去除列表中多个重复的元素" class="headerlink" title="去除列表中多个重复的元素"></a>去除列表中多个重复的元素</h3><p>这里要求去除列表中多个连续的字符，只保留其中的一个。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">// If a list contains repeated elements they should be replaced with</span><br><span class="line">// a single copy of the element.</span><br><span class="line">// The order of the elements should not be changed.</span><br><span class="line">// Example:</span><br><span class="line">// &gt;&gt; compress(List(&apos;a, &apos;a, &apos;a, &apos;a, &apos;b, &apos;c, &apos;c, &apos;a, &apos;a, &apos;d, &apos;e, &apos;e, &apos;e, &apos;e))</span><br><span class="line">// &gt;&gt; List(&apos;a, &apos;b, &apos;c, &apos;a, &apos;d, &apos;e)</span><br><span class="line"></span><br><span class="line">def compressTailRecursive[A](ls: List[A]): List[A] = &#123;</span><br><span class="line">  @tailrec</span><br><span class="line">  def compressR(result: List[A], curList: List[A]): List[A] = curList match &#123;</span><br><span class="line">    case h :: tail  =&gt; compressR(h :: result, tail.dropWhile(_ == h))</span><br><span class="line">    case Nil        =&gt; result.reverse</span><br><span class="line">  &#125;</span><br><span class="line">  compressR(Nil, ls)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> scala </category>
          
      </categories>
      
      
        <tags>
            
            <tag> scala </tag>
            
            <tag> 递归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据仓库架构</title>
      <link href="/2019/05/12/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84/"/>
      <url>/2019/05/12/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<p>业务系统数据：司法信息，工商信息，社保公积金，运营商，淘宝</p><p>增量数据导入到ods层（sparkstreaming任务，sqoop任务，接口调用）</p><p>ods : 贴源层，维度表（dim）</p><p>数据按天分区</p><p>dw(dwd,dws)为了支撑那些应用，那些查询</p><p>dwd:数据宽表</p><p>dws：汇总表</p><p>集市(由dws生成) 面向主题，面向应用。支撑了95%的查询，粒度更细<br>oozie调度 数据增量导入，定时跑任务，cattle（数据迁移，数据增量导入，流程监控）</p><p>一层比一层粒度细 20个表-&gt; 200个表 </p><p>原材料 -&gt;&gt; 数据加工 -&gt; 产品</p>]]></content>
      
      
      <categories>
          
          <category> hive </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据仓库 </tag>
            
            <tag> hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java创建线程的几种方式</title>
      <link href="/2019/03/19/java%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/"/>
      <url>/2019/03/19/java%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="一、继承Thread类创建线程类"><a href="#一、继承Thread类创建线程类" class="headerlink" title="一、继承Thread类创建线程类"></a><strong>一、继承Thread类创建线程类</strong></h2><h3 id="1、Thread类的子类，并重写该类的run方法"><a href="#1、Thread类的子类，并重写该类的run方法" class="headerlink" title="1、Thread类的子类，并重写该类的run方法"></a>1、Thread类的子类，并重写该类的run方法</h3><p>（1）定义Thread类的子类，并重写该类的run方法，该run方法的方法体就代表了线程要完成的任务。因此把run()方法称为执行体。</p><p>（2）创建Thread子类的实例，即创建了线程对象。</p><p>（3）调用线程对象的start()方法来启动该线程。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">package com.thread;  </span><br><span class="line">  </span><br><span class="line">public class FirstThreadTest extends Thread&#123;  </span><br><span class="line">    int i = 0;  </span><br><span class="line">    //重写run方法，run方法的方法体就是现场执行体  </span><br><span class="line">    public void run()  </span><br><span class="line">    &#123;  </span><br><span class="line">        for(;i&lt;100;i++)&#123;  </span><br><span class="line">        System.out.println(getName()+&quot;  &quot;+i);  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    public static void main(String[] args)  </span><br><span class="line">    &#123;  </span><br><span class="line">        for(int i = 0;i&lt; 100;i++)  </span><br><span class="line">        &#123;  </span><br><span class="line">            System.out.println(Thread.currentThread().getName()+&quot;  : &quot;+i);  </span><br><span class="line">            if(i==20)  </span><br><span class="line">            &#123;  </span><br><span class="line">                new FirstThreadTest().start();  </span><br><span class="line">                new FirstThreadTest().start();  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码中Thread.currentThread()方法返回当前正在执行的线程对象。GetName()方法返回调用该方法的线程的名字。</p><h3 id="2、通过Runnable接口创建线程类"><a href="#2、通过Runnable接口创建线程类" class="headerlink" title="2、通过Runnable接口创建线程类"></a>2、通过Runnable接口创建线程类</h3><p>（1）定义runnable接口的实现类，并重写该接口的run()方法，该run()方法的方法体同样是该线程的线程执行体。</p><p>（2）创建 Runnable实现类的实例，并以此实例作为Thread的target来创建Thread对象，该Thread对象才是真正的线程对象。</p><p>（3）调用线程对象的start()方法来启动该线程。</p><p>示例代码为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">package com.thread;  </span><br><span class="line">  </span><br><span class="line">public class RunnableThreadTest implements Runnable  </span><br><span class="line">&#123;  </span><br><span class="line">  </span><br><span class="line">    private int i;  </span><br><span class="line">    public void run()  </span><br><span class="line">    &#123;  </span><br><span class="line">        for(i = 0;i &lt;100;i++)  </span><br><span class="line">        &#123;  </span><br><span class="line">            System.out.println(Thread.currentThread().getName()+&quot; &quot;+i);  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    public static void main(String[] args)  </span><br><span class="line">    &#123;  </span><br><span class="line">        for(int i = 0;i &lt; 100;i++)  </span><br><span class="line">        &#123;  </span><br><span class="line">            System.out.println(Thread.currentThread().getName()+&quot; &quot;+i);  </span><br><span class="line">            if(i==20)  </span><br><span class="line">            &#123;  </span><br><span class="line">                RunnableThreadTest rtt = new RunnableThreadTest();  </span><br><span class="line">                new Thread(rtt,&quot;新线程1&quot;).start();  </span><br><span class="line">                new Thread(rtt,&quot;新线程2&quot;).start();  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>线程的执行流程很简单，当执行代码start()时，就会执行对象中重写的void run();方法，该方法执行完成后，线程就消亡了。</p><h3 id="3、通过Callable和Future创建线程"><a href="#3、通过Callable和Future创建线程" class="headerlink" title="3、通过Callable和Future创建线程"></a>3、通过Callable和Future创建线程</h3><p>（1）创建Callable接口的实现类，并实现call()方法，该call()方法将作为线程执行体，并且有返回值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public interface Callable</span><br><span class="line">&#123;</span><br><span class="line">　　V call() throws Exception;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（2）创建Callable实现类的实例，使用FutureTask类来包装Callable对象，该FutureTask对象封装了该Callable对象的call()方法的返回值。（FutureTask是一个包装器，它通过接受Callable来创建，它同时实现了Future和Runnable接口。）</p><p>（3）使用FutureTask对象作为Thread对象的target创建并启动新线程。</p><p>（4）调用FutureTask对象的get()方法来获得子线程执行结束后的返回值</p><p>实例代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">package com.thread;  </span><br><span class="line">  </span><br><span class="line">import java.util.concurrent.Callable;  </span><br><span class="line">import java.util.concurrent.ExecutionException;  </span><br><span class="line">import java.util.concurrent.FutureTask;  </span><br><span class="line">  </span><br><span class="line">public class CallableThreadTest implements Callable&lt;Integer&gt;  </span><br><span class="line">&#123;  </span><br><span class="line">  </span><br><span class="line">    public static void main(String[] args)  </span><br><span class="line">    &#123;  </span><br><span class="line">        CallableThreadTest ctt = new CallableThreadTest();  </span><br><span class="line">        FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(ctt);  </span><br><span class="line">        for(int i = 0;i &lt; 100;i++)  </span><br><span class="line">        &#123;  </span><br><span class="line">            System.out.println(Thread.currentThread().getName()+&quot; 的循环变量i的值&quot;+i);  </span><br><span class="line">            if(i==20)  </span><br><span class="line">            &#123;  </span><br><span class="line">                new Thread(ft,&quot;有返回值的线程&quot;).start();  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">        try  </span><br><span class="line">        &#123;  </span><br><span class="line">            System.out.println(&quot;子线程的返回值：&quot;+ft.get());  </span><br><span class="line">        &#125; catch (InterruptedException e)  </span><br><span class="line">        &#123;  </span><br><span class="line">            e.printStackTrace();  </span><br><span class="line">        &#125; catch (ExecutionException e)  </span><br><span class="line">        &#123;  </span><br><span class="line">            e.printStackTrace();  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    @Override  </span><br><span class="line">    public Integer call() throws Exception  </span><br><span class="line">    &#123;  </span><br><span class="line">        int i = 0;  </span><br><span class="line">        for(;i&lt;100;i++)  </span><br><span class="line">        &#123;  </span><br><span class="line">            System.out.println(Thread.currentThread().getName()+&quot; &quot;+i);  </span><br><span class="line">        &#125;  </span><br><span class="line">        return i;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="二、创建线程的三种方式的对比"><a href="#二、创建线程的三种方式的对比" class="headerlink" title="二、创建线程的三种方式的对比"></a>二、创建线程的三种方式的对比</h2><p>1、采用实现Runnable、Callable接口的方式创建多线程时，</p><p>优势是：</p><p>线程类只是实现了Runnable接口或Callable接口，还可以继承其他类。</p><p>在这种方式下，多个线程可以共享同一个target对象，所以非常适合多个相同线程来处理同一份资源的情况，从而可以将CPU、代码和数据分开，形成清晰的模型，较好地体现了面向对象的思想。</p><p>劣势是：</p><p>编程稍微复杂，如果要访问当前线程，则必须使用Thread.currentThread()方法。</p><p>2、使用继承Thread类的方式创建多线程时，</p><p>优势是：</p><p>编写简单，如果需要访问当前线程，则无需使用Thread.currentThread()方法，直接使用this即可获得当前线程。</p><p>劣势是：</p><p>线程类已经继承了Thread类，所以不能再继承其他父类。</p><p>3、Runnable和Callable的区别</p><p>(1) Callable规定（重写）的方法是call()，Runnable规定（重写）的方法是run()。</p><p>(2) Callable的任务执行后可返回值，而Runnable的任务是不能返回值的。</p><p>(3) call方法可以抛出异常，run方法不可以。</p><p>(4) 运行Callable任务可以拿到一个Future对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 线程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>主流的OLAP引擎</title>
      <link href="/2019/01/10/%E4%B8%BB%E6%B5%81%E7%9A%84OLAP%E5%BC%95%E6%93%8E/"/>
      <url>/2019/01/10/%E4%B8%BB%E6%B5%81%E7%9A%84OLAP%E5%BC%95%E6%93%8E/</url>
      
        <content type="html"><![CDATA[<h4 id="引用概念"><a href="#引用概念" class="headerlink" title="引用概念"></a>引用概念</h4><ul><li><strong>Serde</strong>：序列化反序列化,serialize/deSerialize</li><li><strong>MPP</strong>：大规模并行处理技术(Massively Parallel Processor)</li><li>按照查询类型划分，OLAP一般分为即席查询和固化查询，<ul><li><strong>即席查询</strong>:通过手写sql完成一些临时的数据分析需求，这类sql形式多变、逻辑复杂，对查询时间没有严格要求</li><li><strong>固化查询</strong>：指的是一些固化下来的取数、看数需求，通过数据产品的形式提供给用户，从而提高数据分析和运营的效率。这类的sql固定模式，对响应时间有较高要求。</li></ul></li></ul><h4 id="按照架构实现划分，主流的OLAP引擎主要有下面三点："><a href="#按照架构实现划分，主流的OLAP引擎主要有下面三点：" class="headerlink" title="按照架构实现划分，主流的OLAP引擎主要有下面三点："></a>按照架构实现划分，主流的OLAP引擎主要有下面三点：</h4><ul><li><p><strong>MPP架构系统</strong>(Presto/Impala/SparkSQL/Drill等)。这种架构主要还是从查询引擎入手，使用分布式查询引擎，而不是使用hive+mapreduce架构，提高查询效率。</p></li><li><p><strong>搜索引擎架构的系统</strong>(es，solr等)，在入库时将数据转换为倒排索引，采用Scatter-Gather计算模型，牺牲了灵活性换取很好的性能，在搜索类查询上能做到亚秒级响应。但是对于扫描聚合为主的查询，随着处理数据量的增加，响应时间也会退化到分钟级。</p></li><li><p><strong>预计算系统</strong>（Druid/Kylin等）则在入库时对数据进行预聚合，进一步牺牲灵活性换取性能，以实现对超大数据集的秒级响应。</p><p>数据轨迹现有的实现方式，从业务诉求看为:每账期按照指定的查询列取数据，进行分析未结算原因，偏向固化查询的方式。但现有的实现方式为先按照查询列值查询出主表数据，再根据主表附属表的关联字段，获取查询附属表的sql，sql为动态拼接出来，这种方式更偏向于即席查询的实现。</p></li></ul><p>需要从以下三个方面考虑框架选型：数据存储和构建、安装搭建、开发成本。</p><h4 id="impala"><a href="#impala" class="headerlink" title="impala"></a>impala</h4><p>​    impala是Cloudera开发开源的，Impala是Cloudera开发并开源的，能查询存储在HDFS和HBase中的数据。同Hive一样，也是一种SQL on Hadoop解决方案。但Impala抛弃了MapReduce,使用更类似于传统的MPP数据库技术来提高查询速度。</p><p>impala可以直接查询hdfs或hbase上的数据，可以与现有的存储无缝对接。<br>impala需要单独安装，公司内paas主推。需要与现场确认。<br>impala提供jdbc接口和sql执行引擎，可以与现有系统集成</p><h4 id="Presto"><a href="#Presto" class="headerlink" title="Presto"></a>Presto</h4><p>​    presto是Facebook开源的大数据查询引擎，为了解决hive查询慢产生。使用java编写，数据全部在内存中处理。</p><p>原生集成了Hive、Hbase和关系型数据库。<br>需要与现场确认是否能提供<br>提供jdbc接口和sql执行引擎，可以与现有系统集成</p><h4 id="druid"><a href="#druid" class="headerlink" title="druid"></a>druid</h4><p>​    druid同kylin一样，是采用预计算的方式。主要解决的是对于大量的基于时序的数据进行聚合查询。数据可以实时摄入，进入到Druid后立即可查，同时数据是几乎是不可变。通常是基于时序的事实事件，事实发生后进入Druid，外部系统就可以对该事实进行查询。</p><p>需要预计算，将数据存储在druid的Segment文件中，占用一部分存储资源<br>需要与现场确认是否能提供<br>对sql支持不友好，需要用他自己的方言书写</p><h4 id="kylin"><a href="#kylin" class="headerlink" title="kylin"></a>kylin</h4><p>​    kylin是一种OLAP数据引擎，支持大数据生态圈的数据分析业务，主要是通过预计算的方式将用户设定的多维度数据立方体(cube)缓存起来，达到快速查询的目的。应用场景应该是针对复杂sql join后的数据缓存。<br>这种OLAP引擎，一般包括以下几部分：</p><p>数据构建存储：cube构建，元数据信息<br>sql解析执行：Query引擎(sql解释器)，routing模块(sql执行)<br>上层接口服务；jdbc/odbc接口，rest服务<br>应用思路：将hive中的数据按照查询列 构建成cube，存储到hbase中，数据轨迹连接kylin的jdbc接口实现快速查询。</p><p>需要预计算，将数据构建成cube存储到hbase<br>需要与现场确认是否能提供<br>提供jdbc接口和rest服务<br>redis<br>将要分析的数据同步到redis，在redis中快速查询数据。可以在分析前将本月数据同步到redis。</p>]]></content>
      
      
      <categories>
          
          <category> 数据仓库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OLAP </tag>
            
            <tag> 数据分析 </tag>
            
            <tag> 数据仓库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Springboot 环境配置</title>
      <link href="/2018/12/17/Springboot-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
      <url>/2018/12/17/Springboot-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h4 id="resource中常见有几种环境配置文件"><a href="#resource中常见有几种环境配置文件" class="headerlink" title="resource中常见有几种环境配置文件"></a><strong>resource中常见有几种环境配置文件</strong></h4><p>​    application-dev.yml（开发环境）<br>     application-test.yml（测试环境）<br>     application-uat.yml（预发布）<br>     application-pro.yml（生产环境）<br>     application.yml</p><h4 id="使用多环境配置有三种方式："><a href="#使用多环境配置有三种方式：" class="headerlink" title="使用多环境配置有三种方式："></a><strong>使用多环境配置有三种方式</strong>：</h4><ol><li>使用@PropertySource注解<br>@PropertySource(classpath:application-dev.yml)</li><li><p>修改spring.profiles.active属性：</p><p>spring.profiles.active:dev</p></li><li><p>执行命令行<br>通过命令行可以直接指定某一配置文件<br>例：java -jar xxx.jar –spring.profiles.active=test</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> springboot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> springboot </tag>
            
            <tag> 环境 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark 数据倾斜（Data Skew）</title>
      <link href="/2018/04/16/spark-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%EF%BC%88Data-Skew%EF%BC%89/"/>
      <url>/2018/04/16/spark-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%EF%BC%88Data-Skew%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h4 id="0、前言"><a href="#0、前言" class="headerlink" title="0、前言"></a>0、前言</h4><p>​    何谓数据倾斜？数据倾斜指的是，并行处理的数据集中，某一部分（如Spark或Kafka的一个Partition）的数据显著多于其它部分，从而使得该部分的处理速度成为整个数据集处理的瓶颈。</p><p>​    数据倾斜的原理很简单：在进行shuffle的时候，必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，比如按照key进行聚合或join等操作。此时如果某个key对应的数据量特别大的话，就会发生数据倾斜。比如大部分key对应10条数据，但是个别key却对应了100万条数据，那么大部分task可能就只会分配到10条数据，然后1秒钟就运行完了；但是个别task可能分配到了100万数据，要运行一两个小时。因此，整个Spark作业的运行进度是由运行时间最长的那个task决定的。</p><p><strong>1 数据倾斜直接会导致一种情况：Out Of Memory。</strong></p><p><strong>2 运行速度慢,特别慢，非常慢，极端的慢，不可接受的慢</strong></p><p>搞定数据倾斜需要：</p><p>1 搞定shuffle</p><p>2 搞定业务场景</p><p>3 搞定 cpu core的使用情况</p><p>4 搞定OOM的根本原因等。</p><p>​    </p><p>​    一个经验结论是：一般情况下，OOM的原因都是数据倾斜。某个task任务数据量太大，GC的压力就很大。这比不了Kafka,因为kafka的内存是不经过JVM的。是基于Linux内核的Page.</p><p>​    <strong>如何定位导致数据倾斜的代码？</strong></p><p>​    数据倾斜只会发生在shuffle过程中。这里给大家罗列一些常用的并且可能会触发shuffle操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。出现数据倾斜时，可能就是你的代码中使用了这些算子中的某一个所导致的。</p><p>​    举例来说，对于上面所说的单词计数程序，如果确定了是stage1的reduceByKey算子导致了数据倾斜，那么就应该看看进行reduceByKey操作的RDD中的key分布情况，在这个例子中指的就是pairs RDD。如下示例，我们可以先对pairs采样10%的样本数据，然后使用countByKey算子统计出每个key出现的次数，最后在客户端遍历和打印样本数据中各个key的出现次数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val sampledPairs = pairs.sample(false, 0.1)</span><br><span class="line"></span><br><span class="line">val sampledWordCounts = sampledPairs.countByKey()</span><br><span class="line"></span><br><span class="line">sampledWordCounts.foreach(println(_))</span><br></pre></td></tr></table></figure><h4 id="1、如何缓解-消除数据倾斜？"><a href="#1、如何缓解-消除数据倾斜？" class="headerlink" title="1、如何缓解/消除数据倾斜？"></a><strong>1、如何缓解/消除数据倾斜？</strong></h4><h5 id="方式一"><a href="#方式一" class="headerlink" title="方式一"></a>方式一</h5><p><strong>尽量避免数据源的数据倾斜</strong><br>​    比如数据源是Kafka</p><p>​    以Spark Stream通过DirectStream方式读取Kafka数据为例。由于Kafka的每一个Partition对应Spark的一个Task（Partition），所以Kafka内相关Topic的各Partition之间数据是否平衡，直接决定Spark处理该数据时是否会产生数据倾斜。</p><p>​    Kafka某一Topic内消息在不同Partition之间的分布，主要由Producer端所使用的Partition实现类决定。如果使用随机Partitioner，则每条消息会随机发送到一个Partition中，从而从概率上来讲，各Partition间的数据会达到平衡。此时源Stage（直接读取Kafka数据的Stage）不会产生数据倾斜。</p><p><strong>解决方案：</strong></p><p>​    将Spark作业的shuffle操作提前到了Hive ETL中，从而让Spark直接使用预处理的Hive中间表，尽可能地减少Spark的shuffle操作，大幅度提升了性能</p><p><strong>方案优点</strong>：实现起来简单便捷，效果还非常好，完全规避掉了数据倾斜，Spark作业的性能会大幅度提升。</p><p><strong>方案缺点</strong>：治标不治本，Hive ETL中还是会发生数据倾斜。</p><h5 id="方式二"><a href="#方式二" class="headerlink" title="方式二"></a>方式二</h5><p><strong>调整并行度分散同一个Task的不同Key</strong><br><strong>案适用场景</strong>：如果我们必须要对数据倾斜迎难而上，那么建议优先使用这种方案，因为这是处理数据倾斜最简单的一种方案。</p><p><strong>方案实现思路</strong>：在对RDD执行shuffle算子时，给shuffle算子传入一个参数，比如reduceByKey(1000)，该参数就设置了这个shuffle算子执行时shuffle read task的数量。对于Spark SQL中的shuffle类语句，比如group by、join等，需要设置一个参数，即spark.sql.shuffle.partitions，该参数代表了shuffle read task的并行度，该值默认是200，对于很多场景来说都有点过小。</p><p><strong>原理</strong></p><p>​    Spark在做Shuffle时，默认使用HashPartitioner（非Hash Shuffle）对数据进行分区。如果并行度设置的不合适，可能造成大量不相同的Key对应的数据被分配到了同一个Task上，造成该Task所处理的数据远大于其它Task，从而造成数据倾斜。</p><p><strong>优势</strong></p><p>​    实现简单，可在需要Shuffle的操作算子上直接设置并行度或者使用spark.default.parallelism设置。如果是Spark SQL，还可通过SET spark.sql.shuffle.partitions=[num_tasks]设置并行度。可用最小的代价解决问题。一般如果出现数据倾斜，都可以通过这种方法先试验几次，如果问题未解决，再尝试其它方法。</p><p><strong>劣势</strong></p><p>​    适用场景少，只能将分配到同一Task的不同Key分散开，但对于同一Key倾斜严重的情况该方法并不适用。并且该方法一般只能缓解数据倾斜，没有彻底消除问题。从实践经验来看，其效果一般。</p><h5 id="方式三"><a href="#方式三" class="headerlink" title="方式三"></a><strong>方式三</strong></h5><p><strong>自定义Partitioner</strong><br><strong>原理</strong></p><p>​    使用自定义的Partitioner（默认为HashPartitioner），将原本被分配到同一个Task的不同Key分配到不同Task。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">class CustomerPartitioner(numParts:Int) extends org.apache.spark.Partitioner &#123;</span><br><span class="line"></span><br><span class="line">//覆盖分区数</span><br><span class="line"></span><br><span class="line">override def numPartitions: Int = numParts</span><br><span class="line"></span><br><span class="line">//覆盖分区号获取函数</span><br><span class="line"></span><br><span class="line">override def getPartition(key: Any): Int = &#123;</span><br><span class="line"></span><br><span class="line">val id: Int = key.toString.toInt</span><br><span class="line"></span><br><span class="line">if (id = 900000)</span><br><span class="line"></span><br><span class="line">return new java.util.Random().nextInt(100) % 12</span><br><span class="line"></span><br><span class="line">else</span><br><span class="line"></span><br><span class="line">return id % 12</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>优势</strong></p><p>​    不影响原有的并行度设计。如果改变并行度，后续Stage的并行度也会默认改变，可能会影响后续Stage。</p><p><strong>劣势</strong></p><p>​    适用场景有限，只能将不同Key分散开，对于同一Key对应数据集非常大的场景不适用。效果与调整并行度类似，只能缓解数据倾斜而不能完全消除数据倾斜。而且需要根据数据特点自定义专用的Partitioner，不够灵活。</p><h5 id><a href="#" class="headerlink" title=" "></a> </h5><h5 id="方式四"><a href="#方式四" class="headerlink" title="方式四"></a>方式四</h5><p><strong>将Reduce side Join转变为Map side Join</strong><br><strong>方案适用场景</strong>：在对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小（比如几百M或者一两G），比较适用此方案。</p><p><strong>方案优点</strong>：对join操作导致的数据倾斜，效果非常好，因为根本就不会发生shuffle，也就根本不会发生数据倾斜。</p><p><strong>方案缺点</strong>：适用场景较少，因为这个方案只适用于一个大表和一个小表的情况。毕竟我们需要将小表进行广播，此时会比较消耗内存资源，driver和每个Executor内存中都会驻留一份小RDD的全量数据。如果我们广播出去的RDD数据比较大，比如10G以上，那么就可能发生内存溢出了。因此并不适合两个都是大表的情况。</p><h5 id="方式五"><a href="#方式五" class="headerlink" title="方式五"></a><strong>方式五</strong></h5><p><strong>两阶段聚合（局部聚合+全局聚合）</strong><br><strong>方案适用场景</strong>：对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时，比较适用这种方案。</p><p>​    比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。</p><p><strong>方案优点</strong>：对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。</p><p><strong>方案缺点</strong>：仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案。</p><h5 id="方式六"><a href="#方式六" class="headerlink" title="方式六"></a>方式六</h5><p><strong>为数据倾斜的key增加随机前/后缀</strong><br><strong>原理</strong></p><p>​    为数据量特别大的Key增加随机前/后缀，使得原来Key相同的数据变为Key不相同的数据，从而使倾斜的数据集分散到不同的Task中，彻底解决数据倾斜问题。Join另一侧的数据中，与倾斜Key对应的部分数据，与随机前缀集作笛卡尔乘积，从而保证无论数据倾斜侧倾斜Key如何加前缀，都能与之正常Join。</p><p><strong>适用场景</strong></p><p>​    两张表都比较大，无法使用Map则Join。其中一个RDD有少数几个Key的数据量过大，另外一个RDD的Key分布较为均匀。</p><p><strong>解决方案</strong></p><p>​    将有数据倾斜的RDD中倾斜Key对应的数据集单独抽取出来加上随机前缀，另外一个RDD每条数据分别与随机前缀结合形成新的RDD（相当于将其数据增到到原来的N倍，N即为随机前缀的总个数），然后将二者Join并去掉前缀。然后将不包含倾斜Key的剩余数据进行Join。最后将两次Join的结果集通过union合并，即可得到全部Join结果。</p><p><strong>优势</strong></p><p>相对于Map则Join，更能适应大数据集的Join。如果资源充足，倾斜部分数据集与非倾斜部分数据集可并行进行，效率提升明显。且只针对倾斜部分的数据做数据扩展，增加的资源消耗有限。</p><p><strong>劣势</strong></p><p>如果倾斜Key非常多，则另一侧数据膨胀非常大，此方案不适用。而且此时对倾斜Key与非倾斜Key分开处理，需要扫描数据集两遍，增加了开销。</p><h5 id="方式七"><a href="#方式七" class="headerlink" title="方式七"></a>方式七</h5><p><strong>使用随机前缀和扩容RDD进行join</strong><br><strong>方案适用场景</strong>：如果在进行join操作时，RDD中有大量的key导致数据倾斜，那么进行分拆key也没什么意义，此时就只能使用最后一种方案来解决问题了。</p><p>​    将该RDD的每条数据都打上一个n以内的随机前缀。同时对另外一个正常的RDD进行扩容，将每条数据都扩容成n条数据，扩容出来的每条数据都依次打上一个0~n的前缀。</p><p><strong>方案优点</strong>：对join类型的数据倾斜基本都可以处理，而且效果也相对比较显著，性能提升效果非常不错。</p><p><strong>方案缺点</strong>：该方案更多的是缓解数据倾斜，而不是彻底避免数据倾斜。而且需要对整个RDD进行扩容，对内存资源要求很高。</p><h5 id="方式八"><a href="#方式八" class="headerlink" title="方式八"></a>方式八</h5><p><strong>采样倾斜key并分拆join操作</strong><br><strong>方案实现思路</strong>：</p><p>​    对包含少数几个数据量过大的key的那个RDD，通过sample算子采样出一份样本来，然后统计一下每个key的数量，计算出来数据量最大的是哪几个key。</p><p>​    然后将这几个key对应的数据从原来的RDD中拆分出来，形成一个单独的RDD，并给每个key都打上n以内的随机数作为前缀，而不会导致倾斜的大部分key形成另外一个RDD。</p><p>​    接着将需要join的另一个RDD，也过滤出来那几个倾斜key对应的数据并形成一个单独的RDD，将每条数据膨胀成n条数据，这n条数据都按顺序附加一个0~n的前缀，不会导致倾斜的大部分key也形成另外一个RDD。</p><p>​    再将附加了随机前缀的独立RDD与另一个膨胀n倍的独立RDD进行join，此时就可以将原先相同的key打散成n份，分散到多个task中去进行join了。而另外两个普通的RDD就照常join即可。最后将两次join的结果使用union算子合并起来即可，就是最终的join结果。</p><p><strong>方案实现原理</strong>：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，可以将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了。具体原理见下图。</p><p><strong>方案优点</strong>：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，采用该方式可以用最有效的方式打散key进行join。而且只需要针对少数倾斜key对应的数据进行扩容n倍，不需要对全量数据进行扩容。避免了占用过多内存。</p><p><strong>方案缺点</strong>：如果导致倾斜的key特别多的话，比如成千上万个key都导致数据倾斜，那么这种方式也不适合。</p><h5 id="方式九"><a href="#方式九" class="headerlink" title="方式九"></a>方式九</h5><p><strong>过滤少数导致倾斜的key</strong><br><strong>方案适用场景</strong>：如果发现导致倾斜的key就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。</p><p><strong>方案优点</strong>：实现简单，而且效果也很好，可以完全规避掉数据倾斜。</p><p><strong>方案缺点</strong>：适用场景不多，大多数情况下，导致倾斜的key还是很多的，并不是只有少数几个。</p>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> 数据倾斜 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java排序算法及稳定性</title>
      <link href="/2018/03/09/java%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%8F%8A%E7%A8%B3%E5%AE%9A%E6%80%A7/"/>
      <url>/2018/03/09/java%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%8F%8A%E7%A8%B3%E5%AE%9A%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<p>​    首先，排序算法的稳定性大家应该都知道，通俗地讲就是能保证排序前2个相等的数其在序列的前后位置顺序和排序后它们两个的前后位置顺序相同。在简单形式化一下，如果Ai = Aj，Ai原来在位置前，排序后Ai还是要在Aj位置前。</p><p>其次，说一下稳定性的好处。排序算法如果是稳定的，那么从一个键上排序，然后再从另一个键上排序，第一个键排序的结果可以为第二个键排序所用。基数排序就是这样，先按低位排序，逐次按高位排序，低位相同的元素其顺序再高位也相同时是不会改变的。另外，如果排序算法稳定，对基于比较的排序算法而言，元素交换的次数可能会少一些（个人感觉，没有证实）。</p><p>​    回到主题，现在分析一下常见的排序算法的稳定性，每个都给出简单的理由。</p><p><strong>(1)冒泡排序</strong></p><p>​    冒泡排序就是把小的元素往前调或者把大的元素往后调。比较是相邻的两个元素比较，交换也发生在这两个元素之间。所以，如果两个元素相等，我想你是不会再无聊地把他们俩交换一下的；如果两个相等的元素没有相邻，那么即使通过前面的两两交换把两个相邻起来，这时候也不会交换，所以相同元素的前后顺序并没有改变，所以冒泡排序是一种稳定排序算法。</p><p><strong>冒泡排序详细介绍，移步：</strong><a href="https://www.javazhiyin.com/go?url=http://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247483704&amp;idx=1&amp;sn=3d056587972675ba725c0ef2c2632709&amp;chksm=fc7a6c96cb0de580be5cf813443f1116a8a7c31450e36de146006933f9ffd21c60286e68bdc0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">冒泡排序</a></p><p><strong>(2)选择排序</strong></p><p>​    选择排序是给每个位置选择当前元素最小的，比如给第一个位置选择最小的，在剩余元素里面给第二个元素选择第二小的，依次类推，直到第n - 1个元素，第n个元素不用选择了，因为只剩下它一个最大的元素了。那么，在一趟选择，如果当前元素比一个元素小，而该小的元素又出现在一个和当前元素相等的元素后面，那么交换后稳定性就被破坏了。</p><p>​    比较拗口，举个例子，序列5 8 5 2 9，我们知道第一遍选择第1个元素5会和2交换，那么原序列中2个5的相对前后顺序就被破坏了，所以选择排序不是一个稳定的排序算法。</p><hr><p><strong>选择排序详细介绍，移步：</strong><a href="https://www.javazhiyin.com/go?url=http://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247483765&amp;idx=1&amp;sn=d39a77a725f6c655608639a083e8c74d&amp;chksm=fc7a6cdbcb0de5cd2bae4320b552089ade93ff6119219dd7b04af476c3ae2303ce25e63dfabc&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">选择排序</a></p><p><strong>(3)插入排序 </strong></p><p>​    插入排序是在一个已经有序的小序列的基础上，一次插入一个元素。当然，刚开始这个有序的小序列只有1个元素，就是第一个元素。比较是从有序序列的末尾开始，也就是想要插入的元素和已经有序的最大者开始比起，如果比它大则直接插入在其后面，否则一直往前找直到找到它该插入的位置。</p><p>​    如果碰见一个和插入元素相等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序就是排好序后的顺序，所以插入排序是稳定的。</p><p><strong>插入排序详细介绍，移步：</strong><a href="https://www.javazhiyin.com/go?url=http://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247483717&amp;idx=1&amp;sn=e664077a8546aff50565ab30e6979c39&amp;chksm=fc7a6cebcb0de5fdbaa3409a828f6f74235aaa59621add59d3f6dac8f84ad6df6ced2bc1e9aa&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">插入排序</a></p><p><strong>(4)快速排序 </strong></p><p>​    快速排序有两个方向，左边的i下标一直往右走，当a[i] &lt;= a[center_index]，其中center_index是中枢元素的数组下标，一般取为数组第0个元素。而右边的j下标一直往左走，当a[j] &gt; a[center_index]。如果i和j都走不动了，i &lt;= j，交换a[i]和a[j],重复上面的过程，直到i &gt; j。 交换a[j]和a[center_index]，完成一趟快速排序。</p><p>​    在中枢元素和a[j]交换的时候，很有可能把前面的元素的稳定性打乱，比如序列为5 3 3 4 3 8 9 10 11，现在中枢元素5和3（第5个元素，下标从1开始计）交换就会把元素3的稳定性打乱，所以快速排序是一个不稳定的排序算法，不稳定发生在中枢元素和a[j] 交换的时刻。</p><p><strong>快速排序详细介绍，移步：</strong><a href="https://www.javazhiyin.com/go?url=http://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247483714&amp;idx=1&amp;sn=5d352c58a48ccc96280a1333ec23c27f&amp;chksm=fc7a6ceccb0de5fa50f4305d91d8b52497e0651927f87dbf8e9863484f94963b0f4aede1d908&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">快速排序</a></p><p><strong>(5)归并排序 </strong></p><p>​    归并排序是把序列递归地分成短序列，递归出口是短序列只有1个元素（认为直接有序）或者2个序列（1次比较和交换），然后把各个有序的段序列合并成一个有序的长序列，不断合并直到原序列全部排好序。可以发现，在1个或2个元素时，1个元素不会交换，2个元素如果大小相等也没有人故意交换，这不会破坏稳定性。</p><p>​    那么，在短的有序序列合并的过程中，稳定是是否受到破坏？没有，合并过程中我们可以保证如果两个当前元素相等时，我们把处在前面的序列的元素保存在结果序列的前面，这样就保证了稳定性。所以，归并排序也是稳定的排序算法。</p><p><strong>归并排序详细介绍，移步：</strong><a href="https://www.javazhiyin.com/go?url=http://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247483773&amp;idx=1&amp;sn=bc7c4eed3f7ee8f7189ae149dd73a719&amp;chksm=fc7a6cd3cb0de5c51fa24a209dd32f6caf5cc087bc97ae0104c503b96b6360bd96ba455abd2e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">归并排序</a></p><p><strong>(6)基数排序 </strong></p><p>​    基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序，最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。基数排序基于分别排序，分别收集，所以其是稳定的排序算法。</p><p><strong>基数排序详细介绍，移步：</strong><a href="https://www.javazhiyin.com/go?url=http://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247483779&amp;idx=1&amp;sn=77c51e9542b28aae1dbe1225ebf3b424&amp;chksm=fc7a6c2dcb0de53b726262f43e18734ab5e5cc5bb02f42390cdde9605dd8a5e88cd0b3fb717d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">基数排序</a></p><p><strong>(7)希尔排序(shell) </strong></p><p>​    希尔排序是按照不同步长对元素进行插入排序，当刚开始元素很无序的时候，步长最大，所以插入排序的元素个数很少，速度很快；当元素基本有序了，步长很小， 插入排序对于有序的序列效率很高。所以，希尔排序的时间复杂度会比O(n^2)好一些。由于多次插入排序，我们知道一次插入排序是稳定的，不会改变相同元素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱，所以shell排序是不稳定的。</p><p><strong>希尔排序详细介绍，移步：</strong><a href="https://www.javazhiyin.com/go?url=http://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247483735&amp;idx=1&amp;sn=ce1ee1707dbc63f12130c30e6f81f24c&amp;chksm=fc7a6cf9cb0de5efdf8d336e75ea2434049adb3f10a7c503db8fbc82abe2abc63c38872b3da7&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">希尔排序</a></p><p><strong>(8)堆排序 </strong></p><p>​    我们知道堆的结构是节点i的孩子为2 <em> i和2 </em> i + 1节点，大顶堆要求父节点大于等于其2个子节点，小顶堆要求父节点小于等于其2个子节点。在一个长为n 的序列，堆排序的过程是从第n / 2开始和其子节点共3个值选择最大（大顶堆）或者最小（小顶堆），这3个元素之间的选择当然不会破坏稳定性。但当为n / 2 - 1， n / 2 - 2， … 1这些个父节点选择元素时，就会破坏稳定性。有可能第n / 2个父节点交换把后面一个元素交换过去了，而第n / 2 - 1个父节点把后面一个相同的元素没 有交换，那么这2个相同的元素之间的稳定性就被破坏了。所以，堆排序不是稳定的排序算法。</p><p><strong>堆排序详细介绍，移步：</strong><a href="https://www.javazhiyin.com/go?url=http://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247483782&amp;idx=1&amp;sn=7a5e25c9abce94062e0ee5d9d77bddde&amp;chksm=fc7a6c28cb0de53e591f73b352628eb4ea8660a38715596affff641aaf4ed0939ecb3f67ddb0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">堆排序</a></p><p>​    综上，得出结论: <strong>选择排序、快速排序、希尔排序、堆排序不是稳定的排序算法，而冒泡排序、插入排序、归并排序和基数排序是稳定的排序算法</strong></p><ul><li>不稳定的排序算法有：快、希、选、堆。（记忆：找到工作就可以“快些选一堆”美女来玩了（并不能））*</li></ul><p>**</p><p><img src="https://www.javazhiyin.com/wp-content/uploads/2018/05/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-1622-1532589910.jpeg" alt="彻底搞懂稳定排序与不稳定排序"></p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 排序 </tag>
            
            <tag> 稳定性 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据集成的几个工具</title>
      <link href="/2018/03/01/%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90%E7%9A%84%E5%87%A0%E4%B8%AA%E5%B7%A5%E5%85%B7/"/>
      <url>/2018/03/01/%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90%E7%9A%84%E5%87%A0%E4%B8%AA%E5%B7%A5%E5%85%B7/</url>
      
        <content type="html"><![CDATA[<p>​      常见的ETL工具或类ETL的数据集成同步工具很多，以下对开源的 Kettle、Sqoop、Datax、Streamset进行简单梳理比较。</p><h4 id="1、Kettle"><a href="#1、Kettle" class="headerlink" title="1、Kettle"></a>1、Kettle</h4><p>​       Kettle是一款国外开源的ETL工具，纯java编写，可以在Window、Linux、Unix上运行，数据抽取高效稳定。Kettle的Spoon有丰富的Steps可以组装开发出满足多种复杂应用场景的数据集成作业，方便实现全量、增量数据同步。缺点是通过定时运行，实时性相对较差。</p><p><img src="https://oscimg.oschina.net/oscnet/4c04a29ab9f2fed0ee2bc9129442e2d298e.jpg" alt="img"></p><p>免费开源:基于java的免费开源的软件，对商业用户也没有限制<br>易配置:可以在Window、Linux、Unix上运行，绿色无需安装，数据抽取高效稳定<br>不同数据库:ETL工具集，它允许你管理来自不同数据库的数据<br>两种脚本文件:transformation和job，transformation完成针对数据的基础转换，job则完成整个工作流的控制<br>图形界面设计:通过图形界面设计实现做什么业务，无需写代码去实现<br>定时功能:在Job下的start模块，有一个定时功能，可以每日，每周等方式进行定时</p><p>Kettle家族目前包括4个产品：Spoon、Pan、CHEF、Kitchen。<br>SPOON:允许你通过图形界面来设计ETL转换过程（Transformation）<br>PAN:允许你批量运行由Spoon设计的ETL转换 (例如使用一个时间调度器)。Pan是一个后台执行的程序，没有图形界面<br>CHEF:允许你创建任务（Job）。 任务通过允许每个转换，任务，脚本等等，更有利于自动化更新数据仓库的复杂工作。任务通过允许每个转换，任务，脚本等等。任务将会被检查，看看是否正确地运行了<br>KITCHEN:允许你批量使用由Chef设计的任务 (例如使用一个时间调度器)。KITCHEN也是一个后台运行的程序</p><h4 id="2、Sqoop"><a href="#2、Sqoop" class="headerlink" title="2、Sqoop"></a>2、Sqoop</h4><p>​        Sqoop是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql…)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。Sqoop专为大数据批量传输设计，能够分割数据集并创建Hadoop任务来处理每个区块。通过导入导出命令加配套参数控制操作。</p><p><img src="https://oscimg.oschina.net/oscnet/3da97bc126bb8dd6407277d825f38833451.jpg" alt="img"></p><p>Sqoop导入：导入工具从RDBMS到HDFS导入单个表。表中的每一行被视为HDFS的记录。所有记录被存储在文本文件的文本数据或者在Avro和序列文件的二进制数据。<br>Sqoop导出：导出工具从HDFS导出一组文件到一个RDBMS。作为输入到Sqoop文件包含记录，这被称为在表中的行。那些被读取并解析成一组记录和分隔使用用户指定的分隔符。     </p><p>Sqoop支持全量数据导入和增量数据导入（增量数据导入分两种，一是基于递增列的增量数据导入（Append方式）。二是基于时间列的增量数据导入（LastModified方式）），同时可以指定数据是否以并发形式导入。</p><p>Append方式</p><p><img src="https://oscimg.oschina.net/oscnet/0f67deab172b8b39871a2842541c9252757.jpg" alt="img"></p><p>lastModify方式</p><p><img src="https://oscimg.oschina.net/oscnet/48c2d264f75082d25634a9ea54f9d4eeac9.jpg" alt="img"></p><h4 id="3、DataX"><a href="#3、DataX" class="headerlink" title="3、DataX"></a>3、DataX</h4><p>DataX 是阿里巴巴集团内被广泛使用的离线数据同步工具/平台，实现包括 MySQL、Oracle、HDFS、Hive、OceanBase、HBase、OTS、ODPS 等各种异构数据源之间高效的数据同步功能。DataX采用了框架 + 插件 的模式，目前已开源，代码托管在github。从应用的模式，DataX更适合ELT模式。</p><p>操作简单通常只需要两步<br>创建作业的配置文件（json格式配置reader,writer）<br>启动执行配置作业</p><p><img src="https://oscimg.oschina.net/oscnet/ac6588e3a1e0b412c1b0e8db9158c72d4b8.jpg" alt="img"></p><p>Job:一道数据同步作业Splitter:作业切分模块,将一个大任务与分解成多个可以并发的小任务.Sub-job:数据同步作业切分后的小任务Reader(Loader):数据读入模块,负责运行切分后的小任务,将数据从源头装载入DataXStorage:Reader和Writer通过Storage交换数据Writer(Dumper):数据写出模块,负责将数据从DataX导入至目的数据地 DataX框架内部通过双缓冲队列、线程池封装等技术,集中处理了高速数据交换遇到的问题,提供简单的接口与插件交互,插件分为Reader和Writer两类,基于框架提供的插件接口,可以十分便捷的开发出需要的插件。</p><p>缺乏对增量更新的内置支持，因为DataX的灵活架构，可以通过shell脚本等方式方便实现增量同步。</p><h4 id="4、StreamSets"><a href="#4、StreamSets" class="headerlink" title="4、StreamSets"></a>4、StreamSets</h4><p>StreamSets 数据收集器是一个轻量级，强大的引擎，实时流数据。使用Data Collector在数据流中路由和处理数据。<br>要为Data Collector定义数据流，请配置管道。一个流水线由代表流水线起点和终点的阶段以及您想要执行的任何附加处理组成。配置管道后，单击“开始”，“ 数据收集器”开始工作。<br>Data Collector在数据到达原点时处理数据，在不需要时静静地等待。您可以查看有关数据的实时统计信息，在数据通过管道时检查数据，或仔细查看数据快照。</p><p><img src="https://oscimg.oschina.net/oscnet/1a4ed8e88cbe7ebcd319dc73af65d68e901.jpg" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kettle </tag>
            
            <tag> datax </tag>
            
            <tag> sqoop </tag>
            
            <tag> streamset </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Springboot整合log4j2并将日志发送到flume</title>
      <link href="/2018/02/04/Springboot%E6%95%B4%E5%90%88log4j2%E5%B9%B6%E5%B0%86%E6%97%A5%E5%BF%97%E5%8F%91%E9%80%81%E5%88%B0flume/"/>
      <url>/2018/02/04/Springboot%E6%95%B4%E5%90%88log4j2%E5%B9%B6%E5%B0%86%E6%97%A5%E5%BF%97%E5%8F%91%E9%80%81%E5%88%B0flume/</url>
      
        <content type="html"><![CDATA[<p>首先pom文件中增加log4j2</p><pre><code>&lt;dependency&gt;&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;  &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>要在springboot启动的时候就强制使用log4j2，需要排除默认的日志：</p><pre><code>&lt;dependency&gt;  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;  &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;  &lt;exclusions&gt;    &lt;exclusion&gt;       &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;    &lt;/exclusion&gt;  &lt;/exclusions&gt;&lt;/dependency&gt;</code></pre><p>然后在resource下增加log4j2的配置文件log4j2.xml.</p><p>然后在默认配置文件application.properties中指定一下log4j2的配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logging.config=classpath:log4j2.xml</span><br></pre></td></tr></table></figure><p>这里需要注意一下，按照官方文档的说法，是会自动发现日志的配置文件的，在开发调试过程中也确实是这样。但是如果要打成war包部署到tomcat中，而且是linux下的tomcat。就会有问题，手动指定一下才会生效。如果只是打jar包通过main方法启动是没有问题的。</p><p>至此springboot整合log4j2就基本完成了。</p><p>然后在log4j2中配置flume</p><p>还是从pom文件开始：</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;  &lt;artifactId&gt;log4j-flume-ng&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.flume&lt;/groupId&gt;  &lt;artifactId&gt;flume-ng-embedded-agent&lt;/artifactId&gt;  &lt;version&gt;1.7.0&lt;/version&gt;  &lt;exclusions&gt;      &lt;exclusion&gt;          &lt;groupId&gt;org.slf4j&lt;/groupId&gt;          &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;      &lt;/exclusion&gt;      &lt;exclusion&gt;          &lt;groupId&gt;org.slf4j&lt;/groupId&gt;          &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;      &lt;/exclusion&gt;      &lt;exclusion&gt;          &lt;groupId&gt;log4j&lt;/groupId&gt;          &lt;artifactId&gt;log4j&lt;/artifactId&gt;      &lt;/exclusion&gt;  &lt;/exclusions&gt;&lt;/dependency&gt;</code></pre><p>log4j2支持的flume是embedded模式的，所以加入flume-ng-embedded-agent</p><p>然后log4j2的配置文件中加入flumeAppend</p><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;WARN&quot;&gt;  &lt;Appenders&gt;&lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt;  &lt;PatternLayout pattern=&quot;%d{yyyy-MM-dd HH:mm:ss SSS} [myapp] %m%n&quot;/&gt;&lt;/Console&gt;&lt;Flume name=&quot;FlumeAppender&quot; compress=&quot;false&quot; type=&quot;Embedded&quot; &gt;  &lt;Property name=&quot;channel.type&quot;&gt;memory&lt;/Property&gt;  &lt;Property name=&quot;channel.capacity&quot;&gt;200&lt;/Property&gt;  &lt;Property name=&quot;sinks&quot;&gt;agent1&lt;/Property&gt;  &lt;Property name=&quot;agent1.type&quot;&gt;avro&lt;/Property&gt;  &lt;Property name=&quot;agent1.hostname&quot;&gt;192.168.0.100&lt;/Property&gt;  &lt;Property name=&quot;agent1.port&quot;&gt;44444&lt;/Property&gt;  &lt;Property name=&quot;agent1.batch-size&quot;&gt;100&lt;/Property&gt;  &lt;Property name=&quot;processor.type&quot;&gt;failover&lt;/Property&gt;  &lt;PatternLayout charset=&quot;UTF-8&quot; pattern=&quot;%d{yyyy-MM-dd HH:mm:ss SSS} [myapp] %m%n&quot; /&gt;&lt;/Flume&gt;  &lt;/Appenders&gt;  &lt;Loggers&gt;&lt;Logger name=&quot;sysLog&quot; level=&quot;trace&quot;&gt;  &lt;AppenderRef ref=&quot;FlumeAppender&quot;/&gt;&lt;/Logger&gt;&lt;Root level=&quot;info&quot;&gt;  &lt;AppenderRef ref=&quot;Console&quot;/&gt;&lt;/Root&gt;  &lt;/Loggers&gt;&lt;/Configuration&gt;</code></pre><p>好了，结束！</p>]]></content>
      
      
      <categories>
          
          <category> flume </category>
          
      </categories>
      
      
        <tags>
            
            <tag> springboot </tag>
            
            <tag> log4j </tag>
            
            <tag> flume </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>sparksql处理小文件</title>
      <link href="/2017/09/03/sparksql%E5%A4%84%E7%90%86%E5%B0%8F%E6%96%87%E4%BB%B6/"/>
      <url>/2017/09/03/sparksql%E5%A4%84%E7%90%86%E5%B0%8F%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h4 id="spark处理方式一："><a href="#spark处理方式一：" class="headerlink" title="spark处理方式一："></a>spark处理方式一：</h4><p>val value: RDD[(Text, Text)] = sc.newAPIHadoopFile[Text,Text,CombineTextInputFormat](“hdfs://localhost:9000/test/hadoopkv1”)</p><h4 id="spark处理方式二："><a href="#spark处理方式二：" class="headerlink" title="spark处理方式二："></a>spark处理方式二：</h4><p>var hadoopConf = new Configuration()<br>hadoopConf.set(“mapreduce.input.fileinputformat.split.maxsize”, “512000000”)<br>hadoopConf.set(“mapreduce.input.fileinputformat.split.minsize”, “268435456”)<br>hadoopConf.set(“mapreduce.input.fileinputformat.split.minsize.per.node”, “134217728”)   //下面这两参数可以不设置，详情看文章末尾<br>hadoopConf.set(“mapreduce.input.fileinputformat.split.minsize.per.rack”, “268435456”)</p><p>val data = sc.newAPIHadoopFile(args(1),<br>  classOf[CombineTextInputFormat],<br>  classOf[LongWritable],<br>  classOf[Text], hadoopConf)</p><h4 id="hive处理小文件："><a href="#hive处理小文件：" class="headerlink" title="hive处理小文件："></a>hive处理小文件：</h4><p>sparksession.sqlContext.setConf(“hive.merge.mapfiles”,”true”)<br>sparksession.sqlContext.setConf(“mapred.max.split.size”,”256000000”)<br>sparksession.sqlContext.setConf(“mapred.min.split.size.per.node”,”192000000”)<br>sparksession.sqlContext.setConf(“mapred.min.split.size.per.rack”,”192000000”)<br>sparksession.sqlContext.setConf(“hive.input.format”,”org.apache.hadoop.hive.ql.io.CombineHiveInputFormat”)</p>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> sparksql </tag>
            
            <tag> 小文件 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql之count</title>
      <link href="/2017/06/01/mysql%E4%B9%8Bcount/"/>
      <url>/2017/06/01/mysql%E4%B9%8Bcount/</url>
      
        <content type="html"><![CDATA[<h2 id="一、测试"><a href="#一、测试" class="headerlink" title="一、测试"></a>一、测试</h2><p>测试表：InnoDB 引擎</p><p>网上有种说法count(1)比count(*)快！我看了下他们的测试，发现有很大问题！ </p><p>第一次测试时时间耗费较多，而下面再测试时耗时很少，这是由于<strong>数据库缓存</strong>的原因！但居然有人把这作为结论表示count(*)效率不行也是奇葩。此处测试多次，发现两者耗时几乎相同！</p><p>下面继续看执行计划： </p><p>发现执行计划一模一样，所以<strong>我们确定count(*)和count(1)的效率是一样</strong>的！</p><p><strong>注意：count(1)并不是值count(第一个字段)！</strong></p><p><strong>mysql底层对count(*)有优化，会选择最有效率的方式去执行count操作</strong>，两者没有性能差异，效率都比较高。</p><p>测试count(列)：</p><p>在比较 count(*)/count(1) 和 count(列) 的效率时，要注意两者本质的区别不是效率！</p><p><strong>count(*) /count(1)将返回表格中所有存在的行的总数包括值为 null 的行，然而 count(列名) 将返回表格中除去 null 以外的所有行的总数 (有默认值的列也会被计入)</strong>，这点对于所有数据的 COUNT 计算都是一样的!</p><p>所以先要明确这一点！再看效率测试，我们可以发现除了count(id)主键 比较快之外，其他列的无论是否建索引，速度都慢于count(*)，有人得出这个结论：列的偏移量决定性能，列越靠后，访问的开销越大，这个我目前的测试还不能确定。</p><h2 id="二、结论"><a href="#二、结论" class="headerlink" title="二、结论"></a>二、结论</h2><p>InnoDB引擎下：</p><p>1.count(*)和count(1)的效率是一样的！两者没有性能差异！<br>如果表存在主键，他们都是根据主键去count的，速度都较快；如果不存在主键，则速度都较慢！</p><p>2.count(1) /count(<em>)会统计表中的所有的记录数，包含字段为null 的记录；<br>count(列名) 会统计该字段在表中出现的次数，不统计字段为null 的记录。<br>且在效率方面count(非主键列)的效率往往低于count(</em>)/count(1) ！count(主键列)效率差不多！</p>]]></content>
      
      
      <categories>
          
          <category> mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
            <tag> sql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hadoop1.x与hadoop2.x的区别</title>
      <link href="/2017/03/11/hadoop1-x%E4%B8%8Ehadoop2-x%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
      <url>/2017/03/11/hadoop1-x%E4%B8%8Ehadoop2-x%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<p>​    （1）Hadoop 1.0Hadoop 1.0即第一代Hadoop，由分布式存储系统HDFS和分布式计算框架MapReduce组成，其中，HDFS由一个NameNode和多个DataNode组成，MapReduce由一个JobTracker和多个TaskTracker组成，对应Hadoop版本为Apache Hadoop 0.20.x、1.x、0.21.X、0.22.x和CDH3。</p><p>​    （2）Hadoop 2.0Hadoop 2.0即第二代Hadoop，为克服Hadoop 1.0中HDFS和MapReduce存在的各种问题而提出的。针对Hadoop 1.0中的单NameNode制约HDFS的扩展性问题，提出了HDFS Federation，它让多个NameNode分管不同的目录进而实现访问隔离和横向扩展，同时它彻底解决了NameNode 单点故障问题；针对Hadoop 1.0中的MapReduce在扩展性和多框架支持等方面的不足，它将JobTracker中的资源管理和作业控制功能分开，分别由组件ResourceManager和ApplicationMaster实现，其中，ResourceManager负责所有应用程序的资源分配，而ApplicationMaster仅负责管理一个应用程序，进而诞生了全新的通用资源管理框架YARN。基于YARN，用户可以运行各种类型的应用程序（不再像1.0那样仅局限于MapReduce一类应用），从离线计算的MapReduce到在线计算（流式处理）的Storm等。Hadoop 2.0对应Hadoop版本为Apache Hadoop 0.23.x、2.x和CDH4。</p><p>​    （3）MapReduce 1.0或MRv1MapReduce 1.0计算框架主要由三部分组成，分别是编程模型、数据处理引擎和运行时环境。它的基本编程模型是将问题抽象成Map和Reduce两个阶段，其中Map阶段将输入数据解析成key/value，迭代调用map()函数处理后，再以key/value的形式输出到本地目录，而Reduce阶段则将key相同的value进行规约处理，并将最终结果写到HDFS上；它的数据处理引擎由MapTask和ReduceTask组成，分别负责Map阶段逻辑和Reduce阶段逻辑的处理；它的运行时环境由（一个）JobTracker和（若干个）TaskTracker两类服务组成，其中，JobTracker负责资源管理和所有作业的控制，而TaskTracker负责接收来自JobTracker的命令并执行它。该框架在扩展性、容错性和多框架支持等方面存在不足，这也促使了MRv2的产生。</p><p>​    （4）MRv2MRv2具有与MRv1相同的编程模型和数据处理引擎，唯一不同的是运行时环境。MRv2是在MRv1基础上经加工之后，运行于资源管理框架YARN之上的计算框架MapReduce。它的运行时环境不再由JobTracker和TaskTracker等服务组成，而是变为通用资源管理系统YARN和作业控制进程ApplicationMaster，其中，YARN负责资源管理和调度，而ApplicationMaster仅负责一个作业的管理。简言之，MRv1仅是一个独立的离线计算框架，而MRv2则是运行于YARN之上的MapReduce。</p><p>​    （5）YARNYARN是Hadoop 2.0中的资源管理系统，它是一个通用的资源管理模块，可为各类应用程序进行资源管理和调度。YARN不仅限于MapReduce一种框架使用，也可以供其他框架使用，比如Tez（将在第9章介绍）、Spark、Storm（将在第10章介绍）等。YARN类似于几年前的资源管理系统Mesos（将在12章介绍）和更早的Torque（将在6章介绍）。由于YARN的通用性，下一代MapReduce的核心已经从简单的支持单一应用的计算框架MapReduce转移到通用的资源管理系统YARN。</p><p>​    （6）HDFS FederationHadoop 2.0中对HDFS进行了改进，使NameNode可以横向扩展成多个，每个NameNode分管一部分目录，进而产生了HDFS Federation，该机制的引入不仅增强了HDFS的扩展性，也使HDFS具备了隔离性。</p>]]></content>
      
      
      <categories>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> bigdata </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scala 集合转换 java集合</title>
      <link href="/2017/02/14/scala-%E9%9B%86%E5%90%88%E8%BD%AC%E6%8D%A2-java%E9%9B%86%E5%90%88/"/>
      <url>/2017/02/14/scala-%E9%9B%86%E5%90%88%E8%BD%AC%E6%8D%A2-java%E9%9B%86%E5%90%88/</url>
      
        <content type="html"><![CDATA[<p>使用 scala.collection.JavaConverters 与Java集合交互。它有一系列的隐式转换，添加了asJava和asScala的转换方法。使用它们这些方法确保转换是显式的，有助于阅读：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import scala.collection.JavaConverters._</span><br><span class="line"></span><br><span class="line">val list: java.util.List[Int] = Seq(1,2,3,4).asJava</span><br><span class="line">val buffer: scala.collection.mutable.Buffer[Int] = list.asScala</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> scala </tag>
            
            <tag> 集合 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark通信架构</title>
      <link href="/2017/01/23/Spark%E9%80%9A%E4%BF%A1%E6%9E%B6%E6%9E%84/"/>
      <url>/2017/01/23/Spark%E9%80%9A%E4%BF%A1%E6%9E%B6%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<ul><li>Spark一开始使用 Akka 作为内部通信部件。<ul><li>在Spark 1.3年代，为了解决大块数据（如Shuffle）的传输问题，Spark引入了Netty通信框架。到了 Spark 1.6, Spark可以配置使用 Akka 或者 Netty 了，这意味着 Netty 可以完全替代 Akka了。再到 Spark 2, Spark 已经完全抛弃 Akka了，全部使用Netty了。</li></ul></li><li>为什么呢？官方的解释是：<ul><li>很多Spark用户也使用Akka，但是由于Akka不同版本之间无法互相通信，这就要求用户必须使用跟Spark完全一样的Akka版本，导致用户无法升级Akka。</li><li>Spark的Akka配置是针对Spark自身来调优的，可能跟用户自己代码中的Akka配置冲突。</li><li>Spark用的Akka特性很少，这部分特性很容易自己实现。同时，这部分代码量相比Akka来说少很多，debug比较容易。如果遇到什么bug，也可以自己马上fix，不需要等Akka上游发布新版本。而且，Spark升级Akka本身又因为第一点会强制要求用户升级他们使用的Akka，对于某些用户来说是不现实的。</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> 通信 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark on yarn</title>
      <link href="/2017/01/13/spark-on-yarn/"/>
      <url>/2017/01/13/spark-on-yarn/</url>
      
        <content type="html"><![CDATA[<p>​    Spark在yarn集群上的部署方式分为两种，yarn client（driver运行在客户端）和yarn cluster（driver运行在master上）</p><h4 id="1、driver-on-master。"><a href="#1、driver-on-master。" class="headerlink" title="1、driver on master。"></a>1、driver on master。</h4><p>​    <strong>(1)</strong> Spark Yarn Client向YARN中提交应用程序，包括Application Master程序、启动Application Master的命令、需要在Executor中运行的程序等；</p><p>​    <strong>(2)</strong> Resource manager收到请求后，在其中一个node manager中为应用程序分配一个container，要求它在container中启动应用程序的Application Master，Application master初始化sparkContext以及创建DAG Scheduler和Task Scheduler。</p><p>​    <strong>(3)</strong> Application master根据sparkContext中的配置，向resource manager申请container，同时，Application master向Resource manager注册，这样用户可通过Resource manager查看应用程序的运行状态</p><p>​    <strong>(4)</strong> Resource manager 在集群中寻找符合条件的node manager，在node manager启动container，要求container启动executor，</p><p>​    <strong>(5)</strong> Executor启动后向Application master注册，并接收Application master分配的task</p><p>​    <strong>(6)</strong> 应用程序运行完成后，Application Master向Resource Manager申请注销并关闭自己。</p><h4 id="2、Driver-on-client"><a href="#2、Driver-on-client" class="headerlink" title="2、Driver on client"></a>2、Driver on client</h4><p>​    <strong>(1)</strong> Spark Yarn Client向YARN的Resource Manager申请启动Application Master。同时在SparkContent初始化中将创建DAG Scheduler和TASK Scheduler等</p><p>​    <strong>(2)</strong> ResourceManager收到请求后，在集群中选择一个NodeManager，为该应用程序分配第一个Container，要求它在这个Container中启动应用程序的ApplicationMaster，与YARN-Cluster区别的是在该ApplicationMaster不运行SparkContext，只与SparkContext进行联系进行资源的分派</p><p>​    <strong>(3)</strong> Client中的SparkContext初始化完毕后，与Application Master建立通讯，向Resource Manager注册，根据任务信息向Resource Manager申请资源(Container)</p><p>​    <strong>(4)</strong> 当application master申请到资源后，便与node manager通信，要求它启动container</p><p>​    <strong>(5)</strong> Container启动后向driver中的sparkContext注册，并申请task</p><p>​    <strong>(6)</strong> 应用程序运行完成后，Client的SparkContext向ResourceManager申请注销并关闭自己。</p><h4 id="3、两种方式的区别"><a href="#3、两种方式的区别" class="headerlink" title="3、两种方式的区别"></a>3、两种方式的区别</h4><p>​    Yarn-client和Yarn cluster模式对比可以看出，在Yarn-client（Driver on client）中，Application Master仅仅从Yarn中申请资源给Executor，之后client会跟container通信进行作业的调度。如果client离集群距离较远，建议不要采用此方式，不过此方式有利于交互式的作业。</p>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> yarn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark的Shuffle过程介绍</title>
      <link href="/2017/01/02/spark%E7%9A%84Shuffle%E8%BF%87%E7%A8%8B%E4%BB%8B%E7%BB%8D/"/>
      <url>/2017/01/02/spark%E7%9A%84Shuffle%E8%BF%87%E7%A8%8B%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h4 id="HashShuffle过程介绍"><a href="#HashShuffle过程介绍" class="headerlink" title="HashShuffle过程介绍"></a>HashShuffle过程介绍</h4><p>​    Spark丰富了任务类型，有些任务之间数据流转不需要通过Shuffle，但是有些任务之间还是需要通过Shuffle来传递数据，比如wide dependency的group by key。</p><p>​    Spark中需要Shuffle输出的Map任务会为每个Reduce创建对应的bucket，Map产生的结果会根据设置的partitioner得到对应的bucketId，然后填充到相应的bucket中去。每个Map的输出结果可能包含所有的Reduce所需要的数据，所以每个Map会创建R个bucket（R是reduce的个数），M个Map总共会创建M*R个bucket。</p><p>​    Map创建的bucket其实对应磁盘上的一个文件，Map的结果写到每个bucket中其实就是写到那个磁盘文件中，这个文件也被称为blockFile，是Disk Block Manager管理器通过文件名的Hash值对应到本地目录的子目录中创建的。每个Map要在节点上创建R个磁盘文件用于结果输出，Map的结果是直接输出到磁盘文件上的，100KB的内存缓冲是用来创建Fast Buffered OutputStream输出流。这种方式一个问题就是Shuffle文件过多。</p><pre><code>每一个Mapper创建出和Reducer数目相同的bucket，bucket实际上是一个buffer，其大小为shuffle.file.buffer.kb（默认32KB）。</code></pre><p>Mapper产生的结果会根据设置的partition算法填充到每个bucket中去，然后再写入到磁盘文件。<br>Reducer从远端或是本地的block manager中找到相应的文件读取数据。</p><p>​    针对上述Shuffle过程产生的文件过多问题，Spark有另外一种改进的Shuffle过程：consolidation Shuffle，以期显著减少Shuffle文件的数量。在consolidation Shuffle中每个bucket并非对应一个文件，而是对应文件中的一个segment部分。Job的map在某个节点上第一次执行，为每个reduce创建bucket对应的输出文件，把这些文件组织成ShuffleFileGroup，当这次map执行完之后，这个ShuffleFileGroup可以释放为下次循环利用；当又有map在这个节点上执行时，不需要创建新的bucket文件，而是在上次的ShuffleFileGroup中取得已经创建的文件继续追加写一个segment；当前次map还没执行完，ShuffleFileGroup还没有释放，这时如果有新的map在这个节点上执行，无法循环利用这个ShuffleFileGroup，而是只能创建新的bucket文件组成新的ShuffleFileGroup来写输出。</p><p><strong>优点</strong></p><pre><code>1、快-不需要排序，也不需要维持hash表2、不需要额外空间用作排序3、不需要额外IO-数据写入磁盘只需一次，读取也只需一次</code></pre><p><strong>缺点</strong></p><pre><code>1、当partitions大时，输出大量的文件（cores * R）,性能开始降低2、大量的文件写入，使文件系统开始变为随机写，性能比顺序写要降低100倍3、缓存空间占用比较大</code></pre><h4 id="SortShuffle过程介绍"><a href="#SortShuffle过程介绍" class="headerlink" title="SortShuffle过程介绍"></a>SortShuffle过程介绍</h4><p>​    从1.2.0开始默认为sort shuffle(spark.shuffle.manager= sort)，实现逻辑类似于Hadoop MapReduce，Hash Shuffle每一个reducers产生一个文件，但是Sort Shuffle只是产生一个按照reducer id排序可索引的文件，这样，只需获取有关文件中的相关数据块的位置信息，并fseek就可以读取指定reducer的数据。但对于rueducer数比较少的情况，Hash Shuffle明显要比Sort Shuffle快，因此Sort Shuffle有个“fallback”计划，对于reducers数少于 “spark.shuffle.sort.bypassMergeThreshold” (200 by default)，我们使用fallback计划，hashing相关数据到分开的文件，然后合并这些文件为一个，具体实现为BypassMergeSortShuffleWriter。</p><p>​    在map进行排序，在reduce端应用Timsort[1]进行合并。map端是否容许spill，通过spark.shuffle.spill来设置，默认是true。设置为false，如果没有足够的内存来存储map的输出，那么就会导致OOM错误，因此要慎用。</p><p>​    spark使用AppendOnlyMap存储map输出的数据，利用开源hash函数MurmurHash3和平方探测法把key和value保存在相同的array中。这种保存方法可以是spark进行combine。如果spill为true，会在spill前sort。</p><p>​    与hash shuffle相比，sort shuffle中每个Mapper只产生一个数据文件和一个索引文件，数据文件中的数据按照Reducer排序，但属于同一个Reducer的数据不排序。Mapper产生的数据先放到AppendOnlyMap这个数据结构中，如果内存不够，数据则会spill到磁盘，最后合并成一个文件。<br>与Hash shuffle相比，shuffle文件数量减少，内存使用更加可控。但排序会影响速度。</p><p><strong>优点</strong></p><pre><code>1 map创建文件量较少2 少量的IO随机操作，大部分是顺序读写</code></pre><p><strong>缺点</strong></p><pre><code>1 要比Hash Shuffle要慢，需要自己通过shuffle.sort.bypassMergeThreshold来设置合适的值。2 如果使用SSD盘存储shuffle数据，那么Hash Shuffle可能更合适。</code></pre>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> shuffle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>maven 本地安装jar包</title>
      <link href="/2016/09/30/maven-%E6%9C%AC%E5%9C%B0%E5%AE%89%E8%A3%85jar%E5%8C%85/"/>
      <url>/2016/09/30/maven-%E6%9C%AC%E5%9C%B0%E5%AE%89%E8%A3%85jar%E5%8C%85/</url>
      
        <content type="html"><![CDATA[<p>做项目发现本地安装不了某个jar包，cmd中手动安装了下，相关命令做一下记录。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn install:install-file -Dfile=&quot;E:\kie-spring-6.5.0.Final.jar&quot; -DgroupId=org.kie -DartifactId=kie-spring -Dversion=6.5.0.Final -Dpackaging=jar</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> maven </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GC 日志分析</title>
      <link href="/2016/09/21/GC-%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"/>
      <url>/2016/09/21/GC-%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>​    2017-07-20T16:32:19.836+0800: 1216.559: [GC pause (G1 Evacuation Pause) (young), 0.0797857 secs]<br>​    这是最顶层的信息，它告诉我们这是一个从进程启动后1216.559秒开始的一个疏散暂停，在这时年轻代所有的区域被疏散，如Eden和Survivor。这次收集用了0.0797857秒完成的。</p><p>[Parallel Time: 58.5 ms, GC Workers: 8]<br>并行时间是所有并行GC工作线程所花费的总时间</p><p>[GC Worker Start (ms): Min: 1216567.9, Avg: 1216568.1, Max: 1216568.4, Diff: 0.5]<br>所有工作线程的平均、最小、最大和差异时间</p><p>……</p><p>[Eden: 180.0M(180.0M)-&gt;0.0B(178.0M) Survivors: 26.0M-&gt;16.0M Heap: 432.5M(512.0M)-&gt;262.5M(512.0M)]<br>这显示了Eden占用了180M，在收集前它的容量也是180M。收集之后，它的容量降到了0，自所有对象从Eden区疏散/晋升后。它的目标大小增长到了178M,<br>Survivors收集之后Survivor从26M变到16M，<br>Heap堆空间总占有量和总容量分别是432M和512M回收之前，回收之后分别变为262和512M。</p>]]></content>
      
      
      <categories>
          
          <category> jvm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jvm </tag>
            
            <tag> GC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA -Xms -Xmx -XX:PermSize -XX:MaxPermSize 区别</title>
      <link href="/2016/08/06/JAVA-Xms-Xmx-XX-PermSize-XX-MaxPermSize-%E5%8C%BA%E5%88%AB/"/>
      <url>/2016/08/06/JAVA-Xms-Xmx-XX-PermSize-XX-MaxPermSize-%E5%8C%BA%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h4 id="1、参数设置背景"><a href="#1、参数设置背景" class="headerlink" title="1、参数设置背景"></a>1、参数设置背景</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在做java开发时尤其是大型软件开发时经常会遇到内存溢出的问题，比如说OutOfMemoryError等。这是个让开发人员很痛苦、也很纠结的问题，因为我们有时不知道什么样的操作导致了这种问题的发生。所以我们不得不通过不断的审查、优化自己的代码结构。但是有时我们会发现有些时候不单单是通过重构自身的代码就能够解决这样的问题，因为也可能是由于我们对java虚拟机运行时的内存分配的不得当导致了内存溢出现象的不断发生。</span><br><span class="line"></span><br><span class="line">为了解决这一问题，java开发团队提供了一个用户自定义的方式按需配置java虚拟机运行时的所需的内存——通过参数配置的形式实现参数分配自定义化。</span><br></pre></td></tr></table></figure><h4 id="2、JVM按照其存储数据的内容将所需内存分配为堆区与非堆区两个部分："><a href="#2、JVM按照其存储数据的内容将所需内存分配为堆区与非堆区两个部分：" class="headerlink" title="2、JVM按照其存储数据的内容将所需内存分配为堆区与非堆区两个部分："></a>2、JVM按照其存储数据的内容将所需内存分配为堆区与非堆区两个部分：</h4><pre><code>堆区即为通过new的方式创建的对象（类实例）所占用的内存空间，非堆区即为代码、常量、外部访问（如文件访问流所占资源）等</code></pre><p>​    虽然java的垃圾回收机制虽然能够很好的解决内存浪费的问题，但是这种机制也仅仅的是回收堆区的资源，而对于非堆区的资源就束手无策了，针对这样的资源回收只能凭借开发人员自身的约束来解决。就算是这样（堆区有java回收机制、非堆区开发人员能够很好的解决），当运行时所需内存瞬间激增的时候JVM无奈的也要中止程序的运行。所以本文讲述的是如何解决后者的问题。<br>常见参数种类（配置内存）</p><pre><code>配置堆区：-Xms 、-Xmx、-XX:newSize、-XX:MaxnewSize、-Xmn配置非堆区：-XX:PermSize、-XX:MaxPermSize</code></pre><h5 id="2-1、堆区参数配置"><a href="#2-1、堆区参数配置" class="headerlink" title="2.1、堆区参数配置"></a>2.1、堆区参数配置</h5><ul><li>2.11、-Xms ：表示java虚拟机堆区内存初始内存分配的大小，通常为操作系统可用内存的1/64大小即可，但仍需按照实际情况进行分配。有可能真的按照这样的一个规则分配时，设计出的软件还没有能够运行得起来就挂了。</li><li><p>2.12、-Xmx： 表示java虚拟机堆区内存可被分配的最大上限，通常为操作系统可用内存的1/4大小。但是开发过程中，通常会将 -Xms 与 -Xmx两个参数的配置相同的值，其目的是为了能够在java垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小而浪费资源。</p><p>  一般来讲对于堆区的内存分配只需要对上述两个参数进行合理配置即可。</p></li></ul><h5 id="2-2、非堆区参数配置"><a href="#2-2、非堆区参数配置" class="headerlink" title="2.2、非堆区参数配置"></a>2.2、非堆区参数配置</h5><ul><li>1、-XX:PermSize：表示非堆区初始内存分配大小，其缩写为permanent size（持久化内存）</li><li>2、-XX:MaxPermSize：表示对非堆区分配的内存的最大上限<ul><li>注：在配置之前一定要慎重的考虑一下自身软件所需要的非堆区内存大小，因为此处内存是不会被java垃圾回收机制进行处理的地方。并且更加要注意的是 最大堆内存与最大非堆内存的和绝对不能够超出操作系统的可用内存。</li></ul></li></ul><h4 id="3、jvm-参数配置"><a href="#3、jvm-参数配置" class="headerlink" title="3、jvm 参数配置"></a>3、jvm 参数配置</h4><ul><li><p>1、-Xms：表示java虚拟机堆区内存初始内存分配的大小，通常为操作系统可用内存的1/64大小即可，但仍需按照实际情况进行分配。</p></li><li><p>2、-Xmx：表示java虚拟机堆区内存可被分配的最大上限，通常为操作系统可用内存的1/4大小。</p><ul><li>开发过程中，通常会将-Xms 与-Xmx两个参数的配置相同的值，其目的是为了能够在java垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小而浪费资源。</li></ul><p>1、-XX:newSize：表示新生代初始内存的大小，应该小于-Xms的值；<br>2、-XX:MaxnewSize：表示新生代可被分配的内存的最大上限；当然这个值应该小于-Xmx的值；<br>3、-Xmn：至于这个参数则是对 -XX:newSize、-XX:MaxnewSize两个参数的同时配置，也就是说如果通过-Xmn来配置新生代的内存大小，那么-XX:newSize = -XX:MaxnewSize　=　-Xmn，虽然会很方便，但需要注意的是这个参数是在JDK1.4版本以后才使用的。</p></li></ul><h5 id="3-1、java虚拟机对非堆区内存配置的两个参数："><a href="#3-1、java虚拟机对非堆区内存配置的两个参数：" class="headerlink" title="3.1、java虚拟机对非堆区内存配置的两个参数："></a>3.1、java虚拟机对非堆区内存配置的两个参数：</h5><p>​    1、-XX:PermSize：表示非堆区初始内存分配大小（方法区）<br>​    2、-XX:MaxPermSize：表示对非堆区分配的内存的最大上限（方法区）。</p><p>​    在配置之前一定要慎重的考虑一下自身软件所需要的非堆区内存大小，因为此处内存是不会被java垃圾回收机制进行处理的地方。并且更加要注意的是最大堆内存与最大非堆内存的和绝对不能够超出操作系统的可用内存。</p>]]></content>
      
      
      <categories>
          
          <category> jvm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GC </tag>
            
            <tag> JAVA </tag>
            
            <tag> JVM </tag>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java中volatile关键字的含义</title>
      <link href="/2016/05/15/java%E4%B8%ADvolatile%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E5%90%AB%E4%B9%89/"/>
      <url>/2016/05/15/java%E4%B8%ADvolatile%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E5%90%AB%E4%B9%89/</url>
      
        <content type="html"><![CDATA[<p><strong>synchronized</strong> </p><p>同步块大家都比较熟悉，通过 synchronized 关键字来实现，所有加上synchronized 和 块语句，在多线程访问的时候，同一时刻只能有一个线程能够用</p><p>synchronized 修饰的方法 或者 代码块。</p><p><strong>volatile</strong></p><p>用volatile修饰的变量，线程在每次使用变量的时候，都会读取变量修改后的最的值。volatile很容易被误用，用来进行原子性操作。</p><p>例子，我们实现一个计数器，每次线程启动的时候，会调用计数器inc方法，对计数器进行加一</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">public class Counter &#123;</span><br><span class="line"> </span><br><span class="line">    public static int count = 0;</span><br><span class="line"> </span><br><span class="line">    public static void inc() &#123;</span><br><span class="line"> </span><br><span class="line">        //这里延迟1毫秒，使得结果明显</span><br><span class="line">        try &#123;</span><br><span class="line">            Thread.sleep(1);</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        count++;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"> </span><br><span class="line">        //同时启动1000个线程，去进行i++计算，看看实际结果</span><br><span class="line"> </span><br><span class="line">        for (int i = 0; i &lt; 1000; i++) &#123;</span><br><span class="line">            new Thread(new Runnable() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    Counter.inc();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;).start();</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        //这里每次运行的值都有可能不同,可能为1000</span><br><span class="line">        System.out.println(&quot;运行结果:Counter.count=&quot; + Counter.count);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">运行结果:Counter.count=995</span><br><span class="line">实际运算结果每次可能都不一样，本机的结果为：运行结果:Counter.count=995，可以看出，在多线程的环境下，Counter.count并没有期望结果是1000</span><br><span class="line">很多人以为，这个是多线程并发问题，只需要在变量count之前加上volatile就可以避免这个问题，那我们在修改代码看看，看看结果是不是符合我们的期望</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">public class Counter &#123;</span><br><span class="line"> </span><br><span class="line">    public volatile static int count = 0;</span><br><span class="line"> </span><br><span class="line">    public static void inc() &#123;</span><br><span class="line"> </span><br><span class="line">        //这里延迟1毫秒，使得结果明显</span><br><span class="line">        try &#123;</span><br><span class="line">            Thread.sleep(1);</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        count++;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"> </span><br><span class="line">        //同时启动1000个线程，去进行i++计算，看看实际结果</span><br><span class="line"> </span><br><span class="line">        for (int i = 0; i &lt; 1000; i++) &#123;</span><br><span class="line">            new Thread(new Runnable() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    Counter.inc();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;).start();</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        //这里每次运行的值都有可能不同,可能为1000</span><br><span class="line">        System.out.println(&quot;运行结果:Counter.count=&quot; + Counter.count);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行结果:Counter.count=992</p><p>运行结果还是没有我们期望的1000，下面我们分析一下原因</p><p>在 java 垃圾回收整理一文中，描述了jvm运行时刻内存的分配。其中有一个内存区域是jvm虚拟机栈，每一个线程运行时都有一个线程栈，</p><p>线程栈保存了线程运行时候变量值信息。当线程访问某一个对象时候值的时候，首先通过对象的引用找到对应在堆内存的变量的值，然后把堆内存</p><p>变量的具体值load到线程本地内存中，建立一个变量副本，之后线程就不再和对象在堆内存变量值有任何关系，而是直接修改副本变量的值，</p><p>在修改完之后的某一个时刻（线程退出之前），自动把线程变量副本的值回写到对象在堆中变量。这样在堆中的对象的值就产生变化了。下面一幅图</p><p>描述这写交互</p><p><a href="http://images.cnblogs.com/cnblogs_com/aigongsi/201204/201204011757234696.jpg" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/aigongsi/201204/201204011757235219.jpg" alt="java volatile1"></a></p><p>read and load 从主存复制变量到当前工作内存<br>use and assign  执行代码，改变共享变量值<br>store and write 用工作内存数据刷新主存相关内容</p><p>其中use and assign 可以多次出现</p><p>但是这一些操作并不是原子性，也就是 在read load之后，如果主内存count变量发生修改之后，线程工作内存中的值由于已经加载，不会产生对应的变化，所以计算出来的结果会和预期不一样</p><p>对于volatile修饰的变量，jvm虚拟机只是保证从主内存加载到线程工作内存的值是最新的</p><p>例如假如线程1，线程2 在进行read,load 操作中，发现主内存中count的值都是5，那么都会加载这个最新的值</p><p>在线程1堆count进行修改之后，会write到主内存中，主内存中的count变量就会变为6</p><p>线程2由于已经进行read,load操作，在进行运算之后，也会更新主内存count的变量值为6</p><p>导致两个线程及时用volatile关键字修改之后，还是会存在并发的情况。</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> volatile </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java中判断字符串为数字的常用方法</title>
      <link href="/2016/05/11/Java%E4%B8%AD%E5%88%A4%E6%96%AD%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%BA%E6%95%B0%E5%AD%97%E7%9A%84%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/"/>
      <url>/2016/05/11/Java%E4%B8%AD%E5%88%A4%E6%96%AD%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%BA%E6%95%B0%E5%AD%97%E7%9A%84%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p><img class="zhao-img-h153" src="http://qnfile.devzhao.com/blog/2018-10-19-jhk-1539947585142.jpeg"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">//方法一：用JAVA自带的函数</span><br><span class="line">public static boolean isNumeric(String str)&#123;</span><br><span class="line">   for (int i = str.length();--i&gt;=0;)&#123;  </span><br><span class="line">       if (!Character.isDigit(str.charAt(i)))&#123;</span><br><span class="line">           return false;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">/*方法二：推荐，速度最快</span><br><span class="line">  * 判断是否为整数 </span><br><span class="line">  * @param str 传入的字符串 </span><br><span class="line">  * @return 是整数返回true,否则返回false </span><br><span class="line">*/</span><br><span class="line"></span><br><span class="line">  public static boolean isInteger(String str) &#123;  </span><br><span class="line">        Pattern pattern = Pattern.compile(&quot;^[-\\+]?[\\d]*$&quot;);  </span><br><span class="line">        return pattern.matcher(str).matches();  </span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//方法三：</span><br><span class="line">public static boolean isNumeric(String str)&#123;</span><br><span class="line">    Pattern pattern = Pattern.compile(&quot;[0-9]*&quot;);</span><br><span class="line">    return pattern.matcher(str).matches();   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//方法四：</span><br><span class="line">public final static boolean isNumeric(String s) &#123;</span><br><span class="line">    if (s != null &amp;&amp; !&quot;&quot;.equals(s.trim()))</span><br><span class="line">        return s.matches(&quot;^[0-9]*$&quot;);</span><br><span class="line">    else</span><br><span class="line">        return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">//方法五：用ascii码 </span><br><span class="line">public static boolean isNumeric(String str)&#123;</span><br><span class="line">    for(int i=str.length();--i&gt;=0;)&#123;</span><br><span class="line">        int chr=str.charAt(i);</span><br><span class="line">        if(chr&lt;48 || chr&gt;57)</span><br><span class="line">            return false;</span><br><span class="line">    &#125;</span><br><span class="line">   return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 常用方法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自己搭建梯子</title>
      <link href="/2016/01/05/%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA%E6%A2%AF%E5%AD%90/"/>
      <url>/2016/01/05/%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA%E6%A2%AF%E5%AD%90/</url>
      
        <content type="html"><![CDATA[<h4 id="1、挑选服务器："><a href="#1、挑选服务器：" class="headerlink" title="1、挑选服务器："></a><strong>1、挑选服务器：</strong></h4><p>​     一般供应商都会提供IP<a href="http://lib.csdn.net/base/softwaretest" target="_blank" rel="noopener">测试</a>延迟，或者看各VPS网站评测介绍，一般来讲亚洲服务器延迟更低，比如香港.新加坡就有很多电信或者网通直连机房，而美国VPS价格更便宜，而且带宽大些。</p><p>​    服务器类型，Xen KVM 性能要好过openvz，不过也要更贵一些，综上所述，建议选直连自己运营商的KVM虚拟技术的亚洲VPS。</p><p>下面我们用日本conoha VPS为例开始操作。</p><p>1.日本conoha支持支付宝支付，每月900日元、中文界面 （50rmb如果几个人合用的话成本还算可以。选择HOSTUS的香港25美元/年电信机房也不错）设置并记root密码点击追加建立服务器，这里我们选择centos 6.6 64位版本</p><p><img src="http://i3.tietuku.com/73939c8862f69acd.png" alt="img">2.回到服务器界面，点开网络配置，记下IP4地址</p><h4 id="2-用XshellPortable连接服务器"><a href="#2-用XshellPortable连接服务器" class="headerlink" title="2.用XshellPortable连接服务器"></a>2.用XshellPortable连接服务器</h4><p>填上IP地址点击确定</p><p>用户名为 root</p><p>密码为开通vps设置的9位密码</p><p>连接成功会显示，root@XXXXXX #<br>然后在设置里把右键改成复制剪贴板中的代码 如图，右键粘贴比较方便</p><h4 id="3-这里我们用秋水兄的SS一键安装脚本"><a href="#3-这里我们用秋水兄的SS一键安装脚本" class="headerlink" title="3.这里我们用秋水兄的SS一键安装脚本"></a>3.这里我们用秋水兄的SS一键安装脚本</h4><p>​    全程仅需3行代码，即使0基础毫无问题，依次输入代码回车即可</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.sh</span><br><span class="line"></span><br><span class="line">chmod +x shadowsocks.sh</span><br><span class="line"></span><br><span class="line">./shadowsocks.sh 2&gt;&amp;1 | tee shadowsocks.log</span><br></pre></td></tr></table></figure><p><img src="http://i3.tietuku.com/ae721437801a8c77.png" alt="img"></p><p>询问密码：输入t66y为端口密码</p><p><img src="http://i3.tietuku.com/0ffcb227120d76cd.png" alt="img"></p><p>默认端口8989.可以指定任意端口 ，回车后耐心等待安装</p><p><img src="http://i3.tietuku.com/5d03e29f5ba8a52b.png" alt="img"></p><p>安装完成后，脚本提示如下：</p><p><img src="http://i3.tietuku.com/ace55c8d0f0405c8.png" alt="img"></p><p>现在我们已经成功搭建了一个单用户版SS代理服务器，用其他帖子的教程连接该服务器即可<br>端口为8989 密码t66y</p><h4 id="4-多用户配置"><a href="#4-多用户配置" class="headerlink" title="4.多用户配置"></a>4.多用户配置</h4><p>删除原配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -f /etc/shadowsocks.json</span><br></pre></td></tr></table></figure><p>编辑配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/shadowsocks.json</span><br></pre></td></tr></table></figure><p><img src="http://i3.tietuku.com/0abd0889dc17cb2e.png" alt="img"></p><p>按下I键，进入编辑状态<br>左下角有标示—INSERT—<br>如图复制下面代码至配置文件<br>配置端口 8989到9004，密码t66y0到t66y4等5个账号<br>可照例加入更多用户</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&quot;local_address&quot;:&quot;127.0.0.1&quot;,</span><br><span class="line">&quot;local_port&quot;:1080,</span><br><span class="line">&quot;port_password&quot;:&#123;</span><br><span class="line">&quot;8989&quot;:&quot;t66y0&quot;,</span><br><span class="line">&quot;9001&quot;:&quot;t66y1&quot;,</span><br><span class="line">&quot;9002&quot;:&quot;t66y2&quot;,</span><br><span class="line">&quot;9003&quot;:&quot;t66y3&quot;,</span><br><span class="line">&quot;9004&quot;:&quot;t66y4&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;timeout&quot;:300,</span><br><span class="line">&quot;method&quot;:&quot;aes-256-cfb&quot;,</span><br><span class="line">&quot;fast_open&quot;: false</span><br></pre></td></tr></table></figure><p>按下ESC键退出编辑状态，同时按下SHIFT+Q键进入退出模式<br>如图输入wq回车保存退出</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wd</span><br></pre></td></tr></table></figure><h4 id="5、重启-SS服务"><a href="#5、重启-SS服务" class="headerlink" title="5、重启 SS服务"></a>5、重启 SS服务</h4><p><code>/etc/init.d/shadowsocks restart</code></p><p>至此一个多用户版本的SS服务器已经搭建完成<br>其他命令：<br>启动：/etc/init.d/shadowsocks start<br>停止：/etc/init.d/shadowsocks stop<br>重启：/etc/init.d/shadowsocks restart<br>状态：/etc/init.d/shadowsocks status<br>卸载：./shadowsocks.sh uninstall</p><h4 id="6、Shadowsocks-WIN客户端设置"><a href="#6、Shadowsocks-WIN客户端设置" class="headerlink" title="6、Shadowsocks WIN客户端设置"></a>6、Shadowsocks WIN客户端设置</h4><p>Win客户端下载地址：<a href="http://sourceforge.NET/projects/shadowsocksgui/files/dist/" target="_blank" rel="noopener">http://sourceforge.NET/projects/shadowsocksgui/files/dist/</a></p><p>设置界面如下：</p><p>其中：Server IP为服务器IP，Server Port为远程端口（在服务器端shadowsocks.json中设置），Password为密码，Encryption为加密方式，选择<code>AES-256-CFB</code>，Proxy Port为本地端口（在服务器端shadowsocks.json中设置），Remarks为别名。</p><p>配置好客户端后，我们需要选择合适的浏览器和插件来应用本地代理，下面分别介绍了Chrome和Firefox的设置方法。</p><p><strong>a、Chrome</strong></p><p>Chrome使用本地代理需要用到插件<a href="http://switchysharp.com/install.html" target="_blank" rel="noopener">SwitchySharp</a>，安装好插件后，打开插件的设置界面，填入如下设置</p><p>设置完成后选择插件的代理模式为<code>Shadowsocks</code>(或者你自己命名的情景模式)后即可。</p><p>上面的设置为全局代理，如需实现智能代理需要手动添加规则，还可以订阅GFWlist，地址为：<a href="http://autoproxy-gfwlist.googlecode.com/svn/trunk/gfwlist.txt" target="_blank" rel="noopener">http://autoproxy-gfwlist.googlecode.com/svn/trunk/gfwlist.txt</a> 由于这个地址不通过代理无法访问，所以你可以通过其它途径下载到本地，这方面资料网上比较丰富，再者使用起来不是很方便，在此我就不赘述了。下面介绍另一种规则，<a href="https://github.com/clowwindy/" target="_blank" rel="noopener">gfwlist2pac</a>，这是网友在Gfwlist的基础上，更新了部分网址转化成的PAC规则文件，目前我就采用的是这种方式，体验不错，当然，由于规则文件都具有时效性，也许你看到这篇文章时这个规则或许不是最好用的了，这里只是讲一种思路，你可以自行选择其他规则，甚至是自定义的规则，使用PAC规则设置如下:</p><p>PAC规则地址：<a href="https://raw.githubusercontent.com/clowwindy/gfwlist2pac/master/test/proxy_abp.pac" target="_blank" rel="noopener">https://raw.githubusercontent.com/clowwindy/gfwlist2pac/master/test/proxy_abp.pac</a></p><p>设置完成后选择插件的代理模式为<code>gfwlist2pac</code>(或者你自己命名的情景模式)后即可。</p><p><strong>b、Firefox</strong></p><p>Firefox使用本地代理需要用到插件<a href="http://fxthunder.com/blog/archives/2866/" target="_blank" rel="noopener">Autoproxy</a>，这个插件原作者已经没有更新了，本文使用的是其他作者的继续更新版，修复了无法订阅gfwlist的bug，订阅方法和上述类似，同样由于原地址无法直接访问，所以可以通过其他途径下载到本地然后导入。</p><h4 id="7、Shadowsocks-Android客户端设置"><a href="#7、Shadowsocks-Android客户端设置" class="headerlink" title="7、Shadowsocks  Android客户端设置"></a>7、Shadowsocks  Android客户端设置</h4><p>首先需要下载android客户端，Shadowsocks的中文名称为影梭，可以从googleplay下载，如果你无法使用googleplay,可从下面的地址下载:<a href="https://github.com/shadowsocks/shadowsocks-android/releases" target="_blank" rel="noopener">https://github.com/shadowsocks/shadowsocks-android/releases</a> ，android版的设置和PC端类似</p>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> 梯子 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络模型和tcp/ip协议</title>
      <link href="/2015/05/16/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%92%8Ctcp-ip%E5%8D%8F%E8%AE%AE/"/>
      <url>/2015/05/16/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%92%8Ctcp-ip%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<h4 id="0、网络模型自上而下共分为七层："><a href="#0、网络模型自上而下共分为七层：" class="headerlink" title="0、网络模型自上而下共分为七层："></a>0、网络模型自上而下共分为七层：</h4><p>7 应用层<br>6 表示层<br>5 会话层<br>4 传输层<br>3 网络层<br>2 数据链路层<br>1 物理层</p><p><strong>其中3、2、1层主要面向通过网络的端到端的数据流，7、6、5、4层定义了应用程序的功能。</strong></p><p><strong>（1）应用层</strong>：与其他计算机进行通讯的一个应用，它是对应应用程序的通信服务的。例如，一个没有通信功能的字处理程序就不能执行通信的代码，从事字处理工作的程序员也不关心OSI的第7层。但是，如果添加了一个传输文件的选项，那么字处理器的程序员就需要实现OSI的第7层。示例：telnet，HTTP,FTP,WWW,NFS,SMTP等。</p><p><strong>（2）表示层</strong>：这一层的主要功能是定义数据格式及加密。例如，FTP允许你选择以二进制或ASII格式传输。如果选择二进制，那么发送方和接收方不改变文件的内容。如果选择ASII格式，发送方将把文本从发送方的字符集转换成标准的ASII后发送数据。在接收方将标准的ASII转换成接收方计算机的字符集。示例：加密，ASII等。</p><p><strong>（3）会话层</strong>：他定义了如何开始、控制和结束一个会话，包括对多个双向小时的控制和管理，以便在只完成连续消息的一部分时可以通知应用，从而使表示层看到的数据是连续的，在某些情况下，如果表示层收到了所有的数据，则用数据代表表示层。示例：RPC，SQL等。</p><p><strong>（4）传输层</strong>：这层的功能包括是否选择差错恢复协议还是无差错恢复协议，及在同一主机上对不同应用的数据流的输入进行复用，还包括对收到的顺序不对的数据包的重新排序功能。示例：TCP，UDP，SPX。</p><p><strong>（5）网络层</strong>：这层对端到端的包传输进行定义，他定义了能够标识所有结点的逻辑地址，还定义了路由实现的方式和学习的方式。为了适应最大传输单元长度小于包长度的传输介质，网络层还定义了如何将一个包分解成更小的包的分段方法。示例：IP,IPX等。</p><p><strong>（6）数据链路层</strong>：他定义了在单个链路上如何传输数据。这些协议与被讨论的歌种介质有关。示例：ATM，FDDI等。</p><p><strong>（7）物理层</strong>：OSI的物理层规范是有关传输介质的特性标准，这些规范通常也参考了其他组织制定的标准。连接头、针、针的使用、电流、电流、编码及光调制等都属于各种物理层规范中的内容。物理层常用多个规范完成对所有细节的定义。示例：Rj45，802.3等。</p><p><strong>OSI分层的优点：</strong><br>（1）人们可以很容易的讨论和学习协议的规范细节。<br>（2）层间的标准接口方便了工程模块化。<br>（3）创建了一个更好的互连环境。<br>（4）降低了复杂度，使程序更容易修改，产品开发的速度更快。<br>（5）每层利用紧邻的下层服务，更容易记住个层的功能。</p><p><strong>tcp/ip</strong></p><p>TCP/IP是“transmission Control Protocol/Internet Protocol”的简写，中文译名为传输控制协议/互联网络协议）协议。</p><p>TCP/IP（传输控制协议/网间协议）是一种网络通信协议，它规范了网络上的所有通信设备，尤其是一个主机与另一个主机之间的数据往来格式以及传送方式。TCP/IP是INTERNET的基础协议，也是一种电脑数据打包和寻址的标准方法。在数据传送中，可以形象地理解为有两个信封，TCP和IP就像是信封，要传递的信息被划分成若干段，每一段塞入一个TCP信封，并在该信封面上记录有分段号的信息，再将TCP信封塞入IP大信封，发送上网。在接受端，一个TCP软件包收集信封，抽出数据，按发送前的顺序还原，并加以校验，若发现差错，TCP将会要求重发。因此，TCP/IP在INTERNET中几乎可以无差错地传送数据。对普通用户来说，并不需要了解网络协议的整个结构，仅需了解IP的地址格式，即可与世界各地进行网络通信。<br>​        </p>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络模型 </tag>
            
            <tag> tcp </tag>
            
            <tag> ip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>transient</title>
      <link href="/2015/05/12/transient/"/>
      <url>/2015/05/12/transient/</url>
      
        <content type="html"><![CDATA[<pre><code>java对象只要实现了Serilizable接口，这个对象就可以被序列化，java的这种序列化模式为开发者提供了很多便利，我们可以不必关系具体序列化的过程，只要这个类实现了Serilizable接口，这个类的所有属性和方法都会自动序列化。 然而在实际开发过程中，我们常常会遇到这样的问题，这个类的有些属性需要序列化，而其他属性不需要被序列化，打个比方，如果一个用户有一些敏感信息（如密码，银行卡号等），为了安全起见，不希望在网络操作（主要涉及到序列化操作，本地序列化缓存也适用）中被传输，这些信息对应的变量就可以加上transient关键字。换句话说，这个字段的生命周期仅存于调用者的内存中而不会写到磁盘里持久化。 总之，java 的transient关键字为我们提供了便利，你只需要实现Serilizable接口，将不需要序列化的属性前添加关键字transient，序列化对象的时候，这个属性就不会序列化到指定的目的地中。</code></pre><h4 id="一、代码测试1"><a href="#一、代码测试1" class="headerlink" title="一、代码测试1"></a>一、代码测试1</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line">import java.io.FileInputStream;</span><br><span class="line">import java.io.FileNotFoundException;</span><br><span class="line">import java.io.FileOutputStream;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.io.ObjectInputStream;</span><br><span class="line">import java.io.ObjectOutputStream;</span><br><span class="line">import java.io.Serializable;</span><br><span class="line"> </span><br><span class="line">/**</span><br><span class="line"> * @description 使用transient关键字不序列化某个变量</span><br><span class="line"> *        注意读取的时候，读取数据的顺序一定要和存放数据的顺序保持一致</span><br><span class="line"> *        </span><br><span class="line"> * @author Alexia</span><br><span class="line"> * @date  2013-10-15</span><br><span class="line"> */</span><br><span class="line">public class TransientTest &#123;</span><br><span class="line">    </span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        </span><br><span class="line">        User user = new User();</span><br><span class="line">        user.setUsername(&quot;Alexia&quot;);</span><br><span class="line">        user.setPasswd(&quot;123456&quot;);</span><br><span class="line">        </span><br><span class="line">        System.out.println(&quot;read before Serializable: &quot;);</span><br><span class="line">        System.out.println(&quot;username: &quot; + user.getUsername());</span><br><span class="line">        System.err.println(&quot;password: &quot; + user.getPasswd());</span><br><span class="line">        </span><br><span class="line">        try &#123;</span><br><span class="line">            ObjectOutputStream os = new ObjectOutputStream(</span><br><span class="line">                    new FileOutputStream(&quot;C:/user.txt&quot;));</span><br><span class="line">            os.writeObject(user); // 将User对象写进文件</span><br><span class="line">            os.flush();</span><br><span class="line">            os.close();</span><br><span class="line">        &#125; catch (FileNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        try &#123;</span><br><span class="line">            ObjectInputStream is = new ObjectInputStream(new FileInputStream(</span><br><span class="line">                    &quot;C:/user.txt&quot;));</span><br><span class="line">            user = (User) is.readObject(); // 从流中读取User的数据</span><br><span class="line">            is.close();</span><br><span class="line">            </span><br><span class="line">            System.out.println(&quot;\nread after Serializable: &quot;);</span><br><span class="line">            System.out.println(&quot;username: &quot; + user.getUsername());</span><br><span class="line">            System.err.println(&quot;password: &quot; + user.getPasswd());</span><br><span class="line">            </span><br><span class="line">        &#125; catch (FileNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; catch (ClassNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">class User implements Serializable &#123;</span><br><span class="line">    private static final long serialVersionUID = 8294180014912103005L;  </span><br><span class="line">    </span><br><span class="line">    private String username;</span><br><span class="line">    private transient String passwd;</span><br><span class="line">    </span><br><span class="line">    public String getUsername() &#123;</span><br><span class="line">        return username;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public void setUsername(String username) &#123;</span><br><span class="line">        this.username = username;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public String getPasswd() &#123;</span><br><span class="line">        return passwd;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public void setPasswd(String passwd) &#123;</span><br><span class="line">        this.passwd = passwd;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">结果如下：</span><br><span class="line">read before Serializable: </span><br><span class="line">username: Alexia</span><br><span class="line">password: 123456</span><br><span class="line"> </span><br><span class="line">read after Serializable: </span><br><span class="line">username: Alexia</span><br><span class="line">password: null</span><br></pre></td></tr></table></figure><h4 id="二、transient使用小结"><a href="#二、transient使用小结" class="headerlink" title="二、transient使用小结"></a>二、transient使用小结</h4><p>1）一旦变量被transient修饰，变量将不再是对象持久化的一部分，该变量内容在序列化后无法获得访问。</p><p>2）transient关键字只能修饰变量，而不能修饰方法和类。注意，本地变量是不能被transient关键字修饰的。变量如果是用户自定义类变量，则该类需要实现Serializable接口。</p><p>3）被transient关键字修饰的变量不再能被序列化，一个静态变量不管是否被transient修饰，均不能被序列化。</p><h4 id="三、代码测试2"><a href="#三、代码测试2" class="headerlink" title="三、代码测试2"></a>三、代码测试2</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">import java.io.Externalizable;</span><br><span class="line">import java.io.File;</span><br><span class="line">import java.io.FileInputStream;</span><br><span class="line">import java.io.FileOutputStream;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.io.ObjectInput;</span><br><span class="line">import java.io.ObjectInputStream;</span><br><span class="line">import java.io.ObjectOutput;</span><br><span class="line">import java.io.ObjectOutputStream;</span><br><span class="line"> </span><br><span class="line">/**</span><br><span class="line"> * @descripiton Externalizable接口的使用</span><br><span class="line"> * </span><br><span class="line"> * @author Alexia</span><br><span class="line"> * @date 2013-10-15</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line">public class ExternalizableTest implements Externalizable &#123;</span><br><span class="line"> </span><br><span class="line">    private transient String content = &quot;是的，我将会被序列化，不管我是否被transient关键字修饰&quot;;</span><br><span class="line"> </span><br><span class="line">    @Override</span><br><span class="line">    public void writeExternal(ObjectOutput out) throws IOException &#123;</span><br><span class="line">        out.writeObject(content);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    @Override</span><br><span class="line">    public void readExternal(ObjectInput in) throws IOException,</span><br><span class="line">            ClassNotFoundException &#123;</span><br><span class="line">        content = (String) in.readObject();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        </span><br><span class="line">        ExternalizableTest et = new ExternalizableTest();</span><br><span class="line">        ObjectOutput out = new ObjectOutputStream(new FileOutputStream(</span><br><span class="line">                new File(&quot;test&quot;)));</span><br><span class="line">        out.writeObject(et);</span><br><span class="line"> </span><br><span class="line">        ObjectInput in = new ObjectInputStream(new FileInputStream(new File(</span><br><span class="line">                &quot;test&quot;)));</span><br><span class="line">        et = (ExternalizableTest) in.readObject();</span><br><span class="line">        System.out.println(et.content);</span><br><span class="line"> </span><br><span class="line">        out.close();</span><br><span class="line">        in.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​    在Java中，对象的序列化可以通过实现两种接口来实现，若实现的是Serializable接口，则所有的序列化将会自动进行，若实现的是Externalizable接口，则没有任何东西可以自动序列化，需要在writeExternal方法中进行手工指定所要序列化的变量，这与是否被transient修饰无关。因此第二个例子输出的是变量content初始化的内容，而不是null。</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> transient </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux安装LAMP</title>
      <link href="/2015/01/21/Linux%E5%AE%89%E8%A3%85LAMP/"/>
      <url>/2015/01/21/Linux%E5%AE%89%E8%A3%85LAMP/</url>
      
        <content type="html"><![CDATA[<h2 id="Linux安装LAMP"><a href="#Linux安装LAMP" class="headerlink" title="Linux安装LAMP"></a>Linux安装LAMP</h2><h4 id="0、使用以下命令安装Apache："><a href="#0、使用以下命令安装Apache：" class="headerlink" title="0、使用以下命令安装Apache："></a><strong>0、使用以下命令安装Apache：</strong></h4><p>yum install httpd</p><p>安装完之后，重新启动Apache：/etc/init.d/httpd restart<br>接着将Apache设置为开机启动：chkconfig httpd on.(这一步使得服务器不需要在每次重启的时候都要手动启动httpd服务)</p><p>要查看httpd服务的启动状态，可以使用命令：chkconfig –list httpd(会显示httpd在各个级别(level)下的启动状态)</p><h4 id="1、使用以下命令安装MySQL："><a href="#1、使用以下命令安装MySQL：" class="headerlink" title="1、使用以下命令安装MySQL："></a>1、使用以下命令安装MySQL：</h4><p>yum install mysql mysql-server<br>同样，如果出现提示已安装的话，就说明系统安装了MySQL了，可以跳过这一步，否则，系统接下来会自动安装MySQL。<br>安装完成了之后，启动MySQL：/etc/init.d/mysql start</p><p>将MySQL设置为开机启动：chkconfig mysqld on<br>最后，拷贝配置文件：cp /usr/share/mysql/my-medium.cnf /etc/my.cnf (在/etc下有个my.cnf文件，直接覆盖就行了)</p><p>1.2、用以下命令给root账户设置密码</p><p>mysql_secure_installation<br>根据提示输入2次密码，就设置成功了。注意，在设置过程中，会提示删除是否anonymous用户，是否拒绝root的远程访问，是否删除测试用的数据库等，这些都需要根据自己的实际情况进行选择。最后出现：Thanks for using MySQL!，设置密码成功了。</p><p>重新启动MySQL：/etc/init.d/mysqld restart</p><ol><li>3、mysql开启远程访问权限</li></ol><p>GRANT ALL PRIVILEGES ON <em>.</em> TO ‘myuser‘@’%’IDENTIFIED BY ‘mypassword’ WITH GRANT OPTION;</p><h4 id="2：安装PHP"><a href="#2：安装PHP" class="headerlink" title="2：安装PHP"></a><strong>2：安装PHP</strong></h4><p>2.1、使用以下命令安装PHP：</p><p>yum install php<br>根据提示往下安装就行了。安装完之后重新启动Apache：/etc/init.d/httpd restart<br>2.2、安装PHP组件，是PHP支持MySQL</p><p>可以使用命令：yum search php来查看PHP的组件，选择需要的模块进行安装：</p><p>yum install php-mysql php-gd libjpeg* php-imap php-ldap php-odbc php-pear php-xml php-xmlrpc php-mbstring php-mcrypt php-bcmath php-mhash libmcrypt</p><p>安装完之后，重启Apache：/etc/init.d/httpd restart</p><p>重启MySQL：/etc/init.d/mysqld restart</p>]]></content>
      
      
      <categories>
          
          <category> 博客搭建 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> apache </tag>
            
            <tag> mysql </tag>
            
            <tag> php </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
