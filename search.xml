<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>数据仓库架构</title>
      <link href="/2019/05/12/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84/"/>
      <url>/2019/05/12/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<p>业务系统数据：司法信息，工商信息，社保公积金，运营商，淘宝</p><p>增量数据导入到ods层（sparkstreaming任务，sqoop任务，接口调用）</p><p>ods : 贴源层，维度表（dim）</p><p>数据按天分区</p><p>dw(dwd,dws)为了支撑那些应用，那些查询</p><p>dwd:数据宽表</p><p>dws：汇总表</p><p>集市(由dws生成) 面向主题，面向应用。支撑了95%的查询，粒度更细<br>oozie调度 数据增量导入，定时跑任务，cattle（数据迁移，数据增量导入，流程监控）</p><p>一层比一层粒度细 20个表-&gt; 200个表 </p><p>原材料 -&gt;&gt; 数据加工 -&gt; 产品</p>]]></content>
      
      
      <categories>
          
          <category> hive </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据仓库 </tag>
            
            <tag> hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java创建线程的几种方式</title>
      <link href="/2019/03/19/java%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/"/>
      <url>/2019/03/19/java%E5%88%9B%E5%BB%BA%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="一、继承Thread类创建线程类"><a href="#一、继承Thread类创建线程类" class="headerlink" title="一、继承Thread类创建线程类"></a><strong>一、继承Thread类创建线程类</strong></h2><h3 id="1、Thread类的子类，并重写该类的run方法"><a href="#1、Thread类的子类，并重写该类的run方法" class="headerlink" title="1、Thread类的子类，并重写该类的run方法"></a>1、Thread类的子类，并重写该类的run方法</h3><p>（1）定义Thread类的子类，并重写该类的run方法，该run方法的方法体就代表了线程要完成的任务。因此把run()方法称为执行体。</p><p>（2）创建Thread子类的实例，即创建了线程对象。</p><p>（3）调用线程对象的start()方法来启动该线程。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">package com.thread;  </span><br><span class="line">  </span><br><span class="line">public class FirstThreadTest extends Thread&#123;  </span><br><span class="line">    int i = 0;  </span><br><span class="line">    //重写run方法，run方法的方法体就是现场执行体  </span><br><span class="line">    public void run()  </span><br><span class="line">    &#123;  </span><br><span class="line">        for(;i&lt;100;i++)&#123;  </span><br><span class="line">        System.out.println(getName()+&quot;  &quot;+i);  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    public static void main(String[] args)  </span><br><span class="line">    &#123;  </span><br><span class="line">        for(int i = 0;i&lt; 100;i++)  </span><br><span class="line">        &#123;  </span><br><span class="line">            System.out.println(Thread.currentThread().getName()+&quot;  : &quot;+i);  </span><br><span class="line">            if(i==20)  </span><br><span class="line">            &#123;  </span><br><span class="line">                new FirstThreadTest().start();  </span><br><span class="line">                new FirstThreadTest().start();  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码中Thread.currentThread()方法返回当前正在执行的线程对象。GetName()方法返回调用该方法的线程的名字。</p><h3 id="2、通过Runnable接口创建线程类"><a href="#2、通过Runnable接口创建线程类" class="headerlink" title="2、通过Runnable接口创建线程类"></a>2、通过Runnable接口创建线程类</h3><p>（1）定义runnable接口的实现类，并重写该接口的run()方法，该run()方法的方法体同样是该线程的线程执行体。</p><p>（2）创建 Runnable实现类的实例，并以此实例作为Thread的target来创建Thread对象，该Thread对象才是真正的线程对象。</p><p>（3）调用线程对象的start()方法来启动该线程。</p><p>示例代码为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">package com.thread;  </span><br><span class="line">  </span><br><span class="line">public class RunnableThreadTest implements Runnable  </span><br><span class="line">&#123;  </span><br><span class="line">  </span><br><span class="line">    private int i;  </span><br><span class="line">    public void run()  </span><br><span class="line">    &#123;  </span><br><span class="line">        for(i = 0;i &lt;100;i++)  </span><br><span class="line">        &#123;  </span><br><span class="line">            System.out.println(Thread.currentThread().getName()+&quot; &quot;+i);  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    public static void main(String[] args)  </span><br><span class="line">    &#123;  </span><br><span class="line">        for(int i = 0;i &lt; 100;i++)  </span><br><span class="line">        &#123;  </span><br><span class="line">            System.out.println(Thread.currentThread().getName()+&quot; &quot;+i);  </span><br><span class="line">            if(i==20)  </span><br><span class="line">            &#123;  </span><br><span class="line">                RunnableThreadTest rtt = new RunnableThreadTest();  </span><br><span class="line">                new Thread(rtt,&quot;新线程1&quot;).start();  </span><br><span class="line">                new Thread(rtt,&quot;新线程2&quot;).start();  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>线程的执行流程很简单，当执行代码start()时，就会执行对象中重写的void run();方法，该方法执行完成后，线程就消亡了。</p><h3 id="3、通过Callable和Future创建线程"><a href="#3、通过Callable和Future创建线程" class="headerlink" title="3、通过Callable和Future创建线程"></a>3、通过Callable和Future创建线程</h3><p>（1）创建Callable接口的实现类，并实现call()方法，该call()方法将作为线程执行体，并且有返回值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public interface Callable</span><br><span class="line">&#123;</span><br><span class="line">　　V call() throws Exception;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（2）创建Callable实现类的实例，使用FutureTask类来包装Callable对象，该FutureTask对象封装了该Callable对象的call()方法的返回值。（FutureTask是一个包装器，它通过接受Callable来创建，它同时实现了Future和Runnable接口。）</p><p>（3）使用FutureTask对象作为Thread对象的target创建并启动新线程。</p><p>（4）调用FutureTask对象的get()方法来获得子线程执行结束后的返回值</p><p>实例代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">package com.thread;  </span><br><span class="line">  </span><br><span class="line">import java.util.concurrent.Callable;  </span><br><span class="line">import java.util.concurrent.ExecutionException;  </span><br><span class="line">import java.util.concurrent.FutureTask;  </span><br><span class="line">  </span><br><span class="line">public class CallableThreadTest implements Callable&lt;Integer&gt;  </span><br><span class="line">&#123;  </span><br><span class="line">  </span><br><span class="line">    public static void main(String[] args)  </span><br><span class="line">    &#123;  </span><br><span class="line">        CallableThreadTest ctt = new CallableThreadTest();  </span><br><span class="line">        FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(ctt);  </span><br><span class="line">        for(int i = 0;i &lt; 100;i++)  </span><br><span class="line">        &#123;  </span><br><span class="line">            System.out.println(Thread.currentThread().getName()+&quot; 的循环变量i的值&quot;+i);  </span><br><span class="line">            if(i==20)  </span><br><span class="line">            &#123;  </span><br><span class="line">                new Thread(ft,&quot;有返回值的线程&quot;).start();  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">        try  </span><br><span class="line">        &#123;  </span><br><span class="line">            System.out.println(&quot;子线程的返回值：&quot;+ft.get());  </span><br><span class="line">        &#125; catch (InterruptedException e)  </span><br><span class="line">        &#123;  </span><br><span class="line">            e.printStackTrace();  </span><br><span class="line">        &#125; catch (ExecutionException e)  </span><br><span class="line">        &#123;  </span><br><span class="line">            e.printStackTrace();  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    @Override  </span><br><span class="line">    public Integer call() throws Exception  </span><br><span class="line">    &#123;  </span><br><span class="line">        int i = 0;  </span><br><span class="line">        for(;i&lt;100;i++)  </span><br><span class="line">        &#123;  </span><br><span class="line">            System.out.println(Thread.currentThread().getName()+&quot; &quot;+i);  </span><br><span class="line">        &#125;  </span><br><span class="line">        return i;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="二、创建线程的三种方式的对比"><a href="#二、创建线程的三种方式的对比" class="headerlink" title="二、创建线程的三种方式的对比"></a>二、创建线程的三种方式的对比</h2><p>1、采用实现Runnable、Callable接口的方式创建多线程时，</p><p>优势是：</p><p>线程类只是实现了Runnable接口或Callable接口，还可以继承其他类。</p><p>在这种方式下，多个线程可以共享同一个target对象，所以非常适合多个相同线程来处理同一份资源的情况，从而可以将CPU、代码和数据分开，形成清晰的模型，较好地体现了面向对象的思想。</p><p>劣势是：</p><p>编程稍微复杂，如果要访问当前线程，则必须使用Thread.currentThread()方法。</p><p>2、使用继承Thread类的方式创建多线程时，</p><p>优势是：</p><p>编写简单，如果需要访问当前线程，则无需使用Thread.currentThread()方法，直接使用this即可获得当前线程。</p><p>劣势是：</p><p>线程类已经继承了Thread类，所以不能再继承其他父类。</p><p>3、Runnable和Callable的区别</p><p>(1) Callable规定（重写）的方法是call()，Runnable规定（重写）的方法是run()。</p><p>(2) Callable的任务执行后可返回值，而Runnable的任务是不能返回值的。</p><p>(3) call方法可以抛出异常，run方法不可以。</p><p>(4) 运行Callable任务可以拿到一个Future对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 线程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Springboot 环境配置</title>
      <link href="/2018/12/17/Springboot-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
      <url>/2018/12/17/Springboot-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h4 id="resource中常见有几种环境配置文件"><a href="#resource中常见有几种环境配置文件" class="headerlink" title="resource中常见有几种环境配置文件"></a><strong>resource中常见有几种环境配置文件</strong></h4><p>​    application-dev.yml（开发环境）<br>     application-test.yml（测试环境）<br>     application-uat.yml（预发布）<br>     application-pro.yml（生产环境）<br>     application.yml</p><h4 id="使用多环境配置有三种方式："><a href="#使用多环境配置有三种方式：" class="headerlink" title="使用多环境配置有三种方式："></a><strong>使用多环境配置有三种方式</strong>：</h4><ol><li>使用@PropertySource注解<br>@PropertySource(classpath:application-dev.yml)</li><li><p>修改spring.profiles.active属性：</p><p>spring.profiles.active:dev</p></li><li><p>执行命令行<br>通过命令行可以直接指定某一配置文件<br>例：java -jar xxx.jar –spring.profiles.active=test</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> springboot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> springboot </tag>
            
            <tag> 环境 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark 数据倾斜（Data Skew）</title>
      <link href="/2018/04/16/spark-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%EF%BC%88Data-Skew%EF%BC%89/"/>
      <url>/2018/04/16/spark-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%EF%BC%88Data-Skew%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h4 id="0、前言"><a href="#0、前言" class="headerlink" title="0、前言"></a>0、前言</h4><p>​    何谓数据倾斜？数据倾斜指的是，并行处理的数据集中，某一部分（如Spark或Kafka的一个Partition）的数据显著多于其它部分，从而使得该部分的处理速度成为整个数据集处理的瓶颈。</p><p>​    数据倾斜的原理很简单：在进行shuffle的时候，必须将各个节点上相同的key拉取到某个节点上的一个task来进行处理，比如按照key进行聚合或join等操作。此时如果某个key对应的数据量特别大的话，就会发生数据倾斜。比如大部分key对应10条数据，但是个别key却对应了100万条数据，那么大部分task可能就只会分配到10条数据，然后1秒钟就运行完了；但是个别task可能分配到了100万数据，要运行一两个小时。因此，整个Spark作业的运行进度是由运行时间最长的那个task决定的。</p><p><strong>1 数据倾斜直接会导致一种情况：Out Of Memory。</strong></p><p><strong>2 运行速度慢,特别慢，非常慢，极端的慢，不可接受的慢</strong></p><p>搞定数据倾斜需要：</p><p>1 搞定shuffle</p><p>2 搞定业务场景</p><p>3 搞定 cpu core的使用情况</p><p>4 搞定OOM的根本原因等。</p><p>​    </p><p>​    一个经验结论是：一般情况下，OOM的原因都是数据倾斜。某个task任务数据量太大，GC的压力就很大。这比不了Kafka,因为kafka的内存是不经过JVM的。是基于Linux内核的Page.</p><p>​    <strong>如何定位导致数据倾斜的代码？</strong></p><p>​    数据倾斜只会发生在shuffle过程中。这里给大家罗列一些常用的并且可能会触发shuffle操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。出现数据倾斜时，可能就是你的代码中使用了这些算子中的某一个所导致的。</p><p>​    举例来说，对于上面所说的单词计数程序，如果确定了是stage1的reduceByKey算子导致了数据倾斜，那么就应该看看进行reduceByKey操作的RDD中的key分布情况，在这个例子中指的就是pairs RDD。如下示例，我们可以先对pairs采样10%的样本数据，然后使用countByKey算子统计出每个key出现的次数，最后在客户端遍历和打印样本数据中各个key的出现次数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val sampledPairs = pairs.sample(false, 0.1)</span><br><span class="line"></span><br><span class="line">val sampledWordCounts = sampledPairs.countByKey()</span><br><span class="line"></span><br><span class="line">sampledWordCounts.foreach(println(_))</span><br></pre></td></tr></table></figure><h4 id="1、如何缓解-消除数据倾斜？"><a href="#1、如何缓解-消除数据倾斜？" class="headerlink" title="1、如何缓解/消除数据倾斜？"></a><strong>1、如何缓解/消除数据倾斜？</strong></h4><h5 id="方式一"><a href="#方式一" class="headerlink" title="方式一"></a>方式一</h5><p><strong>尽量避免数据源的数据倾斜</strong><br>​    比如数据源是Kafka</p><p>​    以Spark Stream通过DirectStream方式读取Kafka数据为例。由于Kafka的每一个Partition对应Spark的一个Task（Partition），所以Kafka内相关Topic的各Partition之间数据是否平衡，直接决定Spark处理该数据时是否会产生数据倾斜。</p><p>​    Kafka某一Topic内消息在不同Partition之间的分布，主要由Producer端所使用的Partition实现类决定。如果使用随机Partitioner，则每条消息会随机发送到一个Partition中，从而从概率上来讲，各Partition间的数据会达到平衡。此时源Stage（直接读取Kafka数据的Stage）不会产生数据倾斜。</p><p><strong>解决方案：</strong></p><p>​    将Spark作业的shuffle操作提前到了Hive ETL中，从而让Spark直接使用预处理的Hive中间表，尽可能地减少Spark的shuffle操作，大幅度提升了性能</p><p><strong>方案优点</strong>：实现起来简单便捷，效果还非常好，完全规避掉了数据倾斜，Spark作业的性能会大幅度提升。</p><p><strong>方案缺点</strong>：治标不治本，Hive ETL中还是会发生数据倾斜。</p><h5 id="方式二"><a href="#方式二" class="headerlink" title="方式二"></a>方式二</h5><p><strong>调整并行度分散同一个Task的不同Key</strong><br><strong>案适用场景</strong>：如果我们必须要对数据倾斜迎难而上，那么建议优先使用这种方案，因为这是处理数据倾斜最简单的一种方案。</p><p><strong>方案实现思路</strong>：在对RDD执行shuffle算子时，给shuffle算子传入一个参数，比如reduceByKey(1000)，该参数就设置了这个shuffle算子执行时shuffle read task的数量。对于Spark SQL中的shuffle类语句，比如group by、join等，需要设置一个参数，即spark.sql.shuffle.partitions，该参数代表了shuffle read task的并行度，该值默认是200，对于很多场景来说都有点过小。</p><p><strong>原理</strong></p><p>​    Spark在做Shuffle时，默认使用HashPartitioner（非Hash Shuffle）对数据进行分区。如果并行度设置的不合适，可能造成大量不相同的Key对应的数据被分配到了同一个Task上，造成该Task所处理的数据远大于其它Task，从而造成数据倾斜。</p><p><strong>优势</strong></p><p>​    实现简单，可在需要Shuffle的操作算子上直接设置并行度或者使用spark.default.parallelism设置。如果是Spark SQL，还可通过SET spark.sql.shuffle.partitions=[num_tasks]设置并行度。可用最小的代价解决问题。一般如果出现数据倾斜，都可以通过这种方法先试验几次，如果问题未解决，再尝试其它方法。</p><p><strong>劣势</strong></p><p>​    适用场景少，只能将分配到同一Task的不同Key分散开，但对于同一Key倾斜严重的情况该方法并不适用。并且该方法一般只能缓解数据倾斜，没有彻底消除问题。从实践经验来看，其效果一般。</p><h5 id="方式三"><a href="#方式三" class="headerlink" title="方式三"></a><strong>方式三</strong></h5><p><strong>自定义Partitioner</strong><br><strong>原理</strong></p><p>​    使用自定义的Partitioner（默认为HashPartitioner），将原本被分配到同一个Task的不同Key分配到不同Task。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">class CustomerPartitioner(numParts:Int) extends org.apache.spark.Partitioner &#123;</span><br><span class="line"></span><br><span class="line">//覆盖分区数</span><br><span class="line"></span><br><span class="line">override def numPartitions: Int = numParts</span><br><span class="line"></span><br><span class="line">//覆盖分区号获取函数</span><br><span class="line"></span><br><span class="line">override def getPartition(key: Any): Int = &#123;</span><br><span class="line"></span><br><span class="line">val id: Int = key.toString.toInt</span><br><span class="line"></span><br><span class="line">if (id = 900000)</span><br><span class="line"></span><br><span class="line">return new java.util.Random().nextInt(100) % 12</span><br><span class="line"></span><br><span class="line">else</span><br><span class="line"></span><br><span class="line">return id % 12</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>优势</strong></p><p>​    不影响原有的并行度设计。如果改变并行度，后续Stage的并行度也会默认改变，可能会影响后续Stage。</p><p><strong>劣势</strong></p><p>​    适用场景有限，只能将不同Key分散开，对于同一Key对应数据集非常大的场景不适用。效果与调整并行度类似，只能缓解数据倾斜而不能完全消除数据倾斜。而且需要根据数据特点自定义专用的Partitioner，不够灵活。</p><h5 id><a href="#" class="headerlink" title=" "></a> </h5><h5 id="方式四"><a href="#方式四" class="headerlink" title="方式四"></a>方式四</h5><p><strong>将Reduce side Join转变为Map side Join</strong><br><strong>方案适用场景</strong>：在对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小（比如几百M或者一两G），比较适用此方案。</p><p><strong>方案优点</strong>：对join操作导致的数据倾斜，效果非常好，因为根本就不会发生shuffle，也就根本不会发生数据倾斜。</p><p><strong>方案缺点</strong>：适用场景较少，因为这个方案只适用于一个大表和一个小表的情况。毕竟我们需要将小表进行广播，此时会比较消耗内存资源，driver和每个Executor内存中都会驻留一份小RDD的全量数据。如果我们广播出去的RDD数据比较大，比如10G以上，那么就可能发生内存溢出了。因此并不适合两个都是大表的情况。</p><h5 id="方式五"><a href="#方式五" class="headerlink" title="方式五"></a><strong>方式五</strong></h5><p><strong>两阶段聚合（局部聚合+全局聚合）</strong><br><strong>方案适用场景</strong>：对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时，比较适用这种方案。</p><p>​    比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。</p><p><strong>方案优点</strong>：对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。</p><p><strong>方案缺点</strong>：仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案。</p><h5 id="方式六"><a href="#方式六" class="headerlink" title="方式六"></a>方式六</h5><p><strong>为数据倾斜的key增加随机前/后缀</strong><br><strong>原理</strong></p><p>​    为数据量特别大的Key增加随机前/后缀，使得原来Key相同的数据变为Key不相同的数据，从而使倾斜的数据集分散到不同的Task中，彻底解决数据倾斜问题。Join另一侧的数据中，与倾斜Key对应的部分数据，与随机前缀集作笛卡尔乘积，从而保证无论数据倾斜侧倾斜Key如何加前缀，都能与之正常Join。</p><p><strong>适用场景</strong></p><p>​    两张表都比较大，无法使用Map则Join。其中一个RDD有少数几个Key的数据量过大，另外一个RDD的Key分布较为均匀。</p><p><strong>解决方案</strong></p><p>​    将有数据倾斜的RDD中倾斜Key对应的数据集单独抽取出来加上随机前缀，另外一个RDD每条数据分别与随机前缀结合形成新的RDD（相当于将其数据增到到原来的N倍，N即为随机前缀的总个数），然后将二者Join并去掉前缀。然后将不包含倾斜Key的剩余数据进行Join。最后将两次Join的结果集通过union合并，即可得到全部Join结果。</p><p><strong>优势</strong></p><p>相对于Map则Join，更能适应大数据集的Join。如果资源充足，倾斜部分数据集与非倾斜部分数据集可并行进行，效率提升明显。且只针对倾斜部分的数据做数据扩展，增加的资源消耗有限。</p><p><strong>劣势</strong></p><p>如果倾斜Key非常多，则另一侧数据膨胀非常大，此方案不适用。而且此时对倾斜Key与非倾斜Key分开处理，需要扫描数据集两遍，增加了开销。</p><h5 id="方式七"><a href="#方式七" class="headerlink" title="方式七"></a>方式七</h5><p><strong>使用随机前缀和扩容RDD进行join</strong><br><strong>方案适用场景</strong>：如果在进行join操作时，RDD中有大量的key导致数据倾斜，那么进行分拆key也没什么意义，此时就只能使用最后一种方案来解决问题了。</p><p>​    将该RDD的每条数据都打上一个n以内的随机前缀。同时对另外一个正常的RDD进行扩容，将每条数据都扩容成n条数据，扩容出来的每条数据都依次打上一个0~n的前缀。</p><p><strong>方案优点</strong>：对join类型的数据倾斜基本都可以处理，而且效果也相对比较显著，性能提升效果非常不错。</p><p><strong>方案缺点</strong>：该方案更多的是缓解数据倾斜，而不是彻底避免数据倾斜。而且需要对整个RDD进行扩容，对内存资源要求很高。</p><h5 id="方式八"><a href="#方式八" class="headerlink" title="方式八"></a>方式八</h5><p><strong>采样倾斜key并分拆join操作</strong><br><strong>方案实现思路</strong>：</p><p>​    对包含少数几个数据量过大的key的那个RDD，通过sample算子采样出一份样本来，然后统计一下每个key的数量，计算出来数据量最大的是哪几个key。</p><p>​    然后将这几个key对应的数据从原来的RDD中拆分出来，形成一个单独的RDD，并给每个key都打上n以内的随机数作为前缀，而不会导致倾斜的大部分key形成另外一个RDD。</p><p>​    接着将需要join的另一个RDD，也过滤出来那几个倾斜key对应的数据并形成一个单独的RDD，将每条数据膨胀成n条数据，这n条数据都按顺序附加一个0~n的前缀，不会导致倾斜的大部分key也形成另外一个RDD。</p><p>​    再将附加了随机前缀的独立RDD与另一个膨胀n倍的独立RDD进行join，此时就可以将原先相同的key打散成n份，分散到多个task中去进行join了。而另外两个普通的RDD就照常join即可。最后将两次join的结果使用union算子合并起来即可，就是最终的join结果。</p><p><strong>方案实现原理</strong>：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，可以将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了。具体原理见下图。</p><p><strong>方案优点</strong>：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，采用该方式可以用最有效的方式打散key进行join。而且只需要针对少数倾斜key对应的数据进行扩容n倍，不需要对全量数据进行扩容。避免了占用过多内存。</p><p><strong>方案缺点</strong>：如果导致倾斜的key特别多的话，比如成千上万个key都导致数据倾斜，那么这种方式也不适合。</p><h5 id="方式九"><a href="#方式九" class="headerlink" title="方式九"></a>方式九</h5><p><strong>过滤少数导致倾斜的key</strong><br><strong>方案适用场景</strong>：如果发现导致倾斜的key就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。</p><p><strong>方案优点</strong>：实现简单，而且效果也很好，可以完全规避掉数据倾斜。</p><p><strong>方案缺点</strong>：适用场景不多，大多数情况下，导致倾斜的key还是很多的，并不是只有少数几个。</p>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> 数据倾斜 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java排序算法及稳定性</title>
      <link href="/2018/03/09/java%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%8F%8A%E7%A8%B3%E5%AE%9A%E6%80%A7/"/>
      <url>/2018/03/09/java%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%8F%8A%E7%A8%B3%E5%AE%9A%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<p>​    首先，排序算法的稳定性大家应该都知道，通俗地讲就是能保证排序前2个相等的数其在序列的前后位置顺序和排序后它们两个的前后位置顺序相同。在简单形式化一下，如果Ai = Aj，Ai原来在位置前，排序后Ai还是要在Aj位置前。</p><p>其次，说一下稳定性的好处。排序算法如果是稳定的，那么从一个键上排序，然后再从另一个键上排序，第一个键排序的结果可以为第二个键排序所用。基数排序就是这样，先按低位排序，逐次按高位排序，低位相同的元素其顺序再高位也相同时是不会改变的。另外，如果排序算法稳定，对基于比较的排序算法而言，元素交换的次数可能会少一些（个人感觉，没有证实）。</p><p>​    回到主题，现在分析一下常见的排序算法的稳定性，每个都给出简单的理由。</p><p><strong>(1)冒泡排序</strong></p><p>​    冒泡排序就是把小的元素往前调或者把大的元素往后调。比较是相邻的两个元素比较，交换也发生在这两个元素之间。所以，如果两个元素相等，我想你是不会再无聊地把他们俩交换一下的；如果两个相等的元素没有相邻，那么即使通过前面的两两交换把两个相邻起来，这时候也不会交换，所以相同元素的前后顺序并没有改变，所以冒泡排序是一种稳定排序算法。</p><p><strong>冒泡排序详细介绍，移步：</strong><a href="https://www.javazhiyin.com/go?url=http://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247483704&amp;idx=1&amp;sn=3d056587972675ba725c0ef2c2632709&amp;chksm=fc7a6c96cb0de580be5cf813443f1116a8a7c31450e36de146006933f9ffd21c60286e68bdc0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">冒泡排序</a></p><p><strong>(2)选择排序</strong></p><p>​    选择排序是给每个位置选择当前元素最小的，比如给第一个位置选择最小的，在剩余元素里面给第二个元素选择第二小的，依次类推，直到第n - 1个元素，第n个元素不用选择了，因为只剩下它一个最大的元素了。那么，在一趟选择，如果当前元素比一个元素小，而该小的元素又出现在一个和当前元素相等的元素后面，那么交换后稳定性就被破坏了。</p><p>​    比较拗口，举个例子，序列5 8 5 2 9，我们知道第一遍选择第1个元素5会和2交换，那么原序列中2个5的相对前后顺序就被破坏了，所以选择排序不是一个稳定的排序算法。</p><hr><p><strong>选择排序详细介绍，移步：</strong><a href="https://www.javazhiyin.com/go?url=http://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247483765&amp;idx=1&amp;sn=d39a77a725f6c655608639a083e8c74d&amp;chksm=fc7a6cdbcb0de5cd2bae4320b552089ade93ff6119219dd7b04af476c3ae2303ce25e63dfabc&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">选择排序</a></p><p><strong>(3)插入排序 </strong></p><p>​    插入排序是在一个已经有序的小序列的基础上，一次插入一个元素。当然，刚开始这个有序的小序列只有1个元素，就是第一个元素。比较是从有序序列的末尾开始，也就是想要插入的元素和已经有序的最大者开始比起，如果比它大则直接插入在其后面，否则一直往前找直到找到它该插入的位置。</p><p>​    如果碰见一个和插入元素相等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序就是排好序后的顺序，所以插入排序是稳定的。</p><p><strong>插入排序详细介绍，移步：</strong><a href="https://www.javazhiyin.com/go?url=http://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247483717&amp;idx=1&amp;sn=e664077a8546aff50565ab30e6979c39&amp;chksm=fc7a6cebcb0de5fdbaa3409a828f6f74235aaa59621add59d3f6dac8f84ad6df6ced2bc1e9aa&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">插入排序</a></p><p><strong>(4)快速排序 </strong></p><p>​    快速排序有两个方向，左边的i下标一直往右走，当a[i] &lt;= a[center_index]，其中center_index是中枢元素的数组下标，一般取为数组第0个元素。而右边的j下标一直往左走，当a[j] &gt; a[center_index]。如果i和j都走不动了，i &lt;= j，交换a[i]和a[j],重复上面的过程，直到i &gt; j。 交换a[j]和a[center_index]，完成一趟快速排序。</p><p>​    在中枢元素和a[j]交换的时候，很有可能把前面的元素的稳定性打乱，比如序列为5 3 3 4 3 8 9 10 11，现在中枢元素5和3（第5个元素，下标从1开始计）交换就会把元素3的稳定性打乱，所以快速排序是一个不稳定的排序算法，不稳定发生在中枢元素和a[j] 交换的时刻。</p><p><strong>快速排序详细介绍，移步：</strong><a href="https://www.javazhiyin.com/go?url=http://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247483714&amp;idx=1&amp;sn=5d352c58a48ccc96280a1333ec23c27f&amp;chksm=fc7a6ceccb0de5fa50f4305d91d8b52497e0651927f87dbf8e9863484f94963b0f4aede1d908&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">快速排序</a></p><p><strong>(5)归并排序 </strong></p><p>​    归并排序是把序列递归地分成短序列，递归出口是短序列只有1个元素（认为直接有序）或者2个序列（1次比较和交换），然后把各个有序的段序列合并成一个有序的长序列，不断合并直到原序列全部排好序。可以发现，在1个或2个元素时，1个元素不会交换，2个元素如果大小相等也没有人故意交换，这不会破坏稳定性。</p><p>​    那么，在短的有序序列合并的过程中，稳定是是否受到破坏？没有，合并过程中我们可以保证如果两个当前元素相等时，我们把处在前面的序列的元素保存在结果序列的前面，这样就保证了稳定性。所以，归并排序也是稳定的排序算法。</p><p><strong>归并排序详细介绍，移步：</strong><a href="https://www.javazhiyin.com/go?url=http://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247483773&amp;idx=1&amp;sn=bc7c4eed3f7ee8f7189ae149dd73a719&amp;chksm=fc7a6cd3cb0de5c51fa24a209dd32f6caf5cc087bc97ae0104c503b96b6360bd96ba455abd2e&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">归并排序</a></p><p><strong>(6)基数排序 </strong></p><p>​    基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序，最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。基数排序基于分别排序，分别收集，所以其是稳定的排序算法。</p><p><strong>基数排序详细介绍，移步：</strong><a href="https://www.javazhiyin.com/go?url=http://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247483779&amp;idx=1&amp;sn=77c51e9542b28aae1dbe1225ebf3b424&amp;chksm=fc7a6c2dcb0de53b726262f43e18734ab5e5cc5bb02f42390cdde9605dd8a5e88cd0b3fb717d&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">基数排序</a></p><p><strong>(7)希尔排序(shell) </strong></p><p>​    希尔排序是按照不同步长对元素进行插入排序，当刚开始元素很无序的时候，步长最大，所以插入排序的元素个数很少，速度很快；当元素基本有序了，步长很小， 插入排序对于有序的序列效率很高。所以，希尔排序的时间复杂度会比O(n^2)好一些。由于多次插入排序，我们知道一次插入排序是稳定的，不会改变相同元素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱，所以shell排序是不稳定的。</p><p><strong>希尔排序详细介绍，移步：</strong><a href="https://www.javazhiyin.com/go?url=http://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247483735&amp;idx=1&amp;sn=ce1ee1707dbc63f12130c30e6f81f24c&amp;chksm=fc7a6cf9cb0de5efdf8d336e75ea2434049adb3f10a7c503db8fbc82abe2abc63c38872b3da7&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">希尔排序</a></p><p><strong>(8)堆排序 </strong></p><p>​    我们知道堆的结构是节点i的孩子为2 <em> i和2 </em> i + 1节点，大顶堆要求父节点大于等于其2个子节点，小顶堆要求父节点小于等于其2个子节点。在一个长为n 的序列，堆排序的过程是从第n / 2开始和其子节点共3个值选择最大（大顶堆）或者最小（小顶堆），这3个元素之间的选择当然不会破坏稳定性。但当为n / 2 - 1， n / 2 - 2， … 1这些个父节点选择元素时，就会破坏稳定性。有可能第n / 2个父节点交换把后面一个元素交换过去了，而第n / 2 - 1个父节点把后面一个相同的元素没 有交换，那么这2个相同的元素之间的稳定性就被破坏了。所以，堆排序不是稳定的排序算法。</p><p><strong>堆排序详细介绍，移步：</strong><a href="https://www.javazhiyin.com/go?url=http://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247483782&amp;idx=1&amp;sn=7a5e25c9abce94062e0ee5d9d77bddde&amp;chksm=fc7a6c28cb0de53e591f73b352628eb4ea8660a38715596affff641aaf4ed0939ecb3f67ddb0&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">堆排序</a></p><p>​    综上，得出结论: <strong>选择排序、快速排序、希尔排序、堆排序不是稳定的排序算法，而冒泡排序、插入排序、归并排序和基数排序是稳定的排序算法</strong></p><ul><li>不稳定的排序算法有：快、希、选、堆。（记忆：找到工作就可以“快些选一堆”美女来玩了（并不能））*</li></ul><p>**</p><p><img src="https://www.javazhiyin.com/wp-content/uploads/2018/05/beepress-beepress-weixin-zhihu-jianshu-plugin-2-4-2-1622-1532589910.jpeg" alt="彻底搞懂稳定排序与不稳定排序"></p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 排序 </tag>
            
            <tag> 稳定性 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>sparksql处理小文件</title>
      <link href="/2017/09/03/sparksql%E5%A4%84%E7%90%86%E5%B0%8F%E6%96%87%E4%BB%B6/"/>
      <url>/2017/09/03/sparksql%E5%A4%84%E7%90%86%E5%B0%8F%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h4 id="spark处理方式一："><a href="#spark处理方式一：" class="headerlink" title="spark处理方式一："></a>spark处理方式一：</h4><p>val value: RDD[(Text, Text)] = sc.newAPIHadoopFile[Text,Text,CombineTextInputFormat](“hdfs://localhost:9000/test/hadoopkv1”)</p><h4 id="spark处理方式二："><a href="#spark处理方式二：" class="headerlink" title="spark处理方式二："></a>spark处理方式二：</h4><p>var hadoopConf = new Configuration()<br>hadoopConf.set(“mapreduce.input.fileinputformat.split.maxsize”, “512000000”)<br>hadoopConf.set(“mapreduce.input.fileinputformat.split.minsize”, “268435456”)<br>hadoopConf.set(“mapreduce.input.fileinputformat.split.minsize.per.node”, “134217728”)   //下面这两参数可以不设置，详情看文章末尾<br>hadoopConf.set(“mapreduce.input.fileinputformat.split.minsize.per.rack”, “268435456”)</p><p>val data = sc.newAPIHadoopFile(args(1),<br>  classOf[CombineTextInputFormat],<br>  classOf[LongWritable],<br>  classOf[Text], hadoopConf)</p><h4 id="hive处理小文件："><a href="#hive处理小文件：" class="headerlink" title="hive处理小文件："></a>hive处理小文件：</h4><p>sparksession.sqlContext.setConf(“hive.merge.mapfiles”,”true”)<br>sparksession.sqlContext.setConf(“mapred.max.split.size”,”256000000”)<br>sparksession.sqlContext.setConf(“mapred.min.split.size.per.node”,”192000000”)<br>sparksession.sqlContext.setConf(“mapred.min.split.size.per.rack”,”192000000”)<br>sparksession.sqlContext.setConf(“hive.input.format”,”org.apache.hadoop.hive.ql.io.CombineHiveInputFormat”)</p>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> sparksql </tag>
            
            <tag> 小文件 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hadoop1.x与hadoop2.x的区别</title>
      <link href="/2017/03/11/hadoop1-x%E4%B8%8Ehadoop2-x%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
      <url>/2017/03/11/hadoop1-x%E4%B8%8Ehadoop2-x%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<p>​    （1）Hadoop 1.0Hadoop 1.0即第一代Hadoop，由分布式存储系统HDFS和分布式计算框架MapReduce组成，其中，HDFS由一个NameNode和多个DataNode组成，MapReduce由一个JobTracker和多个TaskTracker组成，对应Hadoop版本为Apache Hadoop 0.20.x、1.x、0.21.X、0.22.x和CDH3。</p><p>​    （2）Hadoop 2.0Hadoop 2.0即第二代Hadoop，为克服Hadoop 1.0中HDFS和MapReduce存在的各种问题而提出的。针对Hadoop 1.0中的单NameNode制约HDFS的扩展性问题，提出了HDFS Federation，它让多个NameNode分管不同的目录进而实现访问隔离和横向扩展，同时它彻底解决了NameNode 单点故障问题；针对Hadoop 1.0中的MapReduce在扩展性和多框架支持等方面的不足，它将JobTracker中的资源管理和作业控制功能分开，分别由组件ResourceManager和ApplicationMaster实现，其中，ResourceManager负责所有应用程序的资源分配，而ApplicationMaster仅负责管理一个应用程序，进而诞生了全新的通用资源管理框架YARN。基于YARN，用户可以运行各种类型的应用程序（不再像1.0那样仅局限于MapReduce一类应用），从离线计算的MapReduce到在线计算（流式处理）的Storm等。Hadoop 2.0对应Hadoop版本为Apache Hadoop 0.23.x、2.x和CDH4。</p><p>​    （3）MapReduce 1.0或MRv1MapReduce 1.0计算框架主要由三部分组成，分别是编程模型、数据处理引擎和运行时环境。它的基本编程模型是将问题抽象成Map和Reduce两个阶段，其中Map阶段将输入数据解析成key/value，迭代调用map()函数处理后，再以key/value的形式输出到本地目录，而Reduce阶段则将key相同的value进行规约处理，并将最终结果写到HDFS上；它的数据处理引擎由MapTask和ReduceTask组成，分别负责Map阶段逻辑和Reduce阶段逻辑的处理；它的运行时环境由（一个）JobTracker和（若干个）TaskTracker两类服务组成，其中，JobTracker负责资源管理和所有作业的控制，而TaskTracker负责接收来自JobTracker的命令并执行它。该框架在扩展性、容错性和多框架支持等方面存在不足，这也促使了MRv2的产生。</p><p>​    （4）MRv2MRv2具有与MRv1相同的编程模型和数据处理引擎，唯一不同的是运行时环境。MRv2是在MRv1基础上经加工之后，运行于资源管理框架YARN之上的计算框架MapReduce。它的运行时环境不再由JobTracker和TaskTracker等服务组成，而是变为通用资源管理系统YARN和作业控制进程ApplicationMaster，其中，YARN负责资源管理和调度，而ApplicationMaster仅负责一个作业的管理。简言之，MRv1仅是一个独立的离线计算框架，而MRv2则是运行于YARN之上的MapReduce。</p><p>​    （5）YARNYARN是Hadoop 2.0中的资源管理系统，它是一个通用的资源管理模块，可为各类应用程序进行资源管理和调度。YARN不仅限于MapReduce一种框架使用，也可以供其他框架使用，比如Tez（将在第9章介绍）、Spark、Storm（将在第10章介绍）等。YARN类似于几年前的资源管理系统Mesos（将在12章介绍）和更早的Torque（将在6章介绍）。由于YARN的通用性，下一代MapReduce的核心已经从简单的支持单一应用的计算框架MapReduce转移到通用的资源管理系统YARN。</p><p>​    （6）HDFS FederationHadoop 2.0中对HDFS进行了改进，使NameNode可以横向扩展成多个，每个NameNode分管一部分目录，进而产生了HDFS Federation，该机制的引入不仅增强了HDFS的扩展性，也使HDFS具备了隔离性。</p>]]></content>
      
      
      <categories>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hadoop </tag>
            
            <tag> bigdata </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scala 集合转换 java集合</title>
      <link href="/2017/02/14/scala-%E9%9B%86%E5%90%88%E8%BD%AC%E6%8D%A2-java%E9%9B%86%E5%90%88/"/>
      <url>/2017/02/14/scala-%E9%9B%86%E5%90%88%E8%BD%AC%E6%8D%A2-java%E9%9B%86%E5%90%88/</url>
      
        <content type="html"><![CDATA[<p>使用 scala.collection.JavaConverters 与Java集合交互。它有一系列的隐式转换，添加了asJava和asScala的转换方法。使用它们这些方法确保转换是显式的，有助于阅读：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import scala.collection.JavaConverters._</span><br><span class="line"></span><br><span class="line">val list: java.util.List[Int] = Seq(1,2,3,4).asJava</span><br><span class="line">val buffer: scala.collection.mutable.Buffer[Int] = list.asScala</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> scala </tag>
            
            <tag> 集合 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark通信架构</title>
      <link href="/2017/01/23/Spark%E9%80%9A%E4%BF%A1%E6%9E%B6%E6%9E%84/"/>
      <url>/2017/01/23/Spark%E9%80%9A%E4%BF%A1%E6%9E%B6%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<ul><li>Spark一开始使用 Akka 作为内部通信部件。<ul><li>在Spark 1.3年代，为了解决大块数据（如Shuffle）的传输问题，Spark引入了Netty通信框架。到了 Spark 1.6, Spark可以配置使用 Akka 或者 Netty 了，这意味着 Netty 可以完全替代 Akka了。再到 Spark 2, Spark 已经完全抛弃 Akka了，全部使用Netty了。</li></ul></li><li>为什么呢？官方的解释是：<ul><li>很多Spark用户也使用Akka，但是由于Akka不同版本之间无法互相通信，这就要求用户必须使用跟Spark完全一样的Akka版本，导致用户无法升级Akka。</li><li>Spark的Akka配置是针对Spark自身来调优的，可能跟用户自己代码中的Akka配置冲突。</li><li>Spark用的Akka特性很少，这部分特性很容易自己实现。同时，这部分代码量相比Akka来说少很多，debug比较容易。如果遇到什么bug，也可以自己马上fix，不需要等Akka上游发布新版本。而且，Spark升级Akka本身又因为第一点会强制要求用户升级他们使用的Akka，对于某些用户来说是不现实的。</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> 通信 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark on yarn</title>
      <link href="/2017/01/13/spark-on-yarn/"/>
      <url>/2017/01/13/spark-on-yarn/</url>
      
        <content type="html"><![CDATA[<p>​    Spark在yarn集群上的部署方式分为两种，yarn client（driver运行在客户端）和yarn cluster（driver运行在master上）</p><h4 id="1、driver-on-master。"><a href="#1、driver-on-master。" class="headerlink" title="1、driver on master。"></a>1、driver on master。</h4><p>​    <strong>(1)</strong> Spark Yarn Client向YARN中提交应用程序，包括Application Master程序、启动Application Master的命令、需要在Executor中运行的程序等；</p><p>​    <strong>(2)</strong> Resource manager收到请求后，在其中一个node manager中为应用程序分配一个container，要求它在container中启动应用程序的Application Master，Application master初始化sparkContext以及创建DAG Scheduler和Task Scheduler。</p><p>​    <strong>(3)</strong> Application master根据sparkContext中的配置，向resource manager申请container，同时，Application master向Resource manager注册，这样用户可通过Resource manager查看应用程序的运行状态</p><p>​    <strong>(4)</strong> Resource manager 在集群中寻找符合条件的node manager，在node manager启动container，要求container启动executor，</p><p>​    <strong>(5)</strong> Executor启动后向Application master注册，并接收Application master分配的task</p><p>​    <strong>(6)</strong> 应用程序运行完成后，Application Master向Resource Manager申请注销并关闭自己。</p><h4 id="2、Driver-on-client"><a href="#2、Driver-on-client" class="headerlink" title="2、Driver on client"></a>2、Driver on client</h4><p>​    <strong>(1)</strong> Spark Yarn Client向YARN的Resource Manager申请启动Application Master。同时在SparkContent初始化中将创建DAG Scheduler和TASK Scheduler等</p><p>​    <strong>(2)</strong> ResourceManager收到请求后，在集群中选择一个NodeManager，为该应用程序分配第一个Container，要求它在这个Container中启动应用程序的ApplicationMaster，与YARN-Cluster区别的是在该ApplicationMaster不运行SparkContext，只与SparkContext进行联系进行资源的分派</p><p>​    <strong>(3)</strong> Client中的SparkContext初始化完毕后，与Application Master建立通讯，向Resource Manager注册，根据任务信息向Resource Manager申请资源(Container)</p><p>​    <strong>(4)</strong> 当application master申请到资源后，便与node manager通信，要求它启动container</p><p>​    <strong>(5)</strong> Container启动后向driver中的sparkContext注册，并申请task</p><p>​    <strong>(6)</strong> 应用程序运行完成后，Client的SparkContext向ResourceManager申请注销并关闭自己。</p><h4 id="3、两种方式的区别"><a href="#3、两种方式的区别" class="headerlink" title="3、两种方式的区别"></a>3、两种方式的区别</h4><p>​    Yarn-client和Yarn cluster模式对比可以看出，在Yarn-client（Driver on client）中，Application Master仅仅从Yarn中申请资源给Executor，之后client会跟container通信进行作业的调度。如果client离集群距离较远，建议不要采用此方式，不过此方式有利于交互式的作业。</p>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> yarn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spark的Shuffle过程介绍</title>
      <link href="/2017/01/02/spark%E7%9A%84Shuffle%E8%BF%87%E7%A8%8B%E4%BB%8B%E7%BB%8D/"/>
      <url>/2017/01/02/spark%E7%9A%84Shuffle%E8%BF%87%E7%A8%8B%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h4 id="HashShuffle过程介绍"><a href="#HashShuffle过程介绍" class="headerlink" title="HashShuffle过程介绍"></a>HashShuffle过程介绍</h4><p>​    Spark丰富了任务类型，有些任务之间数据流转不需要通过Shuffle，但是有些任务之间还是需要通过Shuffle来传递数据，比如wide dependency的group by key。</p><p>​    Spark中需要Shuffle输出的Map任务会为每个Reduce创建对应的bucket，Map产生的结果会根据设置的partitioner得到对应的bucketId，然后填充到相应的bucket中去。每个Map的输出结果可能包含所有的Reduce所需要的数据，所以每个Map会创建R个bucket（R是reduce的个数），M个Map总共会创建M*R个bucket。</p><p>​    Map创建的bucket其实对应磁盘上的一个文件，Map的结果写到每个bucket中其实就是写到那个磁盘文件中，这个文件也被称为blockFile，是Disk Block Manager管理器通过文件名的Hash值对应到本地目录的子目录中创建的。每个Map要在节点上创建R个磁盘文件用于结果输出，Map的结果是直接输出到磁盘文件上的，100KB的内存缓冲是用来创建Fast Buffered OutputStream输出流。这种方式一个问题就是Shuffle文件过多。</p><pre><code>每一个Mapper创建出和Reducer数目相同的bucket，bucket实际上是一个buffer，其大小为shuffle.file.buffer.kb（默认32KB）。</code></pre><p>Mapper产生的结果会根据设置的partition算法填充到每个bucket中去，然后再写入到磁盘文件。<br>Reducer从远端或是本地的block manager中找到相应的文件读取数据。</p><p>​    针对上述Shuffle过程产生的文件过多问题，Spark有另外一种改进的Shuffle过程：consolidation Shuffle，以期显著减少Shuffle文件的数量。在consolidation Shuffle中每个bucket并非对应一个文件，而是对应文件中的一个segment部分。Job的map在某个节点上第一次执行，为每个reduce创建bucket对应的输出文件，把这些文件组织成ShuffleFileGroup，当这次map执行完之后，这个ShuffleFileGroup可以释放为下次循环利用；当又有map在这个节点上执行时，不需要创建新的bucket文件，而是在上次的ShuffleFileGroup中取得已经创建的文件继续追加写一个segment；当前次map还没执行完，ShuffleFileGroup还没有释放，这时如果有新的map在这个节点上执行，无法循环利用这个ShuffleFileGroup，而是只能创建新的bucket文件组成新的ShuffleFileGroup来写输出。</p><p><strong>优点</strong></p><pre><code>1、快-不需要排序，也不需要维持hash表2、不需要额外空间用作排序3、不需要额外IO-数据写入磁盘只需一次，读取也只需一次</code></pre><p><strong>缺点</strong></p><pre><code>1、当partitions大时，输出大量的文件（cores * R）,性能开始降低2、大量的文件写入，使文件系统开始变为随机写，性能比顺序写要降低100倍3、缓存空间占用比较大</code></pre><h4 id="SortShuffle过程介绍"><a href="#SortShuffle过程介绍" class="headerlink" title="SortShuffle过程介绍"></a>SortShuffle过程介绍</h4><p>​    从1.2.0开始默认为sort shuffle(spark.shuffle.manager= sort)，实现逻辑类似于Hadoop MapReduce，Hash Shuffle每一个reducers产生一个文件，但是Sort Shuffle只是产生一个按照reducer id排序可索引的文件，这样，只需获取有关文件中的相关数据块的位置信息，并fseek就可以读取指定reducer的数据。但对于rueducer数比较少的情况，Hash Shuffle明显要比Sort Shuffle快，因此Sort Shuffle有个“fallback”计划，对于reducers数少于 “spark.shuffle.sort.bypassMergeThreshold” (200 by default)，我们使用fallback计划，hashing相关数据到分开的文件，然后合并这些文件为一个，具体实现为BypassMergeSortShuffleWriter。</p><p>​    在map进行排序，在reduce端应用Timsort[1]进行合并。map端是否容许spill，通过spark.shuffle.spill来设置，默认是true。设置为false，如果没有足够的内存来存储map的输出，那么就会导致OOM错误，因此要慎用。</p><p>​    spark使用AppendOnlyMap存储map输出的数据，利用开源hash函数MurmurHash3和平方探测法把key和value保存在相同的array中。这种保存方法可以是spark进行combine。如果spill为true，会在spill前sort。</p><p>​    与hash shuffle相比，sort shuffle中每个Mapper只产生一个数据文件和一个索引文件，数据文件中的数据按照Reducer排序，但属于同一个Reducer的数据不排序。Mapper产生的数据先放到AppendOnlyMap这个数据结构中，如果内存不够，数据则会spill到磁盘，最后合并成一个文件。<br>与Hash shuffle相比，shuffle文件数量减少，内存使用更加可控。但排序会影响速度。</p><p><strong>优点</strong></p><pre><code>1 map创建文件量较少2 少量的IO随机操作，大部分是顺序读写</code></pre><p><strong>缺点</strong></p><pre><code>1 要比Hash Shuffle要慢，需要自己通过shuffle.sort.bypassMergeThreshold来设置合适的值。2 如果使用SSD盘存储shuffle数据，那么Hash Shuffle可能更合适。</code></pre>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> shuffle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GC 日志分析</title>
      <link href="/2016/09/21/GC-%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"/>
      <url>/2016/09/21/GC-%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>​    2017-07-20T16:32:19.836+0800: 1216.559: [GC pause (G1 Evacuation Pause) (young), 0.0797857 secs]<br>​    这是最顶层的信息，它告诉我们这是一个从进程启动后1216.559秒开始的一个疏散暂停，在这时年轻代所有的区域被疏散，如Eden和Survivor。这次收集用了0.0797857秒完成的。</p><p>[Parallel Time: 58.5 ms, GC Workers: 8]<br>并行时间是所有并行GC工作线程所花费的总时间</p><p>[GC Worker Start (ms): Min: 1216567.9, Avg: 1216568.1, Max: 1216568.4, Diff: 0.5]<br>所有工作线程的平均、最小、最大和差异时间</p><p>……</p><p>[Eden: 180.0M(180.0M)-&gt;0.0B(178.0M) Survivors: 26.0M-&gt;16.0M Heap: 432.5M(512.0M)-&gt;262.5M(512.0M)]<br>这显示了Eden占用了180M，在收集前它的容量也是180M。收集之后，它的容量降到了0，自所有对象从Eden区疏散/晋升后。它的目标大小增长到了178M,<br>Survivors收集之后Survivor从26M变到16M，<br>Heap堆空间总占有量和总容量分别是432M和512M回收之前，回收之后分别变为262和512M。</p>]]></content>
      
      
      <categories>
          
          <category> jvm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jvm </tag>
            
            <tag> GC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA -Xms -Xmx -XX:PermSize -XX:MaxPermSize 区别</title>
      <link href="/2016/08/06/JAVA-Xms-Xmx-XX-PermSize-XX-MaxPermSize-%E5%8C%BA%E5%88%AB/"/>
      <url>/2016/08/06/JAVA-Xms-Xmx-XX-PermSize-XX-MaxPermSize-%E5%8C%BA%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h4 id="1、参数设置背景"><a href="#1、参数设置背景" class="headerlink" title="1、参数设置背景"></a>1、参数设置背景</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在做java开发时尤其是大型软件开发时经常会遇到内存溢出的问题，比如说OutOfMemoryError等。这是个让开发人员很痛苦、也很纠结的问题，因为我们有时不知道什么样的操作导致了这种问题的发生。所以我们不得不通过不断的审查、优化自己的代码结构。但是有时我们会发现有些时候不单单是通过重构自身的代码就能够解决这样的问题，因为也可能是由于我们对java虚拟机运行时的内存分配的不得当导致了内存溢出现象的不断发生。</span><br><span class="line"></span><br><span class="line">为了解决这一问题，java开发团队提供了一个用户自定义的方式按需配置java虚拟机运行时的所需的内存——通过参数配置的形式实现参数分配自定义化。</span><br></pre></td></tr></table></figure><h4 id="2、JVM按照其存储数据的内容将所需内存分配为堆区与非堆区两个部分："><a href="#2、JVM按照其存储数据的内容将所需内存分配为堆区与非堆区两个部分：" class="headerlink" title="2、JVM按照其存储数据的内容将所需内存分配为堆区与非堆区两个部分："></a>2、JVM按照其存储数据的内容将所需内存分配为堆区与非堆区两个部分：</h4><pre><code>堆区即为通过new的方式创建的对象（类实例）所占用的内存空间，非堆区即为代码、常量、外部访问（如文件访问流所占资源）等</code></pre><p>​    虽然java的垃圾回收机制虽然能够很好的解决内存浪费的问题，但是这种机制也仅仅的是回收堆区的资源，而对于非堆区的资源就束手无策了，针对这样的资源回收只能凭借开发人员自身的约束来解决。就算是这样（堆区有java回收机制、非堆区开发人员能够很好的解决），当运行时所需内存瞬间激增的时候JVM无奈的也要中止程序的运行。所以本文讲述的是如何解决后者的问题。<br>常见参数种类（配置内存）</p><pre><code>配置堆区：-Xms 、-Xmx、-XX:newSize、-XX:MaxnewSize、-Xmn配置非堆区：-XX:PermSize、-XX:MaxPermSize</code></pre><h5 id="2-1、堆区参数配置"><a href="#2-1、堆区参数配置" class="headerlink" title="2.1、堆区参数配置"></a>2.1、堆区参数配置</h5><ul><li>2.11、-Xms ：表示java虚拟机堆区内存初始内存分配的大小，通常为操作系统可用内存的1/64大小即可，但仍需按照实际情况进行分配。有可能真的按照这样的一个规则分配时，设计出的软件还没有能够运行得起来就挂了。</li><li><p>2.12、-Xmx： 表示java虚拟机堆区内存可被分配的最大上限，通常为操作系统可用内存的1/4大小。但是开发过程中，通常会将 -Xms 与 -Xmx两个参数的配置相同的值，其目的是为了能够在java垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小而浪费资源。</p><p>  一般来讲对于堆区的内存分配只需要对上述两个参数进行合理配置即可。</p></li></ul><h5 id="2-2、非堆区参数配置"><a href="#2-2、非堆区参数配置" class="headerlink" title="2.2、非堆区参数配置"></a>2.2、非堆区参数配置</h5><ul><li>1、-XX:PermSize：表示非堆区初始内存分配大小，其缩写为permanent size（持久化内存）</li><li>2、-XX:MaxPermSize：表示对非堆区分配的内存的最大上限<ul><li>注：在配置之前一定要慎重的考虑一下自身软件所需要的非堆区内存大小，因为此处内存是不会被java垃圾回收机制进行处理的地方。并且更加要注意的是 最大堆内存与最大非堆内存的和绝对不能够超出操作系统的可用内存。</li></ul></li></ul><h4 id="3、jvm-参数配置"><a href="#3、jvm-参数配置" class="headerlink" title="3、jvm 参数配置"></a>3、jvm 参数配置</h4><ul><li><p>1、-Xms：表示java虚拟机堆区内存初始内存分配的大小，通常为操作系统可用内存的1/64大小即可，但仍需按照实际情况进行分配。</p></li><li><p>2、-Xmx：表示java虚拟机堆区内存可被分配的最大上限，通常为操作系统可用内存的1/4大小。</p><ul><li>开发过程中，通常会将-Xms 与-Xmx两个参数的配置相同的值，其目的是为了能够在java垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小而浪费资源。</li></ul><p>1、-XX:newSize：表示新生代初始内存的大小，应该小于-Xms的值；<br>2、-XX:MaxnewSize：表示新生代可被分配的内存的最大上限；当然这个值应该小于-Xmx的值；<br>3、-Xmn：至于这个参数则是对 -XX:newSize、-XX:MaxnewSize两个参数的同时配置，也就是说如果通过-Xmn来配置新生代的内存大小，那么-XX:newSize = -XX:MaxnewSize　=　-Xmn，虽然会很方便，但需要注意的是这个参数是在JDK1.4版本以后才使用的。</p></li></ul><h5 id="3-1、java虚拟机对非堆区内存配置的两个参数："><a href="#3-1、java虚拟机对非堆区内存配置的两个参数：" class="headerlink" title="3.1、java虚拟机对非堆区内存配置的两个参数："></a>3.1、java虚拟机对非堆区内存配置的两个参数：</h5><p>​    1、-XX:PermSize：表示非堆区初始内存分配大小（方法区）<br>​    2、-XX:MaxPermSize：表示对非堆区分配的内存的最大上限（方法区）。</p><p>​    在配置之前一定要慎重的考虑一下自身软件所需要的非堆区内存大小，因为此处内存是不会被java垃圾回收机制进行处理的地方。并且更加要注意的是最大堆内存与最大非堆内存的和绝对不能够超出操作系统的可用内存。</p>]]></content>
      
      
      <categories>
          
          <category> jvm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GC </tag>
            
            <tag> JAVA </tag>
            
            <tag> JVM </tag>
            
            <tag> spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java中volatile关键字的含义</title>
      <link href="/2016/05/15/java%E4%B8%ADvolatile%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E5%90%AB%E4%B9%89/"/>
      <url>/2016/05/15/java%E4%B8%ADvolatile%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E5%90%AB%E4%B9%89/</url>
      
        <content type="html"><![CDATA[<p><strong>synchronized</strong> </p><p>同步块大家都比较熟悉，通过 synchronized 关键字来实现，所有加上synchronized 和 块语句，在多线程访问的时候，同一时刻只能有一个线程能够用</p><p>synchronized 修饰的方法 或者 代码块。</p><p><strong>volatile</strong></p><p>用volatile修饰的变量，线程在每次使用变量的时候，都会读取变量修改后的最的值。volatile很容易被误用，用来进行原子性操作。</p><p>例子，我们实现一个计数器，每次线程启动的时候，会调用计数器inc方法，对计数器进行加一</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">public class Counter &#123;</span><br><span class="line"> </span><br><span class="line">    public static int count = 0;</span><br><span class="line"> </span><br><span class="line">    public static void inc() &#123;</span><br><span class="line"> </span><br><span class="line">        //这里延迟1毫秒，使得结果明显</span><br><span class="line">        try &#123;</span><br><span class="line">            Thread.sleep(1);</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        count++;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"> </span><br><span class="line">        //同时启动1000个线程，去进行i++计算，看看实际结果</span><br><span class="line"> </span><br><span class="line">        for (int i = 0; i &lt; 1000; i++) &#123;</span><br><span class="line">            new Thread(new Runnable() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    Counter.inc();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;).start();</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        //这里每次运行的值都有可能不同,可能为1000</span><br><span class="line">        System.out.println(&quot;运行结果:Counter.count=&quot; + Counter.count);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">运行结果:Counter.count=995</span><br><span class="line">实际运算结果每次可能都不一样，本机的结果为：运行结果:Counter.count=995，可以看出，在多线程的环境下，Counter.count并没有期望结果是1000</span><br><span class="line">很多人以为，这个是多线程并发问题，只需要在变量count之前加上volatile就可以避免这个问题，那我们在修改代码看看，看看结果是不是符合我们的期望</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">public class Counter &#123;</span><br><span class="line"> </span><br><span class="line">    public volatile static int count = 0;</span><br><span class="line"> </span><br><span class="line">    public static void inc() &#123;</span><br><span class="line"> </span><br><span class="line">        //这里延迟1毫秒，使得结果明显</span><br><span class="line">        try &#123;</span><br><span class="line">            Thread.sleep(1);</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        count++;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"> </span><br><span class="line">        //同时启动1000个线程，去进行i++计算，看看实际结果</span><br><span class="line"> </span><br><span class="line">        for (int i = 0; i &lt; 1000; i++) &#123;</span><br><span class="line">            new Thread(new Runnable() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    Counter.inc();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;).start();</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        //这里每次运行的值都有可能不同,可能为1000</span><br><span class="line">        System.out.println(&quot;运行结果:Counter.count=&quot; + Counter.count);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行结果:Counter.count=992</p><p>运行结果还是没有我们期望的1000，下面我们分析一下原因</p><p>在 java 垃圾回收整理一文中，描述了jvm运行时刻内存的分配。其中有一个内存区域是jvm虚拟机栈，每一个线程运行时都有一个线程栈，</p><p>线程栈保存了线程运行时候变量值信息。当线程访问某一个对象时候值的时候，首先通过对象的引用找到对应在堆内存的变量的值，然后把堆内存</p><p>变量的具体值load到线程本地内存中，建立一个变量副本，之后线程就不再和对象在堆内存变量值有任何关系，而是直接修改副本变量的值，</p><p>在修改完之后的某一个时刻（线程退出之前），自动把线程变量副本的值回写到对象在堆中变量。这样在堆中的对象的值就产生变化了。下面一幅图</p><p>描述这写交互</p><p><a href="http://images.cnblogs.com/cnblogs_com/aigongsi/201204/201204011757234696.jpg" target="_blank" rel="noopener"><img src="https://images.cnblogs.com/cnblogs_com/aigongsi/201204/201204011757235219.jpg" alt="java volatile1"></a></p><p>read and load 从主存复制变量到当前工作内存<br>use and assign  执行代码，改变共享变量值<br>store and write 用工作内存数据刷新主存相关内容</p><p>其中use and assign 可以多次出现</p><p>但是这一些操作并不是原子性，也就是 在read load之后，如果主内存count变量发生修改之后，线程工作内存中的值由于已经加载，不会产生对应的变化，所以计算出来的结果会和预期不一样</p><p>对于volatile修饰的变量，jvm虚拟机只是保证从主内存加载到线程工作内存的值是最新的</p><p>例如假如线程1，线程2 在进行read,load 操作中，发现主内存中count的值都是5，那么都会加载这个最新的值</p><p>在线程1堆count进行修改之后，会write到主内存中，主内存中的count变量就会变为6</p><p>线程2由于已经进行read,load操作，在进行运算之后，也会更新主内存count的变量值为6</p><p>导致两个线程及时用volatile关键字修改之后，还是会存在并发的情况。</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> volatile </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java中判断字符串为数字的常用方法</title>
      <link href="/2016/05/11/Java%E4%B8%AD%E5%88%A4%E6%96%AD%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%BA%E6%95%B0%E5%AD%97%E7%9A%84%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/"/>
      <url>/2016/05/11/Java%E4%B8%AD%E5%88%A4%E6%96%AD%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%BA%E6%95%B0%E5%AD%97%E7%9A%84%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p><img class="zhao-img-h153" src="http://qnfile.devzhao.com/blog/2018-10-19-jhk-1539947585142.jpeg"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">//方法一：用JAVA自带的函数</span><br><span class="line">public static boolean isNumeric(String str)&#123;</span><br><span class="line">   for (int i = str.length();--i&gt;=0;)&#123;  </span><br><span class="line">       if (!Character.isDigit(str.charAt(i)))&#123;</span><br><span class="line">           return false;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">/*方法二：推荐，速度最快</span><br><span class="line">  * 判断是否为整数 </span><br><span class="line">  * @param str 传入的字符串 </span><br><span class="line">  * @return 是整数返回true,否则返回false </span><br><span class="line">*/</span><br><span class="line"></span><br><span class="line">  public static boolean isInteger(String str) &#123;  </span><br><span class="line">        Pattern pattern = Pattern.compile(&quot;^[-\\+]?[\\d]*$&quot;);  </span><br><span class="line">        return pattern.matcher(str).matches();  </span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//方法三：</span><br><span class="line">public static boolean isNumeric(String str)&#123;</span><br><span class="line">    Pattern pattern = Pattern.compile(&quot;[0-9]*&quot;);</span><br><span class="line">    return pattern.matcher(str).matches();   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//方法四：</span><br><span class="line">public final static boolean isNumeric(String s) &#123;</span><br><span class="line">    if (s != null &amp;&amp; !&quot;&quot;.equals(s.trim()))</span><br><span class="line">        return s.matches(&quot;^[0-9]*$&quot;);</span><br><span class="line">    else</span><br><span class="line">        return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">//方法五：用ascii码 </span><br><span class="line">public static boolean isNumeric(String str)&#123;</span><br><span class="line">    for(int i=str.length();--i&gt;=0;)&#123;</span><br><span class="line">        int chr=str.charAt(i);</span><br><span class="line">        if(chr&lt;48 || chr&gt;57)</span><br><span class="line">            return false;</span><br><span class="line">    &#125;</span><br><span class="line">   return true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 常用方法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自己搭建梯子</title>
      <link href="/2016/01/05/%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA%E6%A2%AF%E5%AD%90/"/>
      <url>/2016/01/05/%E8%87%AA%E5%B7%B1%E6%90%AD%E5%BB%BA%E6%A2%AF%E5%AD%90/</url>
      
        <content type="html"><![CDATA[<h4 id="1、挑选服务器："><a href="#1、挑选服务器：" class="headerlink" title="1、挑选服务器："></a><strong>1、挑选服务器：</strong></h4><p>​     一般供应商都会提供IP<a href="http://lib.csdn.net/base/softwaretest" target="_blank" rel="noopener">测试</a>延迟，或者看各VPS网站评测介绍，一般来讲亚洲服务器延迟更低，比如香港.新加坡就有很多电信或者网通直连机房，而美国VPS价格更便宜，而且带宽大些。</p><p>​    服务器类型，Xen KVM 性能要好过openvz，不过也要更贵一些，综上所述，建议选直连自己运营商的KVM虚拟技术的亚洲VPS。</p><p>下面我们用日本conoha VPS为例开始操作。</p><p>1.日本conoha支持支付宝支付，每月900日元、中文界面 （50rmb如果几个人合用的话成本还算可以。选择HOSTUS的香港25美元/年电信机房也不错）设置并记root密码点击追加建立服务器，这里我们选择centos 6.6 64位版本</p><p><img src="http://i3.tietuku.com/73939c8862f69acd.png" alt="img">2.回到服务器界面，点开网络配置，记下IP4地址</p><h4 id="2-用XshellPortable连接服务器"><a href="#2-用XshellPortable连接服务器" class="headerlink" title="2.用XshellPortable连接服务器"></a>2.用XshellPortable连接服务器</h4><p>填上IP地址点击确定</p><p>用户名为 root</p><p>密码为开通vps设置的9位密码</p><p>连接成功会显示，root@XXXXXX #<br>然后在设置里把右键改成复制剪贴板中的代码 如图，右键粘贴比较方便</p><h4 id="3-这里我们用秋水兄的SS一键安装脚本"><a href="#3-这里我们用秋水兄的SS一键安装脚本" class="headerlink" title="3.这里我们用秋水兄的SS一键安装脚本"></a>3.这里我们用秋水兄的SS一键安装脚本</h4><p>​    全程仅需3行代码，即使0基础毫无问题，依次输入代码回车即可</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.sh</span><br><span class="line"></span><br><span class="line">chmod +x shadowsocks.sh</span><br><span class="line"></span><br><span class="line">./shadowsocks.sh 2&gt;&amp;1 | tee shadowsocks.log</span><br></pre></td></tr></table></figure><p><img src="http://i3.tietuku.com/ae721437801a8c77.png" alt="img"></p><p>询问密码：输入t66y为端口密码</p><p><img src="http://i3.tietuku.com/0ffcb227120d76cd.png" alt="img"></p><p>默认端口8989.可以指定任意端口 ，回车后耐心等待安装</p><p><img src="http://i3.tietuku.com/5d03e29f5ba8a52b.png" alt="img"></p><p>安装完成后，脚本提示如下：</p><p><img src="http://i3.tietuku.com/ace55c8d0f0405c8.png" alt="img"></p><p>现在我们已经成功搭建了一个单用户版SS代理服务器，用其他帖子的教程连接该服务器即可<br>端口为8989 密码t66y</p><h4 id="4-多用户配置"><a href="#4-多用户配置" class="headerlink" title="4.多用户配置"></a>4.多用户配置</h4><p>删除原配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -f /etc/shadowsocks.json</span><br></pre></td></tr></table></figure><p>编辑配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/shadowsocks.json</span><br></pre></td></tr></table></figure><p><img src="http://i3.tietuku.com/0abd0889dc17cb2e.png" alt="img"></p><p>按下I键，进入编辑状态<br>左下角有标示—INSERT—<br>如图复制下面代码至配置文件<br>配置端口 8989到9004，密码t66y0到t66y4等5个账号<br>可照例加入更多用户</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&quot;local_address&quot;:&quot;127.0.0.1&quot;,</span><br><span class="line">&quot;local_port&quot;:1080,</span><br><span class="line">&quot;port_password&quot;:&#123;</span><br><span class="line">&quot;8989&quot;:&quot;t66y0&quot;,</span><br><span class="line">&quot;9001&quot;:&quot;t66y1&quot;,</span><br><span class="line">&quot;9002&quot;:&quot;t66y2&quot;,</span><br><span class="line">&quot;9003&quot;:&quot;t66y3&quot;,</span><br><span class="line">&quot;9004&quot;:&quot;t66y4&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;timeout&quot;:300,</span><br><span class="line">&quot;method&quot;:&quot;aes-256-cfb&quot;,</span><br><span class="line">&quot;fast_open&quot;: false</span><br></pre></td></tr></table></figure><p>按下ESC键退出编辑状态，同时按下SHIFT+Q键进入退出模式<br>如图输入wq回车保存退出</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wd</span><br></pre></td></tr></table></figure><h4 id="5、重启-SS服务"><a href="#5、重启-SS服务" class="headerlink" title="5、重启 SS服务"></a>5、重启 SS服务</h4><p><code>/etc/init.d/shadowsocks restart</code></p><p>至此一个多用户版本的SS服务器已经搭建完成<br>其他命令：<br>启动：/etc/init.d/shadowsocks start<br>停止：/etc/init.d/shadowsocks stop<br>重启：/etc/init.d/shadowsocks restart<br>状态：/etc/init.d/shadowsocks status<br>卸载：./shadowsocks.sh uninstall</p><h4 id="6、Shadowsocks-WIN客户端设置"><a href="#6、Shadowsocks-WIN客户端设置" class="headerlink" title="6、Shadowsocks WIN客户端设置"></a>6、Shadowsocks WIN客户端设置</h4><p>Win客户端下载地址：<a href="http://sourceforge.NET/projects/shadowsocksgui/files/dist/" target="_blank" rel="noopener">http://sourceforge.NET/projects/shadowsocksgui/files/dist/</a></p><p>设置界面如下：</p><p>其中：Server IP为服务器IP，Server Port为远程端口（在服务器端shadowsocks.json中设置），Password为密码，Encryption为加密方式，选择<code>AES-256-CFB</code>，Proxy Port为本地端口（在服务器端shadowsocks.json中设置），Remarks为别名。</p><p>配置好客户端后，我们需要选择合适的浏览器和插件来应用本地代理，下面分别介绍了Chrome和Firefox的设置方法。</p><p><strong>a、Chrome</strong></p><p>Chrome使用本地代理需要用到插件<a href="http://switchysharp.com/install.html" target="_blank" rel="noopener">SwitchySharp</a>，安装好插件后，打开插件的设置界面，填入如下设置</p><p>设置完成后选择插件的代理模式为<code>Shadowsocks</code>(或者你自己命名的情景模式)后即可。</p><p>上面的设置为全局代理，如需实现智能代理需要手动添加规则，还可以订阅GFWlist，地址为：<a href="http://autoproxy-gfwlist.googlecode.com/svn/trunk/gfwlist.txt" target="_blank" rel="noopener">http://autoproxy-gfwlist.googlecode.com/svn/trunk/gfwlist.txt</a> 由于这个地址不通过代理无法访问，所以你可以通过其它途径下载到本地，这方面资料网上比较丰富，再者使用起来不是很方便，在此我就不赘述了。下面介绍另一种规则，<a href="https://github.com/clowwindy/" target="_blank" rel="noopener">gfwlist2pac</a>，这是网友在Gfwlist的基础上，更新了部分网址转化成的PAC规则文件，目前我就采用的是这种方式，体验不错，当然，由于规则文件都具有时效性，也许你看到这篇文章时这个规则或许不是最好用的了，这里只是讲一种思路，你可以自行选择其他规则，甚至是自定义的规则，使用PAC规则设置如下:</p><p>PAC规则地址：<a href="https://raw.githubusercontent.com/clowwindy/gfwlist2pac/master/test/proxy_abp.pac" target="_blank" rel="noopener">https://raw.githubusercontent.com/clowwindy/gfwlist2pac/master/test/proxy_abp.pac</a></p><p>设置完成后选择插件的代理模式为<code>gfwlist2pac</code>(或者你自己命名的情景模式)后即可。</p><p><strong>b、Firefox</strong></p><p>Firefox使用本地代理需要用到插件<a href="http://fxthunder.com/blog/archives/2866/" target="_blank" rel="noopener">Autoproxy</a>，这个插件原作者已经没有更新了，本文使用的是其他作者的继续更新版，修复了无法订阅gfwlist的bug，订阅方法和上述类似，同样由于原地址无法直接访问，所以可以通过其他途径下载到本地然后导入。</p><h4 id="7、Shadowsocks-Android客户端设置"><a href="#7、Shadowsocks-Android客户端设置" class="headerlink" title="7、Shadowsocks  Android客户端设置"></a>7、Shadowsocks  Android客户端设置</h4><p>首先需要下载android客户端，Shadowsocks的中文名称为影梭，可以从googleplay下载，如果你无法使用googleplay,可从下面的地址下载:<a href="https://github.com/shadowsocks/shadowsocks-android/releases" target="_blank" rel="noopener">https://github.com/shadowsocks/shadowsocks-android/releases</a> ，android版的设置和PC端类似</p>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> 梯子 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络模型和tcp/ip协议</title>
      <link href="/2015/05/16/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%92%8Ctcp-ip%E5%8D%8F%E8%AE%AE/"/>
      <url>/2015/05/16/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%92%8Ctcp-ip%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<h4 id="0、网络模型自上而下共分为七层："><a href="#0、网络模型自上而下共分为七层：" class="headerlink" title="0、网络模型自上而下共分为七层："></a>0、网络模型自上而下共分为七层：</h4><p>7 应用层<br>6 表示层<br>5 会话层<br>4 传输层<br>3 网络层<br>2 数据链路层<br>1 物理层</p><p><strong>其中3、2、1层主要面向通过网络的端到端的数据流，7、6、5、4层定义了应用程序的功能。</strong></p><p><strong>（1）应用层</strong>：与其他计算机进行通讯的一个应用，它是对应应用程序的通信服务的。例如，一个没有通信功能的字处理程序就不能执行通信的代码，从事字处理工作的程序员也不关心OSI的第7层。但是，如果添加了一个传输文件的选项，那么字处理器的程序员就需要实现OSI的第7层。示例：telnet，HTTP,FTP,WWW,NFS,SMTP等。</p><p><strong>（2）表示层</strong>：这一层的主要功能是定义数据格式及加密。例如，FTP允许你选择以二进制或ASII格式传输。如果选择二进制，那么发送方和接收方不改变文件的内容。如果选择ASII格式，发送方将把文本从发送方的字符集转换成标准的ASII后发送数据。在接收方将标准的ASII转换成接收方计算机的字符集。示例：加密，ASII等。</p><p><strong>（3）会话层</strong>：他定义了如何开始、控制和结束一个会话，包括对多个双向小时的控制和管理，以便在只完成连续消息的一部分时可以通知应用，从而使表示层看到的数据是连续的，在某些情况下，如果表示层收到了所有的数据，则用数据代表表示层。示例：RPC，SQL等。</p><p><strong>（4）传输层</strong>：这层的功能包括是否选择差错恢复协议还是无差错恢复协议，及在同一主机上对不同应用的数据流的输入进行复用，还包括对收到的顺序不对的数据包的重新排序功能。示例：TCP，UDP，SPX。</p><p><strong>（5）网络层</strong>：这层对端到端的包传输进行定义，他定义了能够标识所有结点的逻辑地址，还定义了路由实现的方式和学习的方式。为了适应最大传输单元长度小于包长度的传输介质，网络层还定义了如何将一个包分解成更小的包的分段方法。示例：IP,IPX等。</p><p><strong>（6）数据链路层</strong>：他定义了在单个链路上如何传输数据。这些协议与被讨论的歌种介质有关。示例：ATM，FDDI等。</p><p><strong>（7）物理层</strong>：OSI的物理层规范是有关传输介质的特性标准，这些规范通常也参考了其他组织制定的标准。连接头、针、针的使用、电流、电流、编码及光调制等都属于各种物理层规范中的内容。物理层常用多个规范完成对所有细节的定义。示例：Rj45，802.3等。</p><p><strong>OSI分层的优点：</strong><br>（1）人们可以很容易的讨论和学习协议的规范细节。<br>（2）层间的标准接口方便了工程模块化。<br>（3）创建了一个更好的互连环境。<br>（4）降低了复杂度，使程序更容易修改，产品开发的速度更快。<br>（5）每层利用紧邻的下层服务，更容易记住个层的功能。</p><p><strong>tcp/ip</strong></p><p>TCP/IP是“transmission Control Protocol/Internet Protocol”的简写，中文译名为传输控制协议/互联网络协议）协议。</p><p>TCP/IP（传输控制协议/网间协议）是一种网络通信协议，它规范了网络上的所有通信设备，尤其是一个主机与另一个主机之间的数据往来格式以及传送方式。TCP/IP是INTERNET的基础协议，也是一种电脑数据打包和寻址的标准方法。在数据传送中，可以形象地理解为有两个信封，TCP和IP就像是信封，要传递的信息被划分成若干段，每一段塞入一个TCP信封，并在该信封面上记录有分段号的信息，再将TCP信封塞入IP大信封，发送上网。在接受端，一个TCP软件包收集信封，抽出数据，按发送前的顺序还原，并加以校验，若发现差错，TCP将会要求重发。因此，TCP/IP在INTERNET中几乎可以无差错地传送数据。对普通用户来说，并不需要了解网络协议的整个结构，仅需了解IP的地址格式，即可与世界各地进行网络通信。<br>​        </p>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络模型 </tag>
            
            <tag> tcp </tag>
            
            <tag> ip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>transient</title>
      <link href="/2015/05/12/transient/"/>
      <url>/2015/05/12/transient/</url>
      
        <content type="html"><![CDATA[<pre><code>java对象只要实现了Serilizable接口，这个对象就可以被序列化，java的这种序列化模式为开发者提供了很多便利，我们可以不必关系具体序列化的过程，只要这个类实现了Serilizable接口，这个类的所有属性和方法都会自动序列化。 然而在实际开发过程中，我们常常会遇到这样的问题，这个类的有些属性需要序列化，而其他属性不需要被序列化，打个比方，如果一个用户有一些敏感信息（如密码，银行卡号等），为了安全起见，不希望在网络操作（主要涉及到序列化操作，本地序列化缓存也适用）中被传输，这些信息对应的变量就可以加上transient关键字。换句话说，这个字段的生命周期仅存于调用者的内存中而不会写到磁盘里持久化。 总之，java 的transient关键字为我们提供了便利，你只需要实现Serilizable接口，将不需要序列化的属性前添加关键字transient，序列化对象的时候，这个属性就不会序列化到指定的目的地中。</code></pre><h4 id="一、代码测试1"><a href="#一、代码测试1" class="headerlink" title="一、代码测试1"></a>一、代码测试1</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line">import java.io.FileInputStream;</span><br><span class="line">import java.io.FileNotFoundException;</span><br><span class="line">import java.io.FileOutputStream;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.io.ObjectInputStream;</span><br><span class="line">import java.io.ObjectOutputStream;</span><br><span class="line">import java.io.Serializable;</span><br><span class="line"> </span><br><span class="line">/**</span><br><span class="line"> * @description 使用transient关键字不序列化某个变量</span><br><span class="line"> *        注意读取的时候，读取数据的顺序一定要和存放数据的顺序保持一致</span><br><span class="line"> *        </span><br><span class="line"> * @author Alexia</span><br><span class="line"> * @date  2013-10-15</span><br><span class="line"> */</span><br><span class="line">public class TransientTest &#123;</span><br><span class="line">    </span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        </span><br><span class="line">        User user = new User();</span><br><span class="line">        user.setUsername(&quot;Alexia&quot;);</span><br><span class="line">        user.setPasswd(&quot;123456&quot;);</span><br><span class="line">        </span><br><span class="line">        System.out.println(&quot;read before Serializable: &quot;);</span><br><span class="line">        System.out.println(&quot;username: &quot; + user.getUsername());</span><br><span class="line">        System.err.println(&quot;password: &quot; + user.getPasswd());</span><br><span class="line">        </span><br><span class="line">        try &#123;</span><br><span class="line">            ObjectOutputStream os = new ObjectOutputStream(</span><br><span class="line">                    new FileOutputStream(&quot;C:/user.txt&quot;));</span><br><span class="line">            os.writeObject(user); // 将User对象写进文件</span><br><span class="line">            os.flush();</span><br><span class="line">            os.close();</span><br><span class="line">        &#125; catch (FileNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        try &#123;</span><br><span class="line">            ObjectInputStream is = new ObjectInputStream(new FileInputStream(</span><br><span class="line">                    &quot;C:/user.txt&quot;));</span><br><span class="line">            user = (User) is.readObject(); // 从流中读取User的数据</span><br><span class="line">            is.close();</span><br><span class="line">            </span><br><span class="line">            System.out.println(&quot;\nread after Serializable: &quot;);</span><br><span class="line">            System.out.println(&quot;username: &quot; + user.getUsername());</span><br><span class="line">            System.err.println(&quot;password: &quot; + user.getPasswd());</span><br><span class="line">            </span><br><span class="line">        &#125; catch (FileNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; catch (ClassNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">class User implements Serializable &#123;</span><br><span class="line">    private static final long serialVersionUID = 8294180014912103005L;  </span><br><span class="line">    </span><br><span class="line">    private String username;</span><br><span class="line">    private transient String passwd;</span><br><span class="line">    </span><br><span class="line">    public String getUsername() &#123;</span><br><span class="line">        return username;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public void setUsername(String username) &#123;</span><br><span class="line">        this.username = username;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public String getPasswd() &#123;</span><br><span class="line">        return passwd;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public void setPasswd(String passwd) &#123;</span><br><span class="line">        this.passwd = passwd;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">结果如下：</span><br><span class="line">read before Serializable: </span><br><span class="line">username: Alexia</span><br><span class="line">password: 123456</span><br><span class="line"> </span><br><span class="line">read after Serializable: </span><br><span class="line">username: Alexia</span><br><span class="line">password: null</span><br></pre></td></tr></table></figure><h4 id="二、transient使用小结"><a href="#二、transient使用小结" class="headerlink" title="二、transient使用小结"></a>二、transient使用小结</h4><p>1）一旦变量被transient修饰，变量将不再是对象持久化的一部分，该变量内容在序列化后无法获得访问。</p><p>2）transient关键字只能修饰变量，而不能修饰方法和类。注意，本地变量是不能被transient关键字修饰的。变量如果是用户自定义类变量，则该类需要实现Serializable接口。</p><p>3）被transient关键字修饰的变量不再能被序列化，一个静态变量不管是否被transient修饰，均不能被序列化。</p><h4 id="三、代码测试2"><a href="#三、代码测试2" class="headerlink" title="三、代码测试2"></a>三、代码测试2</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">import java.io.Externalizable;</span><br><span class="line">import java.io.File;</span><br><span class="line">import java.io.FileInputStream;</span><br><span class="line">import java.io.FileOutputStream;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.io.ObjectInput;</span><br><span class="line">import java.io.ObjectInputStream;</span><br><span class="line">import java.io.ObjectOutput;</span><br><span class="line">import java.io.ObjectOutputStream;</span><br><span class="line"> </span><br><span class="line">/**</span><br><span class="line"> * @descripiton Externalizable接口的使用</span><br><span class="line"> * </span><br><span class="line"> * @author Alexia</span><br><span class="line"> * @date 2013-10-15</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line">public class ExternalizableTest implements Externalizable &#123;</span><br><span class="line"> </span><br><span class="line">    private transient String content = &quot;是的，我将会被序列化，不管我是否被transient关键字修饰&quot;;</span><br><span class="line"> </span><br><span class="line">    @Override</span><br><span class="line">    public void writeExternal(ObjectOutput out) throws IOException &#123;</span><br><span class="line">        out.writeObject(content);</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    @Override</span><br><span class="line">    public void readExternal(ObjectInput in) throws IOException,</span><br><span class="line">            ClassNotFoundException &#123;</span><br><span class="line">        content = (String) in.readObject();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        </span><br><span class="line">        ExternalizableTest et = new ExternalizableTest();</span><br><span class="line">        ObjectOutput out = new ObjectOutputStream(new FileOutputStream(</span><br><span class="line">                new File(&quot;test&quot;)));</span><br><span class="line">        out.writeObject(et);</span><br><span class="line"> </span><br><span class="line">        ObjectInput in = new ObjectInputStream(new FileInputStream(new File(</span><br><span class="line">                &quot;test&quot;)));</span><br><span class="line">        et = (ExternalizableTest) in.readObject();</span><br><span class="line">        System.out.println(et.content);</span><br><span class="line"> </span><br><span class="line">        out.close();</span><br><span class="line">        in.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​    在Java中，对象的序列化可以通过实现两种接口来实现，若实现的是Serializable接口，则所有的序列化将会自动进行，若实现的是Externalizable接口，则没有任何东西可以自动序列化，需要在writeExternal方法中进行手工指定所要序列化的变量，这与是否被transient修饰无关。因此第二个例子输出的是变量content初始化的内容，而不是null。</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> transient </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux安装LAMP</title>
      <link href="/2015/01/21/Linux%E5%AE%89%E8%A3%85LAMP/"/>
      <url>/2015/01/21/Linux%E5%AE%89%E8%A3%85LAMP/</url>
      
        <content type="html"><![CDATA[<h2 id="Linux安装LAMP"><a href="#Linux安装LAMP" class="headerlink" title="Linux安装LAMP"></a>Linux安装LAMP</h2><h4 id="0、使用以下命令安装Apache："><a href="#0、使用以下命令安装Apache：" class="headerlink" title="0、使用以下命令安装Apache："></a><strong>0、使用以下命令安装Apache：</strong></h4><p>yum install httpd</p><p>安装完之后，重新启动Apache：/etc/init.d/httpd restart<br>接着将Apache设置为开机启动：chkconfig httpd on.(这一步使得服务器不需要在每次重启的时候都要手动启动httpd服务)</p><p>要查看httpd服务的启动状态，可以使用命令：chkconfig –list httpd(会显示httpd在各个级别(level)下的启动状态)</p><h4 id="1、使用以下命令安装MySQL："><a href="#1、使用以下命令安装MySQL：" class="headerlink" title="1、使用以下命令安装MySQL："></a>1、使用以下命令安装MySQL：</h4><p>yum install mysql mysql-server<br>同样，如果出现提示已安装的话，就说明系统安装了MySQL了，可以跳过这一步，否则，系统接下来会自动安装MySQL。<br>安装完成了之后，启动MySQL：/etc/init.d/mysql start</p><p>将MySQL设置为开机启动：chkconfig mysqld on<br>最后，拷贝配置文件：cp /usr/share/mysql/my-medium.cnf /etc/my.cnf (在/etc下有个my.cnf文件，直接覆盖就行了)</p><p>1.2、用以下命令给root账户设置密码</p><p>mysql_secure_installation<br>根据提示输入2次密码，就设置成功了。注意，在设置过程中，会提示删除是否anonymous用户，是否拒绝root的远程访问，是否删除测试用的数据库等，这些都需要根据自己的实际情况进行选择。最后出现：Thanks for using MySQL!，设置密码成功了。</p><p>重新启动MySQL：/etc/init.d/mysqld restart</p><ol><li>3、mysql开启远程访问权限</li></ol><p>GRANT ALL PRIVILEGES ON <em>.</em> TO ‘myuser‘@’%’IDENTIFIED BY ‘mypassword’ WITH GRANT OPTION;</p><h4 id="2：安装PHP"><a href="#2：安装PHP" class="headerlink" title="2：安装PHP"></a><strong>2：安装PHP</strong></h4><p>2.1、使用以下命令安装PHP：</p><p>yum install php<br>根据提示往下安装就行了。安装完之后重新启动Apache：/etc/init.d/httpd restart<br>2.2、安装PHP组件，是PHP支持MySQL</p><p>可以使用命令：yum search php来查看PHP的组件，选择需要的模块进行安装：</p><p>yum install php-mysql php-gd libjpeg* php-imap php-ldap php-odbc php-pear php-xml php-xmlrpc php-mbstring php-mcrypt php-bcmath php-mhash libmcrypt</p><p>安装完之后，重启Apache：/etc/init.d/httpd restart</p><p>重启MySQL：/etc/init.d/mysqld restart</p>]]></content>
      
      
      <categories>
          
          <category> 博客搭建 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> apache </tag>
            
            <tag> mysql </tag>
            
            <tag> php </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
